{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbaaa9ac",
   "metadata": {},
   "source": [
    "# Explaibability Agent\n",
    "\n",
    "Explaibability Agent (Creates the explainable output of the recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e139c",
   "metadata": {},
   "source": [
    "## **1. Load And Preprocess Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e651b08",
   "metadata": {},
   "source": [
    "This part's only purpose is to load the data used in the Explainability Agent. This process is described in detail in the Preparation Agent. \n",
    "\n",
    "**Note: When computing the script with another Household than Household 1 you might need to adapt some parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e56a7",
   "metadata": {},
   "source": [
    "### **1.1 Initialize And Load Python Scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd511beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "dir = 'D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main'\n",
    "os.chdir(dir)\n",
    "\n",
    "from helper_functions import Helper\n",
    "from agents import Preparation_Agent, Activity_Agent, Usage_Agent, Price_Agent, Load_Agent\n",
    "import pandas as pd\n",
    "\n",
    "helper = Helper()\n",
    "\n",
    "dbfile  = \"D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main/home-assistant_Chris_v3.db\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ebf8b",
   "metadata": {},
   "source": [
    "### **1.2 Set Parameters For Pre-processing Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acea7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "shiftable_devices = [\"sensor.shellyplug_s_4022d88961b4_power\", \"sensor.shellyplug_s_4022d88984b8_power\"]\n",
    "date = '2023-01-09'\n",
    "model_type = 'random forest'\n",
    "\n",
    "\n",
    "truncation_params = {\n",
    "    'features': 'all', \n",
    "    'factor': 1.5, \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "scale_params = {\n",
    "    'features': 'all', \n",
    "    'kind': 'MinMax', \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "aggregate_params = {\n",
    "    'resample_param': '60T'\n",
    "}\n",
    "aggregate_params24_H = {\n",
    "    'resample_param': '24H'\n",
    "}\n",
    "\n",
    "\n",
    "activity_params = {\n",
    "    'active_appliances': shiftable_devices,\n",
    "    'threshold': .10\n",
    "}\n",
    "\n",
    "time_params = {\n",
    "    'features': ['hour', 'day_name']\n",
    "}\n",
    "\n",
    "activity_lag_params = {\n",
    "    'features': ['activity'],\n",
    "    'lags': [24, 48, 72]\n",
    "}\n",
    "\n",
    "device = {\n",
    "    'threshold' : .10}\n",
    "\n",
    "activity_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'activity': activity_params,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params\n",
    "}\n",
    "\n",
    "usage_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'activity': activity_params,\n",
    "    'aggregate_hour': aggregate_params,\n",
    "    'aggregate_day': aggregate_params24_H,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params,\n",
    "    'shiftable_devices' : shiftable_devices,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "device_params = {\n",
    "    'threshold': 0.10\n",
    "}\n",
    "\n",
    "load_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'shiftable_devices': shiftable_devices, \n",
    "    'device': device_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2be56",
   "metadata": {},
   "source": [
    "### **1.3 Pre-process Data For Input In Device_Usage Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d6c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = shiftable_devices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc090b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the preparation pipeline\n",
    "prep = Preparation_Agent(dbfile, shiftable_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29605a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-25 18:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 19:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 20:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 21:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 22:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 19:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 20:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 21:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 22:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 23:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     activity  hour  activity_lag_24  activity_lag_48  \\\n",
       "last_updated                                                            \n",
       "2022-12-25 18:00:00         1    18              NaN              NaN   \n",
       "2022-12-25 19:00:00         0    19              NaN              NaN   \n",
       "2022-12-25 20:00:00         0    20              NaN              NaN   \n",
       "2022-12-25 21:00:00         0    21              NaN              NaN   \n",
       "2022-12-25 22:00:00         0    22              NaN              NaN   \n",
       "...                       ...   ...              ...              ...   \n",
       "2023-01-10 19:00:00         0    19              0.0              0.0   \n",
       "2023-01-10 20:00:00         0    20              0.0              0.0   \n",
       "2023-01-10 21:00:00         0    21              0.0              0.0   \n",
       "2023-01-10 22:00:00         0    22              0.0              0.0   \n",
       "2023-01-10 23:00:00         0    23              0.0              0.0   \n",
       "\n",
       "                     activity_lag_72  day_name_Monday  day_name_Saturday  \\\n",
       "last_updated                                                               \n",
       "2022-12-25 18:00:00              NaN                0                  0   \n",
       "2022-12-25 19:00:00              NaN                0                  0   \n",
       "2022-12-25 20:00:00              NaN                0                  0   \n",
       "2022-12-25 21:00:00              NaN                0                  0   \n",
       "2022-12-25 22:00:00              NaN                0                  0   \n",
       "...                              ...              ...                ...   \n",
       "2023-01-10 19:00:00              0.0                0                  0   \n",
       "2023-01-10 20:00:00              0.0                0                  0   \n",
       "2023-01-10 21:00:00              0.0                0                  0   \n",
       "2023-01-10 22:00:00              0.0                0                  0   \n",
       "2023-01-10 23:00:00              0.0                0                  0   \n",
       "\n",
       "                     day_name_Sunday  day_name_Thursday  day_name_Tuesday  \\\n",
       "last_updated                                                                \n",
       "2022-12-25 18:00:00                1                  0                 0   \n",
       "2022-12-25 19:00:00                1                  0                 0   \n",
       "2022-12-25 20:00:00                1                  0                 0   \n",
       "2022-12-25 21:00:00                1                  0                 0   \n",
       "2022-12-25 22:00:00                1                  0                 0   \n",
       "...                              ...                ...               ...   \n",
       "2023-01-10 19:00:00                0                  0                 1   \n",
       "2023-01-10 20:00:00                0                  0                 1   \n",
       "2023-01-10 21:00:00                0                  0                 1   \n",
       "2023-01-10 22:00:00                0                  0                 1   \n",
       "2023-01-10 23:00:00                0                  0                 1   \n",
       "\n",
       "                     day_name_Wednesday  \n",
       "last_updated                             \n",
       "2022-12-25 18:00:00                   0  \n",
       "2022-12-25 19:00:00                   0  \n",
       "2022-12-25 20:00:00                   0  \n",
       "2022-12-25 21:00:00                   0  \n",
       "2022-12-25 22:00:00                   0  \n",
       "...                                 ...  \n",
       "2023-01-10 19:00:00                   0  \n",
       "2023-01-10 20:00:00                   0  \n",
       "2023-01-10 21:00:00                   0  \n",
       "2023-01-10 22:00:00                   0  \n",
       "2023-01-10 23:00:00                   0  \n",
       "\n",
       "[390 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating activity df\n",
    "activity_df = prep.pipeline_activity(prep.input, activity_pipe_params)\n",
    "activity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd1534ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = Activity_Agent(activity_df)\n",
    "\n",
    "date = '2023-01-09'\n",
    "split_params = {'train_start': '', 'test_delta': {'days':1, 'seconds':-1}, 'target': 'activity'}\n",
    "\n",
    "activity_probs, X_train_activity, X_test_activity, model_activity = activity.pipeline_xai(activity_df, date, 'random forest', split_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5cacb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2023-01-10 00:00:00    0.000000\n",
       "2023-01-10 01:00:00    0.000000\n",
       "2023-01-10 02:00:00    0.000000\n",
       "2023-01-10 03:00:00    0.000000\n",
       "2023-01-10 04:00:00    0.000000\n",
       "2023-01-10 05:00:00    0.000000\n",
       "2023-01-10 06:00:00    0.000000\n",
       "2023-01-10 07:00:00    0.018683\n",
       "2023-01-10 08:00:00    0.027424\n",
       "2023-01-10 09:00:00    0.009704\n",
       "2023-01-10 10:00:00    0.010930\n",
       "2023-01-10 11:00:00    0.030110\n",
       "2023-01-10 12:00:00    0.029779\n",
       "2023-01-10 13:00:00    0.040317\n",
       "2023-01-10 14:00:00    0.056408\n",
       "2023-01-10 15:00:00    0.096224\n",
       "2023-01-10 16:00:00    0.013925\n",
       "2023-01-10 17:00:00    0.012239\n",
       "2023-01-10 18:00:00    0.017667\n",
       "2023-01-10 19:00:00    0.233135\n",
       "2023-01-10 20:00:00    0.070133\n",
       "2023-01-10 21:00:00    0.002891\n",
       "2023-01-10 22:00:00    0.002891\n",
       "2023-01-10 23:00:00    0.002891\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ae19b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>sensor.shellyplug_s_4022d88961b4_power_usage</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power_usage</th>\n",
       "      <th>periods_since_last_activity</th>\n",
       "      <th>periods_since_last_sensor.shellyplug_s_4022d88961b4_power_usage</th>\n",
       "      <th>periods_since_last_sensor.shellyplug_s_4022d88984b8_power_usage</th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_1</th>\n",
       "      <th>activity_lag_2</th>\n",
       "      <th>activity_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power_usage_lag_1</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power_usage_lag_2</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power_usage_lag_3</th>\n",
       "      <th>active_last_2_days</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              activity  sensor.shellyplug_s_4022d88961b4_power_usage  \\\n",
       "last_updated                                                           \n",
       "2022-12-25           1                                             1   \n",
       "2022-12-26           1                                             1   \n",
       "2022-12-27           1                                             1   \n",
       "2022-12-28           0                                             0   \n",
       "2022-12-29           1                                             1   \n",
       "2022-12-30           1                                             1   \n",
       "2022-12-31           1                                             0   \n",
       "2023-01-01           1                                             0   \n",
       "2023-01-02           1                                             1   \n",
       "2023-01-03           0                                             0   \n",
       "2023-01-04           0                                             0   \n",
       "2023-01-05           0                                             0   \n",
       "2023-01-06           1                                             0   \n",
       "2023-01-07           0                                             0   \n",
       "2023-01-08           1                                             1   \n",
       "2023-01-09           1                                             0   \n",
       "2023-01-10           0                                             0   \n",
       "\n",
       "              sensor.shellyplug_s_4022d88984b8_power_usage  \\\n",
       "last_updated                                                 \n",
       "2022-12-25                                               1   \n",
       "2022-12-26                                               1   \n",
       "2022-12-27                                               1   \n",
       "2022-12-28                                               0   \n",
       "2022-12-29                                               0   \n",
       "2022-12-30                                               1   \n",
       "2022-12-31                                               1   \n",
       "2023-01-01                                               1   \n",
       "2023-01-02                                               0   \n",
       "2023-01-03                                               0   \n",
       "2023-01-04                                               0   \n",
       "2023-01-05                                               0   \n",
       "2023-01-06                                               1   \n",
       "2023-01-07                                               0   \n",
       "2023-01-08                                               0   \n",
       "2023-01-09                                               1   \n",
       "2023-01-10                                               0   \n",
       "\n",
       "              periods_since_last_activity  \\\n",
       "last_updated                                \n",
       "2022-12-25                            NaN   \n",
       "2022-12-26                            1.0   \n",
       "2022-12-27                            1.0   \n",
       "2022-12-28                            1.0   \n",
       "2022-12-29                            2.0   \n",
       "2022-12-30                            1.0   \n",
       "2022-12-31                            1.0   \n",
       "2023-01-01                            1.0   \n",
       "2023-01-02                            1.0   \n",
       "2023-01-03                            1.0   \n",
       "2023-01-04                            2.0   \n",
       "2023-01-05                            3.0   \n",
       "2023-01-06                            4.0   \n",
       "2023-01-07                            1.0   \n",
       "2023-01-08                            2.0   \n",
       "2023-01-09                            1.0   \n",
       "2023-01-10                            1.0   \n",
       "\n",
       "              periods_since_last_sensor.shellyplug_s_4022d88961b4_power_usage  \\\n",
       "last_updated                                                                    \n",
       "2022-12-25                                                  NaN                 \n",
       "2022-12-26                                                  1.0                 \n",
       "2022-12-27                                                  1.0                 \n",
       "2022-12-28                                                  1.0                 \n",
       "2022-12-29                                                  2.0                 \n",
       "2022-12-30                                                  1.0                 \n",
       "2022-12-31                                                  1.0                 \n",
       "2023-01-01                                                  2.0                 \n",
       "2023-01-02                                                  3.0                 \n",
       "2023-01-03                                                  1.0                 \n",
       "2023-01-04                                                  2.0                 \n",
       "2023-01-05                                                  3.0                 \n",
       "2023-01-06                                                  4.0                 \n",
       "2023-01-07                                                  5.0                 \n",
       "2023-01-08                                                  6.0                 \n",
       "2023-01-09                                                  1.0                 \n",
       "2023-01-10                                                  2.0                 \n",
       "\n",
       "              periods_since_last_sensor.shellyplug_s_4022d88984b8_power_usage  \\\n",
       "last_updated                                                                    \n",
       "2022-12-25                                                  NaN                 \n",
       "2022-12-26                                                  1.0                 \n",
       "2022-12-27                                                  1.0                 \n",
       "2022-12-28                                                  1.0                 \n",
       "2022-12-29                                                  2.0                 \n",
       "2022-12-30                                                  3.0                 \n",
       "2022-12-31                                                  1.0                 \n",
       "2023-01-01                                                  1.0                 \n",
       "2023-01-02                                                  1.0                 \n",
       "2023-01-03                                                  2.0                 \n",
       "2023-01-04                                                  3.0                 \n",
       "2023-01-05                                                  4.0                 \n",
       "2023-01-06                                                  5.0                 \n",
       "2023-01-07                                                  1.0                 \n",
       "2023-01-08                                                  2.0                 \n",
       "2023-01-09                                                  3.0                 \n",
       "2023-01-10                                                  1.0                 \n",
       "\n",
       "              hour  activity_lag_1  activity_lag_2  activity_lag_3  ...  \\\n",
       "last_updated                                                        ...   \n",
       "2022-12-25       0             NaN             NaN             NaN  ...   \n",
       "2022-12-26       0             1.0             NaN             NaN  ...   \n",
       "2022-12-27       0             1.0             1.0             NaN  ...   \n",
       "2022-12-28       0             1.0             1.0             1.0  ...   \n",
       "2022-12-29       0             0.0             1.0             1.0  ...   \n",
       "2022-12-30       0             1.0             0.0             1.0  ...   \n",
       "2022-12-31       0             1.0             1.0             0.0  ...   \n",
       "2023-01-01       0             1.0             1.0             1.0  ...   \n",
       "2023-01-02       0             1.0             1.0             1.0  ...   \n",
       "2023-01-03       0             1.0             1.0             1.0  ...   \n",
       "2023-01-04       0             0.0             1.0             1.0  ...   \n",
       "2023-01-05       0             0.0             0.0             1.0  ...   \n",
       "2023-01-06       0             0.0             0.0             0.0  ...   \n",
       "2023-01-07       0             1.0             0.0             0.0  ...   \n",
       "2023-01-08       0             0.0             1.0             0.0  ...   \n",
       "2023-01-09       0             1.0             0.0             1.0  ...   \n",
       "2023-01-10       0             1.0             1.0             0.0  ...   \n",
       "\n",
       "              sensor.shellyplug_s_4022d88984b8_power_usage_lag_1  \\\n",
       "last_updated                                                       \n",
       "2022-12-25                                                  NaN    \n",
       "2022-12-26                                                  1.0    \n",
       "2022-12-27                                                  1.0    \n",
       "2022-12-28                                                  1.0    \n",
       "2022-12-29                                                  0.0    \n",
       "2022-12-30                                                  0.0    \n",
       "2022-12-31                                                  1.0    \n",
       "2023-01-01                                                  1.0    \n",
       "2023-01-02                                                  1.0    \n",
       "2023-01-03                                                  0.0    \n",
       "2023-01-04                                                  0.0    \n",
       "2023-01-05                                                  0.0    \n",
       "2023-01-06                                                  0.0    \n",
       "2023-01-07                                                  1.0    \n",
       "2023-01-08                                                  0.0    \n",
       "2023-01-09                                                  0.0    \n",
       "2023-01-10                                                  1.0    \n",
       "\n",
       "              sensor.shellyplug_s_4022d88984b8_power_usage_lag_2  \\\n",
       "last_updated                                                       \n",
       "2022-12-25                                                  NaN    \n",
       "2022-12-26                                                  NaN    \n",
       "2022-12-27                                                  1.0    \n",
       "2022-12-28                                                  1.0    \n",
       "2022-12-29                                                  1.0    \n",
       "2022-12-30                                                  0.0    \n",
       "2022-12-31                                                  0.0    \n",
       "2023-01-01                                                  1.0    \n",
       "2023-01-02                                                  1.0    \n",
       "2023-01-03                                                  1.0    \n",
       "2023-01-04                                                  0.0    \n",
       "2023-01-05                                                  0.0    \n",
       "2023-01-06                                                  0.0    \n",
       "2023-01-07                                                  0.0    \n",
       "2023-01-08                                                  1.0    \n",
       "2023-01-09                                                  0.0    \n",
       "2023-01-10                                                  0.0    \n",
       "\n",
       "              sensor.shellyplug_s_4022d88984b8_power_usage_lag_3  \\\n",
       "last_updated                                                       \n",
       "2022-12-25                                                  NaN    \n",
       "2022-12-26                                                  NaN    \n",
       "2022-12-27                                                  NaN    \n",
       "2022-12-28                                                  1.0    \n",
       "2022-12-29                                                  1.0    \n",
       "2022-12-30                                                  1.0    \n",
       "2022-12-31                                                  0.0    \n",
       "2023-01-01                                                  0.0    \n",
       "2023-01-02                                                  1.0    \n",
       "2023-01-03                                                  1.0    \n",
       "2023-01-04                                                  1.0    \n",
       "2023-01-05                                                  0.0    \n",
       "2023-01-06                                                  0.0    \n",
       "2023-01-07                                                  0.0    \n",
       "2023-01-08                                                  0.0    \n",
       "2023-01-09                                                  1.0    \n",
       "2023-01-10                                                  0.0    \n",
       "\n",
       "              active_last_2_days  day_name_Monday  day_name_Saturday  \\\n",
       "last_updated                                                           \n",
       "2022-12-25                     0                0                  0   \n",
       "2022-12-26                     1                1                  0   \n",
       "2022-12-27                     1                0                  0   \n",
       "2022-12-28                     1                0                  0   \n",
       "2022-12-29                     1                0                  0   \n",
       "2022-12-30                     1                0                  0   \n",
       "2022-12-31                     1                0                  1   \n",
       "2023-01-01                     1                0                  0   \n",
       "2023-01-02                     1                1                  0   \n",
       "2023-01-03                     1                0                  0   \n",
       "2023-01-04                     1                0                  0   \n",
       "2023-01-05                     0                0                  0   \n",
       "2023-01-06                     0                0                  0   \n",
       "2023-01-07                     1                0                  1   \n",
       "2023-01-08                     1                0                  0   \n",
       "2023-01-09                     1                1                  0   \n",
       "2023-01-10                     1                0                  0   \n",
       "\n",
       "              day_name_Sunday  day_name_Thursday  day_name_Tuesday  \\\n",
       "last_updated                                                         \n",
       "2022-12-25                  1                  0                 0   \n",
       "2022-12-26                  0                  0                 0   \n",
       "2022-12-27                  0                  0                 1   \n",
       "2022-12-28                  0                  0                 0   \n",
       "2022-12-29                  0                  1                 0   \n",
       "2022-12-30                  0                  0                 0   \n",
       "2022-12-31                  0                  0                 0   \n",
       "2023-01-01                  1                  0                 0   \n",
       "2023-01-02                  0                  0                 0   \n",
       "2023-01-03                  0                  0                 1   \n",
       "2023-01-04                  0                  0                 0   \n",
       "2023-01-05                  0                  1                 0   \n",
       "2023-01-06                  0                  0                 0   \n",
       "2023-01-07                  0                  0                 0   \n",
       "2023-01-08                  1                  0                 0   \n",
       "2023-01-09                  0                  0                 0   \n",
       "2023-01-10                  0                  0                 1   \n",
       "\n",
       "              day_name_Wednesday  \n",
       "last_updated                      \n",
       "2022-12-25                     0  \n",
       "2022-12-26                     0  \n",
       "2022-12-27                     0  \n",
       "2022-12-28                     1  \n",
       "2022-12-29                     0  \n",
       "2022-12-30                     0  \n",
       "2022-12-31                     0  \n",
       "2023-01-01                     0  \n",
       "2023-01-02                     0  \n",
       "2023-01-03                     0  \n",
       "2023-01-04                     1  \n",
       "2023-01-05                     0  \n",
       "2023-01-06                     0  \n",
       "2023-01-07                     0  \n",
       "2023-01-08                     0  \n",
       "2023-01-09                     0  \n",
       "2023-01-10                     0  \n",
       "\n",
       "[17 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating usage df\n",
    "usage_df = prep.pipeline_usage(prep.input, usage_pipe_params)\n",
    "usage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64037579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Master BWL HU\\3. Semester\\Seminar Information Systems\\Seminar-Information-Systems-main\\agents.py:438: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "usage = Usage_Agent(usage_df, device)\n",
    "date = '2023-01-09'\n",
    "train_start = ''\n",
    "usage_prob, X_train_usage, X_test_usage, model_usage = usage.pipeline_xai(usage_df, date, 'random forest', train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71b8bee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51215238])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff9be3",
   "metadata": {},
   "source": [
    "## **2.  Constructing the Load Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c856d2c",
   "metadata": {},
   "source": [
    "### **2.1 Initialize Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7dcc1",
   "metadata": {},
   "source": [
    "First we define the **Load Agent class**. It takes as input the data generated by the prep.pipeline_usage function computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14fdf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explainability_Agent:\n",
    "    def __init__(self, model_activity, X_train_activity, X_test_activity, best_hour, model_usage,\n",
    "               X_train_usage, X_test_usage, model_type):\n",
    "        self.model_activity = model_activity\n",
    "        self.model_type = model_type\n",
    "        self.X_train_activity = X_train_activity\n",
    "        self.X_test_activity = X_test_activity\n",
    "        self.best_hour = best_hour\n",
    "        self.model_usage = model_usage\n",
    "        self.X_train_usage = X_train_usage\n",
    "        self.X_test_usage = X_test_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133b304",
   "metadata": {},
   "source": [
    "### 2.2 Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb928e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap as shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d8ca122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(self):\n",
    "    if self.model_type == \"logit\":\n",
    "        X_train_summary = shap.sample(self.X_train_activity, 100)\n",
    "        self.explainer_activity = shap.KernelExplainer(self.model_activity.predict_proba, X_train_summary)\n",
    "\n",
    "    elif self.model_type == \"ada\":\n",
    "        X_train_summary = shap.sample(self.X_train_activity, 100)\n",
    "        self.explainer_activity = shap.KernelExplainer(self.model_activity.predict_proba, X_train_summary)\n",
    "\n",
    "    elif self.model_type == \"knn\":\n",
    "        X_train_summary = shap.sample(self.X_train_activity, 100)\n",
    "        self.explainer_activity = shap.KernelExplainer(self.model_activity.predict_proba, X_train_summary)\n",
    "\n",
    "    elif self.model_type == \"random forest\":\n",
    "\n",
    "        self.explainer_activity = shap.TreeExplainer(self.model_activity, self.X_train_activity)\n",
    "\n",
    "    elif self.model_type == \"xgboost\":\n",
    "        self.explainer_activity = shap.TreeExplainer(self.model_activity, self.X_train_activity, model_output='predict_proba')\n",
    "    else:\n",
    "        raise InputError(\"Unknown model type.\")\n",
    "\n",
    "\n",
    "    self.shap_values = self.explainer_activity.shap_values(\n",
    "        self.X_test_activity.iloc[self.best_hour, :])\n",
    "\n",
    "    feature_names_activity = list(self.X_train_activity.columns.values)\n",
    "\n",
    "    vals_activity = self.shap_values[1]\n",
    "\n",
    "    feature_importance_activity = pd.DataFrame(list(zip(feature_names_activity, vals_activity)),\n",
    "                                               columns=['col_name', 'feature_importance_vals'])\n",
    "    feature_importance_activity.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
    "\n",
    "    # usage\n",
    "    if self.model_type == \"logit\":\n",
    "        X_train_summary = shap.sample(self.X_train_usage, 100)\n",
    "        self.explainer_usage = shap.KernelExplainer(self.model_usage.predict_proba, X_train_summary)\n",
    "\n",
    "\n",
    "    elif self.model_type == \"ada\":\n",
    "        X_train_summary = shap.sample(self.X_train_usage, 100)\n",
    "        self.explainer_usage = shap.KernelExplainer(self.model_usage.predict_proba, X_train_summary)\n",
    "\n",
    "    elif self.model_type == \"knn\":\n",
    "        X_train_summary = shap.sample(self.X_train_usage, 100)\n",
    "        self.explainer_usage = shap.KernelExplainer(self.model_usage.predict_proba, X_train_summary)\n",
    "\n",
    "    elif self.model_type == \"random forest\":\n",
    "\n",
    "        self.explainer_usage = shap.TreeExplainer(self.model_usage, self.X_train_usage)\n",
    "\n",
    "    elif self.model_type == \"xgboost\":\n",
    "        self.explainer_usage = shap.TreeExplainer(self.model_usage, self.X_train_usage, model_output='predict_proba')\n",
    "    else:\n",
    "        raise InputError(\"Unknown model type.\")\n",
    "\n",
    "\n",
    "    self.shap_values_usage = self.explainer_usage.shap_values(\n",
    "        self.X_test_usage)\n",
    "\n",
    "    feature_names_usage = list(self.X_train_usage.columns.values)\n",
    "\n",
    "    vals = self.shap_values_usage[1]\n",
    "\n",
    "    feature_importance_usage = pd.DataFrame(list(zip(feature_names_usage, vals)),\n",
    "                                            columns=['col_name', 'feature_importance_vals'])\n",
    "    feature_importance_usage.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
    "\n",
    "    return feature_importance_activity, feature_importance_usage, self.explainer_activity, self.explainer_usage, self.shap_values, self.shap_values_usage, self.X_test_activity, self.X_test_usage\n",
    "\n",
    "# add to Explainability agent\n",
    "setattr(Explainability_Agent, 'feature_importance', feature_importance)\n",
    "del feature_importance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a38d44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>feature_importance_vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hour</td>\n",
       "      <td>0.196181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day_name_Thursday</td>\n",
       "      <td>0.040027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>day_name_Saturday</td>\n",
       "      <td>0.028307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>day_name_Wednesday</td>\n",
       "      <td>0.021947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>activity_lag_72</td>\n",
       "      <td>0.016128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>activity_lag_24</td>\n",
       "      <td>0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>day_name_Monday</td>\n",
       "      <td>0.012265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>day_name_Sunday</td>\n",
       "      <td>0.009619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>activity_lag_48</td>\n",
       "      <td>0.005575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day_name_Tuesday</td>\n",
       "      <td>-0.190192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             col_name  feature_importance_vals\n",
       "0                hour                 0.196181\n",
       "7   day_name_Thursday                 0.040027\n",
       "5   day_name_Saturday                 0.028307\n",
       "9  day_name_Wednesday                 0.021947\n",
       "3     activity_lag_72                 0.016128\n",
       "1     activity_lag_24                 0.014109\n",
       "4     day_name_Monday                 0.012265\n",
       "6     day_name_Sunday                 0.009619\n",
       "2     activity_lag_48                 0.005575\n",
       "8    day_name_Tuesday                -0.190192"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hour = 19\n",
    "Explainability_Agent_i = Explainability_Agent(model_activity, X_train_activity, X_test_activity, best_hour, model_usage,\n",
    "               X_train_usage, X_test_usage, model_type) \n",
    "feature_importance_activity, feature_importance_usage, explainer_activity, explainer_usage, shap_values, shap_values_usage, X_test_activity, X_test_usage = Explainability_Agent_i.feature_importance()\n",
    "feature_importance_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2908b1d",
   "metadata": {},
   "source": [
    "### 2.3 Explaination from feature importance for activity agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbcd7ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_hourly = pd.read_pickle('D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main//export/weather_unscaled_hourly.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e633fb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix</th>\n",
       "      <th>Aggregate</th>\n",
       "      <th>Toaster</th>\n",
       "      <th>Fridge-Freezer</th>\n",
       "      <th>Freezer</th>\n",
       "      <th>Tumble Dryer</th>\n",
       "      <th>Dishwasher</th>\n",
       "      <th>Washing Machine</th>\n",
       "      <th>Television</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>Kettle</th>\n",
       "      <th>Issues</th>\n",
       "      <th>dwpt</th>\n",
       "      <th>rhum</th>\n",
       "      <th>temp</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-09-25 19:00:00</th>\n",
       "      <td>1.380138e+09</td>\n",
       "      <td>410.766578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.384615</td>\n",
       "      <td>36.310345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144.262599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-25 20:00:00</th>\n",
       "      <td>1.380141e+09</td>\n",
       "      <td>417.421053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.443124</td>\n",
       "      <td>44.348048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.928693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>82.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-25 21:00:00</th>\n",
       "      <td>1.380145e+09</td>\n",
       "      <td>508.165821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.849408</td>\n",
       "      <td>36.592217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.302876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-25 22:00:00</th>\n",
       "      <td>1.380148e+09</td>\n",
       "      <td>264.194492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.306368</td>\n",
       "      <td>35.734940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-25 23:00:00</th>\n",
       "      <td>1.380152e+09</td>\n",
       "      <td>296.035836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.110922</td>\n",
       "      <td>36.262799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-02 06:00:00</th>\n",
       "      <td>1.433227e+09</td>\n",
       "      <td>289.996047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.592885</td>\n",
       "      <td>46.397233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-02 07:00:00</th>\n",
       "      <td>1.433230e+09</td>\n",
       "      <td>407.575581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207364</td>\n",
       "      <td>35.753876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.546512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.724806</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>25.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-02 08:00:00</th>\n",
       "      <td>1.433234e+09</td>\n",
       "      <td>731.157390</td>\n",
       "      <td>41.857965</td>\n",
       "      <td>77.969290</td>\n",
       "      <td>37.124760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.180422</td>\n",
       "      <td>0.846449</td>\n",
       "      <td>101.712092</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-02 09:00:00</th>\n",
       "      <td>1.433237e+09</td>\n",
       "      <td>426.764479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.401544</td>\n",
       "      <td>48.005792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.725869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98.171815</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>40.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-02 10:00:00</th>\n",
       "      <td>1.433241e+09</td>\n",
       "      <td>1037.876827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526096</td>\n",
       "      <td>29.085595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>531.390397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025052</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>48.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14752 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Unix    Aggregate    Toaster  Fridge-Freezer  \\\n",
       "Time                                                                        \n",
       "2013-09-25 19:00:00  1.380138e+09   410.766578   0.000000       28.384615   \n",
       "2013-09-25 20:00:00  1.380141e+09   417.421053   0.000000       49.443124   \n",
       "2013-09-25 21:00:00  1.380145e+09   508.165821   0.000000       31.849408   \n",
       "2013-09-25 22:00:00  1.380148e+09   264.194492   0.000000       33.306368   \n",
       "2013-09-25 23:00:00  1.380152e+09   296.035836   0.000000       99.110922   \n",
       "...                           ...          ...        ...             ...   \n",
       "2015-06-02 06:00:00  1.433227e+09   289.996047   0.000000       45.592885   \n",
       "2015-06-02 07:00:00  1.433230e+09   407.575581   0.000000        0.207364   \n",
       "2015-06-02 08:00:00  1.433234e+09   731.157390  41.857965       77.969290   \n",
       "2015-06-02 09:00:00  1.433237e+09   426.764479   0.000000       47.401544   \n",
       "2015-06-02 10:00:00  1.433241e+09  1037.876827   0.000000        0.526096   \n",
       "\n",
       "                       Freezer  Tumble Dryer  Dishwasher  Washing Machine  \\\n",
       "Time                                                                        \n",
       "2013-09-25 19:00:00  36.310345           0.0         0.0         0.000000   \n",
       "2013-09-25 20:00:00  44.348048           0.0         0.0         0.000000   \n",
       "2013-09-25 21:00:00  36.592217           0.0         0.0         0.000000   \n",
       "2013-09-25 22:00:00  35.734940           0.0         0.0         0.000000   \n",
       "2013-09-25 23:00:00  36.262799           0.0         0.0         0.000000   \n",
       "...                        ...           ...         ...              ...   \n",
       "2015-06-02 06:00:00  46.397233           0.0         0.0         0.000000   \n",
       "2015-06-02 07:00:00  35.753876           0.0         0.0         0.000000   \n",
       "2015-06-02 08:00:00  37.124760           0.0         0.0         0.000000   \n",
       "2015-06-02 09:00:00  48.005792           0.0         0.0         0.000000   \n",
       "2015-06-02 10:00:00  29.085595           0.0         0.0       531.390397   \n",
       "\n",
       "                     Television  Microwave      Kettle    Issues  dwpt  rhum  \\\n",
       "Time                                                                           \n",
       "2013-09-25 19:00:00  144.262599   0.000000    0.000000  0.000000  16.0  14.0   \n",
       "2013-09-25 20:00:00  143.928693   0.000000    0.000000  0.000000  16.0  12.9   \n",
       "2013-09-25 21:00:00   67.302876   0.000000    0.000000  0.000000  15.0  13.0   \n",
       "2013-09-25 22:00:00    0.000000   0.000000    0.000000  0.000000  15.0  13.0   \n",
       "2013-09-25 23:00:00    0.000000   0.000000    0.000000  0.000000  13.0  12.1   \n",
       "...                         ...        ...         ...       ...   ...   ...   \n",
       "2015-06-02 06:00:00    0.000000   0.000000    0.000000  0.000000  12.0  11.1   \n",
       "2015-06-02 07:00:00    3.546512   0.000000  136.724806  0.003876  13.0  12.1   \n",
       "2015-06-02 08:00:00  143.180422   0.846449  101.712092  0.003839  14.0  12.0   \n",
       "2015-06-02 09:00:00   34.725869   0.000000   98.171815  0.001931  15.0  13.0   \n",
       "2015-06-02 10:00:00    0.000000   0.000000    0.000000  0.025052  16.0  12.0   \n",
       "\n",
       "                     temp   wdir  wspd  \n",
       "Time                                    \n",
       "2013-09-25 19:00:00  88.0   50.0   9.4  \n",
       "2013-09-25 20:00:00  82.0   40.0   7.6  \n",
       "2013-09-25 21:00:00  88.0   30.0  13.0  \n",
       "2013-09-25 22:00:00  88.0   70.0  18.4  \n",
       "2013-09-25 23:00:00  94.0   60.0  20.5  \n",
       "...                   ...    ...   ...  \n",
       "2015-06-02 06:00:00  94.0  240.0  22.3  \n",
       "2015-06-02 07:00:00  94.0  230.0  25.9  \n",
       "2015-06-02 08:00:00  88.0  220.0  29.5  \n",
       "2015-06-02 09:00:00  88.0  230.0  40.7  \n",
       "2015-06-02 10:00:00  77.0  230.0  48.2  \n",
       "\n",
       "[14752 rows x 17 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38e7d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explanation_from_feature_importance_activity(self, feature_importance_activity, date, best_hour, diagnostics=False, weather_sel = False):\n",
    "    self.feature_importance_activity = feature_importance_activity\n",
    "    self.diagnostics = diagnostics\n",
    "\n",
    "    sentence = 'We based the recommendation on your past activity and usage of the device. '\n",
    "\n",
    "    #activity_lags:\n",
    "\n",
    "    if self.X_test_activity['activity_lag_24'].iloc[self.best_hour] and self.X_test_activity['activity_lag_48'].iloc[self.best_hour] and self.X_test_activity['activity_lag_72'].iloc[self.best_hour] ==0:\n",
    "        active_past = 'not '\n",
    "    else:\n",
    "        active_past = ''\n",
    "\n",
    "    # input the activity lag with the strongest feature importance\n",
    "    if feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_24','feature_importance_vals'].to_numpy()[0] >= 0 or \\\n",
    "            feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_48','feature_importance_vals'].to_numpy()[0] >= 0 or \\\n",
    "            feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_72','feature_importance_vals'].to_numpy()[0] >= 0:\n",
    "\n",
    "            FI_lag = np.argmax([feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_24','feature_importance_vals'],\n",
    "                               feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_48','feature_importance_vals'],\n",
    "                               feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_72','feature_importance_vals']])\n",
    "\n",
    "            if FI_lag == 0:\n",
    "                activity_lag = 'day'\n",
    "            elif FI_lag == 1:\n",
    "                activity_lag = 'two days'\n",
    "            elif FI_lag == 2:\n",
    "                activity_lag = 'three days'\n",
    "            else:\n",
    "                activity_lag = 'three days'\n",
    "\n",
    "            part1 = f\"We believe you are active today since you were {active_past}active during the last {activity_lag}.\"\n",
    "    else:\n",
    "        part1 = \"\"\n",
    "        \n",
    "    if weather_sel:\n",
    "        # weather:\n",
    "        # need to rewrite that part afterwards, we need different weather data!\n",
    "\n",
    "        # weather_hourly = pd.read_pickle('../export/weather_unscaled_hourly.pkl')\n",
    "\n",
    "\n",
    "        d = {'features': ['dwpt', 'rhum', 'temp', 'wdir', 'wspd'],\n",
    "             'labels': ['dewing point', 'relative humidity','temperature', 'wind direction', 'windspeed'],\n",
    "             'feature_importances' : [feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                'col_name'] == 'dwpt', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                  feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                'col_name'] == 'rhum', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                  feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                'col_name'] == 'temp', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                  feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                      'col_name'] == 'wdir', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                  feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                      'col_name'] == 'wspd', 'feature_importance_vals'].to_numpy()[0]],\n",
    "             'feature_values' : [weather_hourly[date].iloc[best_hour, -5:].loc['dwpt'],\n",
    "                                 weather_hourly[date].iloc[best_hour, -5:].loc['rhum'],\n",
    "                                 weather_hourly[date].iloc[best_hour, -5:].loc['temp'],\n",
    "                                 weather_hourly[date].iloc[best_hour, -5:].loc['wdir'],\n",
    "                                 weather_hourly[date].iloc[best_hour, -5:].loc['wspd']\n",
    "                                 ]\n",
    "\n",
    "             }\n",
    "        df = pd.DataFrame(data=d)\n",
    "\n",
    "        sorted_df = df['feature_importances'].sort_values(ascending=False)\n",
    "        if sorted_df.iloc[0] >= 0:\n",
    "            weather1_ind = sorted_df.index[0]\n",
    "            weather1 = df['labels'][weather1_ind]\n",
    "\n",
    "            value1 = round(df['feature_values'][weather1_ind], 2)\n",
    "\n",
    "            part2= f\"The weather condition ({weather1}:{value1}) support that recommendation.\"\n",
    "\n",
    "            if sorted_df.iloc[1] >= 0:\n",
    "\n",
    "                weather2_ind = sorted_df.index[1]\n",
    "                weather2 = df['labels'][weather2_ind]\n",
    "\n",
    "                value2 = round(df['feature_values'][weather2_ind], 2)\n",
    "                part2 = f\"The weather conditions ({weather1}:{value1}, {weather2}:{value2}) support that recommendation.\"\n",
    "\n",
    "        else:\n",
    "            part2= \"\"\n",
    "    else:\n",
    "        part2 = \"\"\n",
    "\n",
    "    # Time features\n",
    "    # DAY\n",
    "    day_names = ['day_name_Monday','day_name_Tuesday','day_name_Wednesday','day_name_Thursday','day_name_Saturday','day_name_Sunday']\n",
    "    for day in day_names:\n",
    "        if feature_importance_activity.loc[feature_importance_activity['col_name'] == day, 'feature_importance_vals'].to_numpy()[0] >= 0:\n",
    "            part3 = \"The weekday strenghtens that prediction.\"\n",
    "\n",
    "            if feature_importance_activity.loc[\n",
    "                feature_importance_activity['col_name'] == 'hour', 'feature_importance_vals'].to_numpy()[0] >= 0:\n",
    "                part3 = \"The weekday and hour strenghtens that prediction.\"\n",
    "\n",
    "        else:\n",
    "            part3 = \"\"\n",
    "            if feature_importance_activity.loc[\n",
    "                feature_importance_activity['col_name'] == 'hour', 'feature_importance_vals'].to_numpy()[0] >= 0:\n",
    "                part3 = \"The hour strenghtens that prediction.\"\n",
    "\n",
    "\n",
    "    # final activity sentence\n",
    "    sentence_activity = (str(part1) + str(part2)+ str(part3))\n",
    "\n",
    "    explanation_sentence = sentence + sentence_activity\n",
    "\n",
    "    return explanation_sentence\n",
    "\n",
    "# add to Explainability agent\n",
    "setattr(Explainability_Agent, 'explanation_from_feature_importance_activity', explanation_from_feature_importance_activity)\n",
    "del explanation_from_feature_importance_activity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "579af8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We based the recommendation on your past activity and usage of the device. We believe you are active today since you were active during the last three days.The weekday and hour strenghtens that prediction.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hour = 19\n",
    "Explainability_Agent_i = Explainability_Agent(model_activity, X_train_activity, X_test_activity, best_hour, model_usage,\n",
    "               X_train_usage, X_test_usage, model_type) \n",
    "sentence = Explainability_Agent_i.explanation_from_feature_importance_activity(feature_importance_activity, date, best_hour, diagnostics=False, weather_sel = False)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f1761",
   "metadata": {},
   "source": [
    "### 2.4 Explaination from feature importance for usage agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f392ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explanation_from_feature_importance_usage(self, feature_importance_usage, date, diagnostics=False, weather_sel = False):\n",
    "\n",
    "    self.feature_importance_usage= feature_importance_usage\n",
    "    self.diagnostics = diagnostics\n",
    "\n",
    "    if self.X_test_usage['active_last_2_days'] == 0:\n",
    "        active_past = 'not'\n",
    "    else:\n",
    "        active_past = ''\n",
    "\n",
    "    if feature_importance_usage.loc[0, 'feature_importance_vals'] >= 0 or feature_importance_usage.loc[1, 'feature_importance_vals'] >= 0:\n",
    "\n",
    "        FI_lag = np.argmax([feature_importance_usage.loc[0, 'feature_importance_vals'],\n",
    "                            feature_importance_usage.loc[1, 'feature_importance_vals']])\n",
    "\n",
    "        if FI_lag == 0:\n",
    "            device_usage = \"\"\n",
    "            number_days = 'day'\n",
    "        elif FI_lag == 1:\n",
    "            device_usage = \"\"\n",
    "            number_days = 'two days'\n",
    "        else:\n",
    "            device_usage = \" not\"\n",
    "            number_days = 'two days'\n",
    "\n",
    "        part1 = f\" and have{device_usage} used the device in the last {number_days}\"\n",
    "\n",
    "    else:\n",
    "        part1= \"\"\n",
    "\n",
    "    if weather_sel:\n",
    "        # weather:\n",
    "        # need to rewrite that part afterwards, we need different weather data!\n",
    "        weather_daily = pd.read_pickle('../export/weather_unscaled_daily.pkl')\n",
    "\n",
    "        d = {'features': ['dwpt', 'rhum', 'temp', 'wdir', 'wspd'],\n",
    "             'labels': ['dewing point', 'relative humidity','temperature', 'wind direction', 'windspeed'],\n",
    "             'feature_importances' : [feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                'col_name'] == 'dwpt', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                  feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                'col_name'] == 'rhum', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                  feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                'col_name'] == 'temp', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                  feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                      'col_name'] == 'wdir', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                  feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                      'col_name'] == 'wspd', 'feature_importance_vals'].to_numpy()[0]],\n",
    "             'feature_values': [weather_daily.loc[date].loc['dwpt'],\n",
    "                                weather_daily.loc[date].loc['rhum'],\n",
    "                                weather_daily.loc[date].loc['temp'],\n",
    "                                weather_daily.loc[date].loc['wdir'],\n",
    "                                weather_daily.loc[date].loc['wspd']\n",
    "             ]\n",
    "\n",
    "\n",
    "             }\n",
    "        df = pd.DataFrame(data=d)\n",
    "\n",
    "        sorted_df = df['feature_importances'].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "        if sorted_df.iloc[0] >= 0:\n",
    "            weather1_ind = sorted_df.index[0]\n",
    "            weather1 = df['labels'][weather1_ind]\n",
    "\n",
    "            value1 = round(df['feature_values'][weather1_ind], 2)\n",
    "\n",
    "            part2= f\"The weather condition ({weather1}:{value1}) support that recommendation.\"\n",
    "\n",
    "            if sorted_df.iloc[1] >= 0:\n",
    "\n",
    "                weather2_ind = sorted_df.index[1]\n",
    "                weather2 = df['labels'][weather2_ind]\n",
    "\n",
    "                value2 = round(df['feature_values'][weather2_ind], 2)\n",
    "                part2 = f\"The weather conditions ({weather1}:{value1}, {weather2}:{value2}) support that recommendation.\"\n",
    "\n",
    "    else:\n",
    "        part2 = \"\"\n",
    "\n",
    "    sentence_usage = f\"We believe you are likely to use the device in the near future since you \" \\\n",
    "                     f\"were {active_past}active during the last 2 days\" + str(part1) + \".\" + str(part2)\n",
    "    explanation_sentence = sentence_usage\n",
    "\n",
    "    return explanation_sentence\n",
    "\n",
    "# add to Explainability agent\n",
    "setattr(Explainability_Agent, 'explanation_from_feature_importance_usage', explanation_from_feature_importance_usage)\n",
    "del explanation_from_feature_importance_usage \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35b369af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We believe you are likely to use the device in the near future since you were active during the last 2 days and have used the device in the last two days.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hour = 19\n",
    "Explainability_Agent_i = Explainability_Agent(model_activity, X_train_activity, X_test_activity, best_hour, model_usage,\n",
    "               X_train_usage, X_test_usage, model_type) \n",
    "sentence = Explainability_Agent_i.explanation_from_feature_importance_usage(feature_importance_usage, date, diagnostics=False, weather_sel = False)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d8b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da2b0351",
   "metadata": {},
   "source": [
    "# 3. Complete Explainability Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainability Agent\n",
    "# ===============================================================================================\n",
    "class Explainability_Agent:\n",
    "    def __init__(self, model_activity, X_train_activity, X_test_activity, best_hour, model_usage,\n",
    "               X_train_usage, X_test_usage, model_type):\n",
    "        self.model_activity = model_activity\n",
    "        self.model_type = model_type\n",
    "        self.X_train_activity = X_train_activity\n",
    "        self.X_test_activity = X_test_activity\n",
    "        self.best_hour = best_hour\n",
    "        self.model_usage = model_usage\n",
    "        self.X_train_usage = X_train_usage\n",
    "        self.X_test_usage = X_test_usage\n",
    "\n",
    "    def feature_importance(self):\n",
    "        if self.model_type == \"logit\":\n",
    "            X_train_summary = shap.sample(self.X_train_activity, 100)\n",
    "            self.explainer_activity = shap.KernelExplainer(self.model_activity.predict_proba, X_train_summary)\n",
    "\n",
    "        elif self.model_type == \"ada\":\n",
    "            X_train_summary = shap.sample(self.X_train_activity, 100)\n",
    "            self.explainer_activity = shap.KernelExplainer(self.model_activity.predict_proba, X_train_summary)\n",
    "\n",
    "        elif self.model_type == \"knn\":\n",
    "            X_train_summary = shap.sample(self.X_train_activity, 100)\n",
    "            self.explainer_activity = shap.KernelExplainer(self.model_activity.predict_proba, X_train_summary)\n",
    "\n",
    "        elif self.model_type == \"random forest\":\n",
    "\n",
    "            self.explainer_activity = shap.TreeExplainer(self.model_activity, self.X_train_activity)\n",
    "\n",
    "        elif self.model_type == \"xgboost\":\n",
    "            self.explainer_activity = shap.TreeExplainer(self.model_activity, self.X_train_activity, model_output='predict_proba')\n",
    "        else:\n",
    "            raise InputError(\"Unknown model type.\")\n",
    "\n",
    "\n",
    "        self.shap_values = self.explainer_activity.shap_values(\n",
    "            self.X_test_activity.iloc[self.best_hour, :])\n",
    "\n",
    "        feature_names_activity = list(self.X_train_activity.columns.values)\n",
    "\n",
    "        vals_activity = self.shap_values[1]\n",
    "\n",
    "        feature_importance_activity = pd.DataFrame(list(zip(feature_names_activity, vals_activity)),\n",
    "                                                   columns=['col_name', 'feature_importance_vals'])\n",
    "        feature_importance_activity.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
    "\n",
    "        # usage\n",
    "        if self.model_type == \"logit\":\n",
    "            X_train_summary = shap.sample(self.X_train_usage, 100)\n",
    "            self.explainer_usage = shap.KernelExplainer(self.model_usage.predict_proba, X_train_summary)\n",
    "\n",
    "\n",
    "        elif self.model_type == \"ada\":\n",
    "            X_train_summary = shap.sample(self.X_train_usage, 100)\n",
    "            self.explainer_usage = shap.KernelExplainer(self.model_usage.predict_proba, X_train_summary)\n",
    "\n",
    "        elif self.model_type == \"knn\":\n",
    "            X_train_summary = shap.sample(self.X_train_usage, 100)\n",
    "            self.explainer_usage = shap.KernelExplainer(self.model_usage.predict_proba, X_train_summary)\n",
    "\n",
    "        elif self.model_type == \"random forest\":\n",
    "\n",
    "            self.explainer_usage = shap.TreeExplainer(self.model_usage, self.X_train_usage)\n",
    "\n",
    "        elif self.model_type == \"xgboost\":\n",
    "            self.explainer_usage = shap.TreeExplainer(self.model_usage, self.X_train_usage, model_output='predict_proba')\n",
    "        else:\n",
    "            raise InputError(\"Unknown model type.\")\n",
    "\n",
    "\n",
    "        self.shap_values_usage = self.explainer_usage.shap_values(\n",
    "            self.X_test_usage)\n",
    "\n",
    "        feature_names_usage = list(self.X_train_usage.columns.values)\n",
    "\n",
    "        vals = self.shap_values_usage[1]\n",
    "\n",
    "        feature_importance_usage = pd.DataFrame(list(zip(feature_names_usage, vals)),\n",
    "                                                columns=['col_name', 'feature_importance_vals'])\n",
    "        feature_importance_usage.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
    "\n",
    "        return feature_importance_activity, feature_importance_usage, self.explainer_activity, self.explainer_usage, self.shap_values, self.shap_values_usage, self.X_test_activity, self.X_test_usage\n",
    "\n",
    "    def explanation_from_feature_importance_activity(self, feature_importance_activity, date, best_hour, diagnostics=False, weather_sel = False):\n",
    "        self.feature_importance_activity = feature_importance_activity\n",
    "        self.diagnostics = diagnostics\n",
    "\n",
    "        sentence = 'We based the recommendation on your past activity and usage of the device. '\n",
    "\n",
    "        #activity_lags:\n",
    "\n",
    "        if self.X_test_activity['activity_lag_24'].iloc[self.best_hour] and self.X_test_activity['activity_lag_48'].iloc[self.best_hour] and self.X_test_activity['activity_lag_72'].iloc[self.best_hour] ==0:\n",
    "            active_past = 'not '\n",
    "        else:\n",
    "            active_past = ''\n",
    "\n",
    "        # input the activity lag with the strongest feature importance\n",
    "        if feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_24','feature_importance_vals'].to_numpy()[0] >= 0 or \\\n",
    "                feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_48','feature_importance_vals'].to_numpy()[0] >= 0 or \\\n",
    "                feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_72','feature_importance_vals'].to_numpy()[0] >= 0:\n",
    "\n",
    "                FI_lag = np.argmax([feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_24','feature_importance_vals'],\n",
    "                                   feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_48','feature_importance_vals'],\n",
    "                                   feature_importance_activity.loc[feature_importance_activity['col_name']=='activity_lag_72','feature_importance_vals']])\n",
    "\n",
    "                if FI_lag == 0:\n",
    "                    activity_lag = 'day'\n",
    "                elif FI_lag == 1:\n",
    "                    activity_lag = 'two days'\n",
    "                elif FI_lag == 2:\n",
    "                    activity_lag = 'three days'\n",
    "                else:\n",
    "                    activity_lag = 'three days'\n",
    "\n",
    "                part1 = f\"We believe you are active today since you were {active_past}active during the last {activity_lag}.\"\n",
    "        else:\n",
    "            part1 = \"\"\n",
    "\n",
    "        if weather_sel:\n",
    "            # weather:\n",
    "            # need to rewrite that part afterwards, we need different weather data!\n",
    "\n",
    "            # weather_hourly = pd.read_pickle('../export/weather_unscaled_hourly.pkl')\n",
    "\n",
    "\n",
    "            d = {'features': ['dwpt', 'rhum', 'temp', 'wdir', 'wspd'],\n",
    "                 'labels': ['dewing point', 'relative humidity','temperature', 'wind direction', 'windspeed'],\n",
    "                 'feature_importances' : [feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                    'col_name'] == 'dwpt', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                      feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                    'col_name'] == 'rhum', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                      feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                    'col_name'] == 'temp', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                      feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                          'col_name'] == 'wdir', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                      feature_importance_activity.loc[feature_importance_activity[\n",
    "                                                                          'col_name'] == 'wspd', 'feature_importance_vals'].to_numpy()[0]],\n",
    "                 'feature_values' : [weather_hourly[date].iloc[best_hour, -5:].loc['dwpt'],\n",
    "                                     weather_hourly[date].iloc[best_hour, -5:].loc['rhum'],\n",
    "                                     weather_hourly[date].iloc[best_hour, -5:].loc['temp'],\n",
    "                                     weather_hourly[date].iloc[best_hour, -5:].loc['wdir'],\n",
    "                                     weather_hourly[date].iloc[best_hour, -5:].loc['wspd']\n",
    "                                     ]\n",
    "\n",
    "                 }\n",
    "            df = pd.DataFrame(data=d)\n",
    "\n",
    "            sorted_df = df['feature_importances'].sort_values(ascending=False)\n",
    "            if sorted_df.iloc[0] >= 0:\n",
    "                weather1_ind = sorted_df.index[0]\n",
    "                weather1 = df['labels'][weather1_ind]\n",
    "\n",
    "                value1 = round(df['feature_values'][weather1_ind], 2)\n",
    "\n",
    "                part2= f\"The weather condition ({weather1}:{value1}) support that recommendation.\"\n",
    "\n",
    "                if sorted_df.iloc[1] >= 0:\n",
    "\n",
    "                    weather2_ind = sorted_df.index[1]\n",
    "                    weather2 = df['labels'][weather2_ind]\n",
    "\n",
    "                    value2 = round(df['feature_values'][weather2_ind], 2)\n",
    "                    part2 = f\"The weather conditions ({weather1}:{value1}, {weather2}:{value2}) support that recommendation.\"\n",
    "\n",
    "            else:\n",
    "                part2= \"\"\n",
    "        else:\n",
    "            part2 = \"\"\n",
    "\n",
    "        # Time features\n",
    "        # DAY\n",
    "        day_names = ['day_name_Monday','day_name_Tuesday','day_name_Wednesday','day_name_Thursday','day_name_Saturday','day_name_Sunday']\n",
    "        for day in day_names:\n",
    "            if feature_importance_activity.loc[feature_importance_activity['col_name'] == day, 'feature_importance_vals'].to_numpy()[0] >= 0:\n",
    "                part3 = \"The weekday strenghtens that prediction.\"\n",
    "\n",
    "                if feature_importance_activity.loc[\n",
    "                    feature_importance_activity['col_name'] == 'hour', 'feature_importance_vals'].to_numpy()[0] >= 0:\n",
    "                    part3 = \"The weekday and hour strenghtens that prediction.\"\n",
    "\n",
    "            else:\n",
    "                part3 = \"\"\n",
    "                if feature_importance_activity.loc[\n",
    "                    feature_importance_activity['col_name'] == 'hour', 'feature_importance_vals'].to_numpy()[0] >= 0:\n",
    "                    part3 = \"The hour strenghtens that prediction.\"\n",
    "\n",
    "\n",
    "        # final activity sentence\n",
    "        sentence_activity = (str(part1) + str(part2)+ str(part3))\n",
    "\n",
    "        explanation_sentence = sentence + sentence_activity\n",
    "\n",
    "        return explanation_sentence\n",
    "\n",
    "    def explanation_from_feature_importance_usage(self, feature_importance_usage, date, diagnostics=False, weather_sel = False):\n",
    "\n",
    "        self.feature_importance_usage= feature_importance_usage\n",
    "        self.diagnostics = diagnostics\n",
    "\n",
    "        if self.X_test_usage['active_last_2_days'] == 0:\n",
    "            active_past = 'not'\n",
    "        else:\n",
    "            active_past = ''\n",
    "\n",
    "        if feature_importance_usage.loc[0, 'feature_importance_vals'] >= 0 or feature_importance_usage.loc[1, 'feature_importance_vals'] >= 0:\n",
    "\n",
    "            FI_lag = np.argmax([feature_importance_usage.loc[0, 'feature_importance_vals'],\n",
    "                                feature_importance_usage.loc[1, 'feature_importance_vals']])\n",
    "\n",
    "            if FI_lag == 0:\n",
    "                device_usage = \"\"\n",
    "                number_days = 'day'\n",
    "            elif FI_lag == 1:\n",
    "                device_usage = \"\"\n",
    "                number_days = 'two days'\n",
    "            else:\n",
    "                device_usage = \" not\"\n",
    "                number_days = 'two days'\n",
    "\n",
    "            part1 = f\" and have{device_usage} used the device in the last {number_days}\"\n",
    "\n",
    "        else:\n",
    "            part1= \"\"\n",
    "\n",
    "        if weather_sel:\n",
    "            # weather:\n",
    "            # need to rewrite that part afterwards, we need different weather data!\n",
    "            weather_daily = pd.read_pickle('../export/weather_unscaled_daily.pkl')\n",
    "\n",
    "            d = {'features': ['dwpt', 'rhum', 'temp', 'wdir', 'wspd'],\n",
    "                 'labels': ['dewing point', 'relative humidity','temperature', 'wind direction', 'windspeed'],\n",
    "                 'feature_importances' : [feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                    'col_name'] == 'dwpt', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                      feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                    'col_name'] == 'rhum', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                      feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                    'col_name'] == 'temp', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                      feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                          'col_name'] == 'wdir', 'feature_importance_vals'].to_numpy()[0],\n",
    "                                      feature_importance_usage.loc[feature_importance_usage[\n",
    "                                                                          'col_name'] == 'wspd', 'feature_importance_vals'].to_numpy()[0]],\n",
    "                 'feature_values': [weather_daily.loc[date].loc['dwpt'],\n",
    "                                    weather_daily.loc[date].loc['rhum'],\n",
    "                                    weather_daily.loc[date].loc['temp'],\n",
    "                                    weather_daily.loc[date].loc['wdir'],\n",
    "                                    weather_daily.loc[date].loc['wspd']\n",
    "                 ]\n",
    "\n",
    "\n",
    "                 }\n",
    "            df = pd.DataFrame(data=d)\n",
    "\n",
    "            sorted_df = df['feature_importances'].sort_values(ascending=False)\n",
    "\n",
    "\n",
    "            if sorted_df.iloc[0] >= 0:\n",
    "                weather1_ind = sorted_df.index[0]\n",
    "                weather1 = df['labels'][weather1_ind]\n",
    "\n",
    "                value1 = round(df['feature_values'][weather1_ind], 2)\n",
    "\n",
    "                part2= f\"The weather condition ({weather1}:{value1}) support that recommendation.\"\n",
    "\n",
    "                if sorted_df.iloc[1] >= 0:\n",
    "\n",
    "                    weather2_ind = sorted_df.index[1]\n",
    "                    weather2 = df['labels'][weather2_ind]\n",
    "\n",
    "                    value2 = round(df['feature_values'][weather2_ind], 2)\n",
    "                    part2 = f\"The weather conditions ({weather1}:{value1}, {weather2}:{value2}) support that recommendation.\"\n",
    "\n",
    "        else:\n",
    "            part2 = \"\"\n",
    "\n",
    "        sentence_usage = f\"We believe you are likely to use the device in the near future since you \" \\\n",
    "                         f\"were {active_past}active during the last 2 days\" + str(part1) + \".\" + str(part2)\n",
    "        explanation_sentence = sentence_usage\n",
    "\n",
    "        return explanation_sentence\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.3px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
