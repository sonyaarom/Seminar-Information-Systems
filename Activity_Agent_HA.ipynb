{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWcGAGgFE_M7"
   },
   "source": [
    "# **Activity Agent**\n",
    "\n",
    "The activity agent will be responsible for predicting the user's activity for a given day. It will produce activity probabilities for the given user and the given day on an hourly level. These hourly activity probabilities will be processed by the subsequent recommendation agent to determine for which hours our framework should make recommendations. As input the activity agent receives the prepared data from the preparation agent.\n",
    "\n",
    "We will define an activity agent class, add necessary functions to the agent, explain each step and build our final activity agent pipeline. A complete activity agent class definition will be available in the appendix to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrrXBEI4s6zc"
   },
   "source": [
    "## **1. Preparing the Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJ4EHWrhW6_m"
   },
   "source": [
    "### **1.1 Loading the Libraries and the Data**\n",
    "\n",
    "Steps to set up the environment for the activity agent include loading the necessary libraries, data and preceding agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 38554,
     "status": "ok",
     "timestamp": 1607622434744,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "VzS_qOg8teXQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "dir = 'D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main'\n",
    "os.chdir(dir)\n",
    "\n",
    "from helper_functions import Helper\n",
    "from agents import Preparation_Agent\n",
    "import pandas as pd\n",
    "\n",
    "helper = Helper()\n",
    "\n",
    "dbfile  = \"D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main/home-assistant_v2.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QisezqyFAt39"
   },
   "source": [
    "### **1.2 Calling the Preparation Agent**\n",
    "\n",
    "To receive the necessary input for the activity agent, we will call the activity pipeline function of the preparation agent. We will specify the input data and the necessary configurations. As a quick validation that the preparation pipeline worked properly, we will plot the hourly activity of the household.\n",
    "\n",
    "The current input data includes only a few time features and activity lags. However, our agent architecture allows to expand the inputs to the activity agent to further features or further data sources (e.g. whether data). For the purpose of demonstrating the functionality of our framework, we only use the inputs from the prepared REFIT data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 50821,
     "status": "ok",
     "timestamp": 1607622447021,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "CP1f_6EvAygB"
   },
   "outputs": [],
   "source": [
    "shiftable_devices = [\"sensor.shellyplug_s_4022d88961b4_power\", \"sensor.shellyplug_s_4022d88984b8_power\"]\n",
    "activity_devices = [\"light.olaf_der_gesundigte\", \"light.blub\", \"light.extended_color_light_1\", \"switch.shellyplug_s_80646f824e22\", \n",
    "                    \"light.bogenleuchte\", \"light.hue_color_candle_1\", \"light.hue_color_candle_2\"]\n",
    "date = '2023-03-19'\n",
    "model_type = 'random forest'\n",
    "number_days = 360\n",
    "\n",
    "truncation_params = {\n",
    "    'features': 'all', \n",
    "    'factor': 1.5, \n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "scale_params = {\n",
    "    'features': 'all', \n",
    "    'kind': 'MinMax', \n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "aggregate_params = {\n",
    "    'resample_param': '60T'\n",
    "}\n",
    "#update with active appliances attributes_ids\n",
    "activity_params = {\n",
    "    'active_appliances': shiftable_devices,\n",
    "    'threshold': 0.01\n",
    "}\n",
    "\n",
    "time_params = {\n",
    "    'features': ['hour', 'day_name']\n",
    "}\n",
    "\n",
    "activity_lag_params = {\n",
    "    'features': ['activity'],\n",
    "    'lags': [24, 48, 72]\n",
    "}\n",
    "\n",
    "activity_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'activity': activity_params,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 50814,
     "status": "ok",
     "timestamp": 1607622447009,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "qCjWp7PIAeSZ"
   },
   "outputs": [],
   "source": [
    "# load household data\n",
    "prep = Preparation_Agent(dbfile, shiftable_devices, activity_devices, number_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 108175,
     "status": "ok",
     "timestamp": 1607622504415,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "NOrSOdufBY5q",
    "outputId": "c00ab194-b017-4105-c8a4-336e8f38820d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-25 18:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 19:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 20:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 21:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 22:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 19:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 20:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 21:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 22:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 23:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     activity  hour  activity_lag_24  activity_lag_48  \\\n",
       "last_updated                                                            \n",
       "2022-12-25 18:00:00         1    18              NaN              NaN   \n",
       "2022-12-25 19:00:00         0    19              NaN              NaN   \n",
       "2022-12-25 20:00:00         0    20              NaN              NaN   \n",
       "2022-12-25 21:00:00         0    21              NaN              NaN   \n",
       "2022-12-25 22:00:00         0    22              NaN              NaN   \n",
       "...                       ...   ...              ...              ...   \n",
       "2023-01-10 19:00:00         0    19              0.0              0.0   \n",
       "2023-01-10 20:00:00         0    20              0.0              0.0   \n",
       "2023-01-10 21:00:00         0    21              0.0              0.0   \n",
       "2023-01-10 22:00:00         0    22              0.0              0.0   \n",
       "2023-01-10 23:00:00         0    23              0.0              0.0   \n",
       "\n",
       "                     activity_lag_72  day_name_Monday  day_name_Saturday  \\\n",
       "last_updated                                                               \n",
       "2022-12-25 18:00:00              NaN                0                  0   \n",
       "2022-12-25 19:00:00              NaN                0                  0   \n",
       "2022-12-25 20:00:00              NaN                0                  0   \n",
       "2022-12-25 21:00:00              NaN                0                  0   \n",
       "2022-12-25 22:00:00              NaN                0                  0   \n",
       "...                              ...              ...                ...   \n",
       "2023-01-10 19:00:00              0.0                0                  0   \n",
       "2023-01-10 20:00:00              0.0                0                  0   \n",
       "2023-01-10 21:00:00              0.0                0                  0   \n",
       "2023-01-10 22:00:00              0.0                0                  0   \n",
       "2023-01-10 23:00:00              0.0                0                  0   \n",
       "\n",
       "                     day_name_Sunday  day_name_Thursday  day_name_Tuesday  \\\n",
       "last_updated                                                                \n",
       "2022-12-25 18:00:00                1                  0                 0   \n",
       "2022-12-25 19:00:00                1                  0                 0   \n",
       "2022-12-25 20:00:00                1                  0                 0   \n",
       "2022-12-25 21:00:00                1                  0                 0   \n",
       "2022-12-25 22:00:00                1                  0                 0   \n",
       "...                              ...                ...               ...   \n",
       "2023-01-10 19:00:00                0                  0                 1   \n",
       "2023-01-10 20:00:00                0                  0                 1   \n",
       "2023-01-10 21:00:00                0                  0                 1   \n",
       "2023-01-10 22:00:00                0                  0                 1   \n",
       "2023-01-10 23:00:00                0                  0                 1   \n",
       "\n",
       "                     day_name_Wednesday  \n",
       "last_updated                             \n",
       "2022-12-25 18:00:00                   0  \n",
       "2022-12-25 19:00:00                   0  \n",
       "2022-12-25 20:00:00                   0  \n",
       "2022-12-25 21:00:00                   0  \n",
       "2022-12-25 22:00:00                   0  \n",
       "...                                 ...  \n",
       "2023-01-10 19:00:00                   0  \n",
       "2023-01-10 20:00:00                   0  \n",
       "2023-01-10 21:00:00                   0  \n",
       "2023-01-10 22:00:00                   0  \n",
       "2023-01-10 23:00:00                   0  \n",
       "\n",
       "[390 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the preparation pipelin\n",
    "import pandas as pd\n",
    "df = prep.pipeline_activity(prep.input, activity_pipe_params)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     activity  hour\n",
      "last_updated                       \n",
      "2022-12-25 18:00:00         1    18\n",
      "2022-12-25 19:00:00         0    19\n",
      "2022-12-25 20:00:00         0    20\n",
      "2022-12-25 21:00:00         0    21\n",
      "2022-12-25 22:00:00         0    22\n",
      "2022-12-25 23:00:00         0    23\n",
      "2022-12-26 00:00:00         0     0\n",
      "2022-12-26 01:00:00         0     1\n",
      "2022-12-26 02:00:00         0     2\n",
      "2022-12-26 03:00:00         0     3\n",
      "2022-12-26 04:00:00         0     4\n",
      "2022-12-26 05:00:00         0     5\n",
      "2022-12-26 06:00:00         0     6\n",
      "2022-12-26 07:00:00         0     7\n",
      "2022-12-26 08:00:00         0     8\n",
      "2022-12-26 09:00:00         0     9\n",
      "2022-12-26 10:00:00         0    10\n",
      "2022-12-26 11:00:00         1    11\n",
      "2022-12-26 12:00:00         1    12\n",
      "2022-12-26 13:00:00         1    13\n",
      "2022-12-26 14:00:00         1    14\n",
      "2022-12-26 15:00:00         1    15\n",
      "2022-12-26 16:00:00         1    16\n",
      "2022-12-26 17:00:00         1    17\n",
      "2022-12-26 18:00:00         1    18\n",
      "2022-12-26 19:00:00         1    19\n",
      "2022-12-26 20:00:00         1    20\n",
      "2022-12-26 21:00:00         1    21\n",
      "2022-12-26 22:00:00         1    22\n",
      "2022-12-26 23:00:00         1    23\n",
      "2022-12-27 00:00:00         1     0\n",
      "2022-12-27 01:00:00         1     1\n",
      "2022-12-27 02:00:00         1     2\n",
      "2022-12-27 03:00:00         1     3\n",
      "2022-12-27 04:00:00         1     4\n",
      "2022-12-27 05:00:00         1     5\n",
      "2022-12-27 06:00:00         1     6\n",
      "2022-12-27 07:00:00         1     7\n",
      "2022-12-27 08:00:00         1     8\n",
      "2022-12-27 09:00:00         1     9\n",
      "2022-12-27 10:00:00         1    10\n",
      "2022-12-27 11:00:00         1    11\n",
      "2022-12-27 12:00:00         1    12\n",
      "2022-12-27 13:00:00         1    13\n",
      "2022-12-27 14:00:00         1    14\n",
      "2022-12-27 15:00:00         0    15\n",
      "2022-12-27 16:00:00         0    16\n",
      "2022-12-27 17:00:00         0    17\n",
      "2022-12-27 18:00:00         0    18\n",
      "2022-12-27 19:00:00         0    19\n",
      "2022-12-27 20:00:00         0    20\n",
      "2022-12-27 21:00:00         0    21\n",
      "2022-12-27 22:00:00         0    22\n",
      "2022-12-27 23:00:00         0    23\n",
      "2022-12-28 00:00:00         0     0\n",
      "2022-12-28 01:00:00         0     1\n",
      "2022-12-28 02:00:00         0     2\n",
      "2022-12-28 03:00:00         0     3\n",
      "2022-12-28 04:00:00         0     4\n",
      "2022-12-28 05:00:00         0     5\n",
      "2022-12-28 06:00:00         0     6\n",
      "2022-12-28 07:00:00         0     7\n",
      "2022-12-28 08:00:00         0     8\n",
      "2022-12-28 09:00:00         0     9\n",
      "2022-12-28 10:00:00         0    10\n",
      "2022-12-28 11:00:00         0    11\n",
      "2022-12-28 12:00:00         0    12\n",
      "2022-12-28 13:00:00         0    13\n",
      "2022-12-28 14:00:00         0    14\n",
      "2022-12-28 15:00:00         0    15\n",
      "2022-12-28 16:00:00         0    16\n",
      "2022-12-28 17:00:00         0    17\n",
      "2022-12-28 18:00:00         0    18\n",
      "2022-12-28 19:00:00         0    19\n",
      "2022-12-28 20:00:00         0    20\n",
      "2022-12-28 21:00:00         0    21\n",
      "2022-12-28 22:00:00         0    22\n",
      "2022-12-28 23:00:00         0    23\n",
      "2022-12-29 00:00:00         0     0\n",
      "2022-12-29 01:00:00         0     1\n",
      "2022-12-29 02:00:00         0     2\n",
      "2022-12-29 03:00:00         0     3\n",
      "2022-12-29 04:00:00         0     4\n",
      "2022-12-29 05:00:00         0     5\n",
      "2022-12-29 06:00:00         0     6\n",
      "2022-12-29 07:00:00         1     7\n",
      "2022-12-29 08:00:00         1     8\n",
      "2022-12-29 09:00:00         1     9\n",
      "2022-12-29 10:00:00         0    10\n",
      "2022-12-29 11:00:00         0    11\n",
      "2022-12-29 12:00:00         0    12\n",
      "2022-12-29 13:00:00         0    13\n",
      "2022-12-29 14:00:00         0    14\n",
      "2022-12-29 15:00:00         0    15\n",
      "2022-12-29 16:00:00         0    16\n",
      "2022-12-29 17:00:00         0    17\n",
      "2022-12-29 18:00:00         0    18\n",
      "2022-12-29 19:00:00         0    19\n",
      "2022-12-29 20:00:00         0    20\n",
      "2022-12-29 21:00:00         0    21\n",
      "2022-12-29 22:00:00         0    22\n",
      "2022-12-29 23:00:00         0    23\n",
      "2022-12-30 00:00:00         0     0\n",
      "2022-12-30 01:00:00         0     1\n",
      "2022-12-30 02:00:00         0     2\n",
      "2022-12-30 03:00:00         0     3\n",
      "2022-12-30 04:00:00         0     4\n",
      "2022-12-30 05:00:00         0     5\n",
      "2022-12-30 06:00:00         0     6\n",
      "2022-12-30 07:00:00         0     7\n",
      "2022-12-30 08:00:00         0     8\n",
      "2022-12-30 09:00:00         0     9\n",
      "2022-12-30 10:00:00         0    10\n",
      "2022-12-30 11:00:00         0    11\n",
      "2022-12-30 12:00:00         0    12\n",
      "2022-12-30 13:00:00         0    13\n",
      "2022-12-30 14:00:00         1    14\n",
      "2022-12-30 15:00:00         1    15\n",
      "2022-12-30 16:00:00         1    16\n",
      "2022-12-30 17:00:00         1    17\n",
      "2022-12-30 18:00:00         1    18\n",
      "2022-12-30 19:00:00         1    19\n",
      "2022-12-30 20:00:00         0    20\n",
      "2022-12-30 21:00:00         0    21\n",
      "2022-12-30 22:00:00         0    22\n",
      "2022-12-30 23:00:00         0    23\n",
      "2022-12-31 00:00:00         0     0\n",
      "2022-12-31 01:00:00         0     1\n",
      "2022-12-31 02:00:00         0     2\n",
      "2022-12-31 03:00:00         0     3\n",
      "2022-12-31 04:00:00         0     4\n",
      "2022-12-31 05:00:00         0     5\n",
      "2022-12-31 06:00:00         0     6\n",
      "2022-12-31 07:00:00         0     7\n",
      "2022-12-31 08:00:00         0     8\n",
      "2022-12-31 09:00:00         0     9\n",
      "2022-12-31 10:00:00         0    10\n",
      "2022-12-31 11:00:00         1    11\n",
      "2022-12-31 12:00:00         1    12\n",
      "2022-12-31 13:00:00         1    13\n",
      "2022-12-31 14:00:00         1    14\n",
      "2022-12-31 15:00:00         0    15\n",
      "2022-12-31 16:00:00         0    16\n",
      "2022-12-31 17:00:00         0    17\n",
      "2022-12-31 18:00:00         0    18\n",
      "2022-12-31 19:00:00         0    19\n",
      "2022-12-31 20:00:00         0    20\n",
      "2022-12-31 21:00:00         0    21\n",
      "2022-12-31 22:00:00         0    22\n",
      "2022-12-31 23:00:00         0    23\n",
      "2023-01-01 00:00:00         0     0\n",
      "2023-01-01 01:00:00         0     1\n",
      "2023-01-01 02:00:00         0     2\n",
      "2023-01-01 03:00:00         0     3\n",
      "2023-01-01 04:00:00         0     4\n",
      "2023-01-01 05:00:00         0     5\n",
      "2023-01-01 06:00:00         0     6\n",
      "2023-01-01 07:00:00         0     7\n",
      "2023-01-01 08:00:00         0     8\n",
      "2023-01-01 09:00:00         0     9\n",
      "2023-01-01 10:00:00         0    10\n",
      "2023-01-01 11:00:00         0    11\n",
      "2023-01-01 12:00:00         0    12\n",
      "2023-01-01 13:00:00         1    13\n",
      "2023-01-01 14:00:00         1    14\n",
      "2023-01-01 15:00:00         1    15\n",
      "2023-01-01 16:00:00         1    16\n",
      "2023-01-01 17:00:00         1    17\n",
      "2023-01-01 18:00:00         1    18\n",
      "2023-01-01 19:00:00         1    19\n",
      "2023-01-01 20:00:00         0    20\n",
      "2023-01-01 21:00:00         0    21\n",
      "2023-01-01 22:00:00         0    22\n",
      "2023-01-01 23:00:00         0    23\n",
      "2023-01-02 00:00:00         0     0\n",
      "2023-01-02 01:00:00         0     1\n",
      "2023-01-02 02:00:00         0     2\n",
      "2023-01-02 03:00:00         0     3\n",
      "2023-01-02 04:00:00         0     4\n",
      "2023-01-02 05:00:00         0     5\n",
      "2023-01-02 06:00:00         0     6\n",
      "2023-01-02 07:00:00         1     7\n",
      "2023-01-02 08:00:00         1     8\n",
      "2023-01-02 09:00:00         0     9\n",
      "2023-01-02 10:00:00         0    10\n",
      "2023-01-02 11:00:00         0    11\n",
      "2023-01-02 12:00:00         0    12\n",
      "2023-01-02 13:00:00         0    13\n",
      "2023-01-02 14:00:00         0    14\n",
      "2023-01-02 15:00:00         0    15\n",
      "2023-01-02 16:00:00         0    16\n",
      "2023-01-02 17:00:00         0    17\n",
      "2023-01-02 18:00:00         0    18\n",
      "2023-01-02 19:00:00         0    19\n",
      "2023-01-02 20:00:00         0    20\n",
      "2023-01-02 21:00:00         0    21\n",
      "2023-01-02 22:00:00         0    22\n",
      "2023-01-02 23:00:00         0    23\n",
      "2023-01-03 00:00:00         0     0\n",
      "2023-01-03 01:00:00         0     1\n",
      "2023-01-03 02:00:00         0     2\n",
      "2023-01-03 03:00:00         0     3\n",
      "2023-01-03 04:00:00         0     4\n",
      "2023-01-03 05:00:00         0     5\n",
      "2023-01-03 06:00:00         0     6\n",
      "2023-01-03 07:00:00         0     7\n",
      "2023-01-03 08:00:00         0     8\n",
      "2023-01-03 09:00:00         0     9\n",
      "2023-01-03 10:00:00         0    10\n",
      "2023-01-03 11:00:00         0    11\n",
      "2023-01-03 12:00:00         0    12\n",
      "2023-01-03 13:00:00         0    13\n",
      "2023-01-03 14:00:00         0    14\n",
      "2023-01-03 15:00:00         0    15\n",
      "2023-01-03 16:00:00         0    16\n",
      "2023-01-03 17:00:00         0    17\n",
      "2023-01-03 18:00:00         0    18\n",
      "2023-01-03 19:00:00         0    19\n",
      "2023-01-03 20:00:00         0    20\n",
      "2023-01-03 21:00:00         0    21\n",
      "2023-01-03 22:00:00         0    22\n",
      "2023-01-03 23:00:00         0    23\n",
      "2023-01-04 00:00:00         0     0\n",
      "2023-01-04 01:00:00         0     1\n",
      "2023-01-04 02:00:00         0     2\n",
      "2023-01-04 03:00:00         0     3\n",
      "2023-01-04 04:00:00         0     4\n",
      "2023-01-04 05:00:00         0     5\n",
      "2023-01-04 06:00:00         0     6\n",
      "2023-01-04 07:00:00         0     7\n",
      "2023-01-04 08:00:00         0     8\n",
      "2023-01-04 09:00:00         0     9\n",
      "2023-01-04 10:00:00         0    10\n",
      "2023-01-04 11:00:00         0    11\n",
      "2023-01-04 12:00:00         0    12\n",
      "2023-01-04 13:00:00         0    13\n",
      "2023-01-04 14:00:00         0    14\n",
      "2023-01-04 15:00:00         0    15\n",
      "2023-01-04 16:00:00         0    16\n",
      "2023-01-04 17:00:00         0    17\n",
      "2023-01-04 18:00:00         0    18\n",
      "2023-01-04 19:00:00         0    19\n",
      "2023-01-04 20:00:00         0    20\n",
      "2023-01-04 21:00:00         0    21\n",
      "2023-01-04 22:00:00         0    22\n",
      "2023-01-04 23:00:00         0    23\n",
      "2023-01-05 00:00:00         0     0\n",
      "2023-01-05 01:00:00         0     1\n",
      "2023-01-05 02:00:00         0     2\n",
      "2023-01-05 03:00:00         0     3\n",
      "2023-01-05 04:00:00         0     4\n",
      "2023-01-05 05:00:00         0     5\n",
      "2023-01-05 06:00:00         0     6\n",
      "2023-01-05 07:00:00         0     7\n",
      "2023-01-05 08:00:00         0     8\n",
      "2023-01-05 09:00:00         0     9\n",
      "2023-01-05 10:00:00         0    10\n",
      "2023-01-05 11:00:00         0    11\n",
      "2023-01-05 12:00:00         0    12\n",
      "2023-01-05 13:00:00         0    13\n",
      "2023-01-05 14:00:00         0    14\n",
      "2023-01-05 15:00:00         0    15\n",
      "2023-01-05 16:00:00         0    16\n",
      "2023-01-05 17:00:00         0    17\n",
      "2023-01-05 18:00:00         0    18\n",
      "2023-01-05 19:00:00         0    19\n",
      "2023-01-05 20:00:00         0    20\n",
      "2023-01-05 21:00:00         0    21\n",
      "2023-01-05 22:00:00         0    22\n",
      "2023-01-05 23:00:00         0    23\n",
      "2023-01-06 00:00:00         0     0\n",
      "2023-01-06 01:00:00         0     1\n",
      "2023-01-06 02:00:00         0     2\n",
      "2023-01-06 03:00:00         0     3\n",
      "2023-01-06 04:00:00         0     4\n",
      "2023-01-06 05:00:00         0     5\n",
      "2023-01-06 06:00:00         0     6\n",
      "2023-01-06 07:00:00         0     7\n",
      "2023-01-06 08:00:00         0     8\n",
      "2023-01-06 09:00:00         0     9\n",
      "2023-01-06 10:00:00         0    10\n",
      "2023-01-06 11:00:00         0    11\n",
      "2023-01-06 12:00:00         0    12\n",
      "2023-01-06 13:00:00         0    13\n",
      "2023-01-06 14:00:00         0    14\n",
      "2023-01-06 15:00:00         0    15\n",
      "2023-01-06 16:00:00         0    16\n",
      "2023-01-06 17:00:00         1    17\n",
      "2023-01-06 18:00:00         1    18\n",
      "2023-01-06 19:00:00         1    19\n",
      "2023-01-06 20:00:00         1    20\n",
      "2023-01-06 21:00:00         0    21\n",
      "2023-01-06 22:00:00         0    22\n",
      "2023-01-06 23:00:00         0    23\n",
      "2023-01-07 00:00:00         0     0\n",
      "2023-01-07 01:00:00         0     1\n",
      "2023-01-07 02:00:00         0     2\n",
      "2023-01-07 03:00:00         0     3\n",
      "2023-01-07 04:00:00         0     4\n",
      "2023-01-07 05:00:00         0     5\n",
      "2023-01-07 06:00:00         0     6\n",
      "2023-01-07 07:00:00         0     7\n",
      "2023-01-07 08:00:00         0     8\n",
      "2023-01-07 09:00:00         0     9\n",
      "2023-01-07 10:00:00         0    10\n",
      "2023-01-07 11:00:00         0    11\n",
      "2023-01-07 12:00:00         0    12\n",
      "2023-01-07 13:00:00         0    13\n",
      "2023-01-07 14:00:00         0    14\n",
      "2023-01-07 15:00:00         0    15\n",
      "2023-01-07 16:00:00         0    16\n",
      "2023-01-07 17:00:00         0    17\n",
      "2023-01-07 18:00:00         0    18\n",
      "2023-01-07 19:00:00         0    19\n",
      "2023-01-07 20:00:00         0    20\n",
      "2023-01-07 21:00:00         0    21\n",
      "2023-01-07 22:00:00         0    22\n",
      "2023-01-07 23:00:00         0    23\n",
      "2023-01-08 00:00:00         0     0\n",
      "2023-01-08 01:00:00         0     1\n",
      "2023-01-08 02:00:00         0     2\n",
      "2023-01-08 03:00:00         0     3\n",
      "2023-01-08 04:00:00         0     4\n",
      "2023-01-08 05:00:00         0     5\n",
      "2023-01-08 06:00:00         0     6\n",
      "2023-01-08 07:00:00         0     7\n",
      "2023-01-08 08:00:00         0     8\n",
      "2023-01-08 09:00:00         0     9\n",
      "2023-01-08 10:00:00         0    10\n",
      "2023-01-08 11:00:00         0    11\n",
      "2023-01-08 12:00:00         0    12\n",
      "2023-01-08 13:00:00         0    13\n",
      "2023-01-08 14:00:00         0    14\n",
      "2023-01-08 15:00:00         0    15\n",
      "2023-01-08 16:00:00         1    16\n",
      "2023-01-08 17:00:00         1    17\n",
      "2023-01-08 18:00:00         1    18\n",
      "2023-01-08 19:00:00         0    19\n",
      "2023-01-08 20:00:00         0    20\n",
      "2023-01-08 21:00:00         0    21\n",
      "2023-01-08 22:00:00         0    22\n",
      "2023-01-08 23:00:00         0    23\n",
      "2023-01-09 00:00:00         0     0\n",
      "2023-01-09 01:00:00         0     1\n",
      "2023-01-09 02:00:00         0     2\n",
      "2023-01-09 03:00:00         0     3\n",
      "2023-01-09 04:00:00         0     4\n",
      "2023-01-09 05:00:00         0     5\n",
      "2023-01-09 06:00:00         0     6\n",
      "2023-01-09 07:00:00         0     7\n",
      "2023-01-09 08:00:00         0     8\n",
      "2023-01-09 09:00:00         1     9\n",
      "2023-01-09 10:00:00         1    10\n",
      "2023-01-09 11:00:00         0    11\n",
      "2023-01-09 12:00:00         0    12\n",
      "2023-01-09 13:00:00         0    13\n",
      "2023-01-09 14:00:00         0    14\n",
      "2023-01-09 15:00:00         0    15\n",
      "2023-01-09 16:00:00         0    16\n",
      "2023-01-09 17:00:00         0    17\n",
      "2023-01-09 18:00:00         0    18\n",
      "2023-01-09 19:00:00         0    19\n",
      "2023-01-09 20:00:00         0    20\n",
      "2023-01-09 21:00:00         0    21\n",
      "2023-01-09 22:00:00         0    22\n",
      "2023-01-09 23:00:00         0    23\n",
      "2023-01-10 00:00:00         0     0\n",
      "2023-01-10 01:00:00         0     1\n",
      "2023-01-10 02:00:00         0     2\n",
      "2023-01-10 03:00:00         0     3\n",
      "2023-01-10 04:00:00         0     4\n",
      "2023-01-10 05:00:00         0     5\n",
      "2023-01-10 06:00:00         0     6\n",
      "2023-01-10 07:00:00         0     7\n",
      "2023-01-10 08:00:00         0     8\n",
      "2023-01-10 09:00:00         0     9\n",
      "2023-01-10 10:00:00         0    10\n",
      "2023-01-10 11:00:00         0    11\n",
      "2023-01-10 12:00:00         0    12\n",
      "2023-01-10 13:00:00         0    13\n",
      "2023-01-10 14:00:00         0    14\n",
      "2023-01-10 15:00:00         0    15\n",
      "2023-01-10 16:00:00         0    16\n",
      "2023-01-10 17:00:00         0    17\n",
      "2023-01-10 18:00:00         0    18\n",
      "2023-01-10 19:00:00         0    19\n",
      "2023-01-10 20:00:00         0    20\n",
      "2023-01-10 21:00:00         0    21\n",
      "2023-01-10 22:00:00         0    22\n",
      "2023-01-10 23:00:00         0    23\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df[[\"activity\",\"hour\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 108144,
     "status": "ok",
     "timestamp": 1607622504422,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "XMEj_9y2CnVv",
    "outputId": "28c159c0-4117-4647-df05-a6ed797ee05a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.groupby(by='hour').mean()['activity'].plot();\n",
    "plt.title('Average hourly activity')\n",
    "plt.ylim(-0.1, 1.1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1CTQIKBDCXO"
   },
   "source": [
    "## **2. Creating the Activity Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 108144,
     "status": "ok",
     "timestamp": 1607622504425,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "rK6ASFf4DFso"
   },
   "outputs": [],
   "source": [
    "class Activity_Agent:\n",
    "\n",
    "    def __init__(self, activity_input_df):\n",
    "        self.input = activity_input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZumht1rEkBL"
   },
   "source": [
    "### **2.1 Train Test Split**\n",
    "\n",
    "As our recommendation framework will provide recommendations for a given day, our activity agent must be able to provide activity predictions for each day. However, for each day to be predicted we are only allowed to use information from the past to prevent leakage. Therefore, we will create a custom train test split function to meet the time series requirements. \n",
    "\n",
    "Our train test split function will enable us to conveniently split our data in the train and test data sets for each day to be predicted while allowing for further configurations of the split (i.e. size of the train and test data sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqWrmBl6NZi0"
   },
   "source": [
    "**X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 108140,
     "status": "ok",
     "timestamp": 1607622504427,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "DriEbbpvNbmH"
   },
   "outputs": [],
   "source": [
    "def get_Xtest(self, df, date, time_delta='all', target='activity'):\n",
    "    import pandas as pd\n",
    "    from helper_functions import Helper\n",
    "\n",
    "    helper = Helper()\n",
    "    \n",
    "    tomorrow = (pd.to_datetime(date) + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if time_delta == 'all':\n",
    "        output = df.loc[pd.to_datetime(tomorrow):, df.columns != target]\n",
    "    else:\n",
    "        df = helper.get_timespan(df, tomorrow, time_delta)\n",
    "        output = df.loc[:, df.columns != target]\n",
    "    return output\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'get_Xtest', get_Xtest)\n",
    "del get_Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 108103,
     "status": "ok",
     "timestamp": 1607622504428,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "qt9snGWeNtV9",
    "outputId": "438200f4-cc4d-4cb6-b5c2-03f92c44ac41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-08 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2023-01-08 00:00:00     0              0.0              0.0              0.0   \n",
       "2023-01-08 01:00:00     1              0.0              0.0              0.0   \n",
       "2023-01-08 02:00:00     2              0.0              0.0              0.0   \n",
       "2023-01-08 03:00:00     3              0.0              0.0              0.0   \n",
       "2023-01-08 04:00:00     4              0.0              0.0              0.0   \n",
       "...                   ...              ...              ...              ...   \n",
       "2023-01-10 19:00:00    19              0.0              0.0              0.0   \n",
       "2023-01-10 20:00:00    20              0.0              0.0              0.0   \n",
       "2023-01-10 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-10 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-10 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2023-01-08 00:00:00                0                  0                1   \n",
       "2023-01-08 01:00:00                0                  0                1   \n",
       "2023-01-08 02:00:00                0                  0                1   \n",
       "2023-01-08 03:00:00                0                  0                1   \n",
       "2023-01-08 04:00:00                0                  0                1   \n",
       "...                              ...                ...              ...   \n",
       "2023-01-10 19:00:00                0                  0                0   \n",
       "2023-01-10 20:00:00                0                  0                0   \n",
       "2023-01-10 21:00:00                0                  0                0   \n",
       "2023-01-10 22:00:00                0                  0                0   \n",
       "2023-01-10 23:00:00                0                  0                0   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2023-01-08 00:00:00                  0                 0                   0  \n",
       "2023-01-08 01:00:00                  0                 0                   0  \n",
       "2023-01-08 02:00:00                  0                 0                   0  \n",
       "2023-01-08 03:00:00                  0                 0                   0  \n",
       "2023-01-08 04:00:00                  0                 0                   0  \n",
       "...                                ...               ...                 ...  \n",
       "2023-01-10 19:00:00                  0                 1                   0  \n",
       "2023-01-10 20:00:00                  0                 1                   0  \n",
       "2023-01-10 21:00:00                  0                 1                   0  \n",
       "2023-01-10 22:00:00                  0                 1                   0  \n",
       "2023-01-10 23:00:00                  0                 1                   0  \n",
       "\n",
       "[72 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "X_test = activity.get_Xtest(df, date)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 108073,
     "status": "ok",
     "timestamp": 1607622504434,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "UtZ9wkb_GTcS",
    "outputId": "501b3dd6-e182-4fd1-fbf9-b01327d88457"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-08 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 05:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 06:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 07:00:00</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 08:00:00</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 09:00:00</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 10:00:00</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 11:00:00</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 12:00:00</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 13:00:00</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 14:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 15:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 16:00:00</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 17:00:00</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 18:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2023-01-08 00:00:00     0              0.0              0.0              0.0   \n",
       "2023-01-08 01:00:00     1              0.0              0.0              0.0   \n",
       "2023-01-08 02:00:00     2              0.0              0.0              0.0   \n",
       "2023-01-08 03:00:00     3              0.0              0.0              0.0   \n",
       "2023-01-08 04:00:00     4              0.0              0.0              0.0   \n",
       "2023-01-08 05:00:00     5              0.0              0.0              0.0   \n",
       "2023-01-08 06:00:00     6              0.0              0.0              0.0   \n",
       "2023-01-08 07:00:00     7              0.0              0.0              0.0   \n",
       "2023-01-08 08:00:00     8              0.0              0.0              0.0   \n",
       "2023-01-08 09:00:00     9              0.0              0.0              0.0   \n",
       "2023-01-08 10:00:00    10              0.0              0.0              0.0   \n",
       "2023-01-08 11:00:00    11              0.0              0.0              0.0   \n",
       "2023-01-08 12:00:00    12              0.0              0.0              0.0   \n",
       "2023-01-08 13:00:00    13              0.0              0.0              0.0   \n",
       "2023-01-08 14:00:00    14              0.0              0.0              0.0   \n",
       "2023-01-08 15:00:00    15              0.0              0.0              0.0   \n",
       "2023-01-08 16:00:00    16              0.0              0.0              0.0   \n",
       "2023-01-08 17:00:00    17              0.0              1.0              0.0   \n",
       "2023-01-08 18:00:00    18              0.0              1.0              0.0   \n",
       "2023-01-08 19:00:00    19              0.0              1.0              0.0   \n",
       "2023-01-08 20:00:00    20              0.0              1.0              0.0   \n",
       "2023-01-08 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-08 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-08 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2023-01-08 00:00:00                0                  0                1   \n",
       "2023-01-08 01:00:00                0                  0                1   \n",
       "2023-01-08 02:00:00                0                  0                1   \n",
       "2023-01-08 03:00:00                0                  0                1   \n",
       "2023-01-08 04:00:00                0                  0                1   \n",
       "2023-01-08 05:00:00                0                  0                1   \n",
       "2023-01-08 06:00:00                0                  0                1   \n",
       "2023-01-08 07:00:00                0                  0                1   \n",
       "2023-01-08 08:00:00                0                  0                1   \n",
       "2023-01-08 09:00:00                0                  0                1   \n",
       "2023-01-08 10:00:00                0                  0                1   \n",
       "2023-01-08 11:00:00                0                  0                1   \n",
       "2023-01-08 12:00:00                0                  0                1   \n",
       "2023-01-08 13:00:00                0                  0                1   \n",
       "2023-01-08 14:00:00                0                  0                1   \n",
       "2023-01-08 15:00:00                0                  0                1   \n",
       "2023-01-08 16:00:00                0                  0                1   \n",
       "2023-01-08 17:00:00                0                  0                1   \n",
       "2023-01-08 18:00:00                0                  0                1   \n",
       "2023-01-08 19:00:00                0                  0                1   \n",
       "2023-01-08 20:00:00                0                  0                1   \n",
       "2023-01-08 21:00:00                0                  0                1   \n",
       "2023-01-08 22:00:00                0                  0                1   \n",
       "2023-01-08 23:00:00                0                  0                1   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2023-01-08 00:00:00                  0                 0                   0  \n",
       "2023-01-08 01:00:00                  0                 0                   0  \n",
       "2023-01-08 02:00:00                  0                 0                   0  \n",
       "2023-01-08 03:00:00                  0                 0                   0  \n",
       "2023-01-08 04:00:00                  0                 0                   0  \n",
       "2023-01-08 05:00:00                  0                 0                   0  \n",
       "2023-01-08 06:00:00                  0                 0                   0  \n",
       "2023-01-08 07:00:00                  0                 0                   0  \n",
       "2023-01-08 08:00:00                  0                 0                   0  \n",
       "2023-01-08 09:00:00                  0                 0                   0  \n",
       "2023-01-08 10:00:00                  0                 0                   0  \n",
       "2023-01-08 11:00:00                  0                 0                   0  \n",
       "2023-01-08 12:00:00                  0                 0                   0  \n",
       "2023-01-08 13:00:00                  0                 0                   0  \n",
       "2023-01-08 14:00:00                  0                 0                   0  \n",
       "2023-01-08 15:00:00                  0                 0                   0  \n",
       "2023-01-08 16:00:00                  0                 0                   0  \n",
       "2023-01-08 17:00:00                  0                 0                   0  \n",
       "2023-01-08 18:00:00                  0                 0                   0  \n",
       "2023-01-08 19:00:00                  0                 0                   0  \n",
       "2023-01-08 20:00:00                  0                 0                   0  \n",
       "2023-01-08 21:00:00                  0                 0                   0  \n",
       "2023-01-08 22:00:00                  0                 0                   0  \n",
       "2023-01-08 23:00:00                  0                 0                   0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "time_delta = {'days': 1, 'seconds': -1}\n",
    "X_test = activity.get_Xtest(df, date, time_delta=time_delta)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 109187,
     "status": "ok",
     "timestamp": 1607622505587,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "NrVhitY0ISQU",
    "outputId": "203e7bf7-d66b-481c-c18f-71d3094aabeb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-08 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2023-01-08 00:00:00     0              0.0              0.0              0.0   \n",
       "2023-01-08 01:00:00     1              0.0              0.0              0.0   \n",
       "2023-01-08 02:00:00     2              0.0              0.0              0.0   \n",
       "2023-01-08 03:00:00     3              0.0              0.0              0.0   \n",
       "2023-01-08 04:00:00     4              0.0              0.0              0.0   \n",
       "...                   ...              ...              ...              ...   \n",
       "2023-01-10 19:00:00    19              0.0              0.0              0.0   \n",
       "2023-01-10 20:00:00    20              0.0              0.0              0.0   \n",
       "2023-01-10 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-10 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-10 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2023-01-08 00:00:00                0                  0                1   \n",
       "2023-01-08 01:00:00                0                  0                1   \n",
       "2023-01-08 02:00:00                0                  0                1   \n",
       "2023-01-08 03:00:00                0                  0                1   \n",
       "2023-01-08 04:00:00                0                  0                1   \n",
       "...                              ...                ...              ...   \n",
       "2023-01-10 19:00:00                0                  0                0   \n",
       "2023-01-10 20:00:00                0                  0                0   \n",
       "2023-01-10 21:00:00                0                  0                0   \n",
       "2023-01-10 22:00:00                0                  0                0   \n",
       "2023-01-10 23:00:00                0                  0                0   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2023-01-08 00:00:00                  0                 0                   0  \n",
       "2023-01-08 01:00:00                  0                 0                   0  \n",
       "2023-01-08 02:00:00                  0                 0                   0  \n",
       "2023-01-08 03:00:00                  0                 0                   0  \n",
       "2023-01-08 04:00:00                  0                 0                   0  \n",
       "...                                ...               ...                 ...  \n",
       "2023-01-10 19:00:00                  0                 1                   0  \n",
       "2023-01-10 20:00:00                  0                 1                   0  \n",
       "2023-01-10 21:00:00                  0                 1                   0  \n",
       "2023-01-10 22:00:00                  0                 1                   0  \n",
       "2023-01-10 23:00:00                  0                 1                   0  \n",
       "\n",
       "[72 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "time_delta = {'days': 30, 'seconds': -1}\n",
    "X_test = activity.get_Xtest(df, date, time_delta=time_delta)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVjq9VF-LUI8"
   },
   "source": [
    "**y_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 109183,
     "status": "ok",
     "timestamp": 1607622505588,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "5PaQ0TOdJ5_m"
   },
   "outputs": [],
   "source": [
    "def get_ytest(self, df, date, time_delta='all', target='activity'):\n",
    "    import pandas as pd\n",
    "    from helper_functions import Helper\n",
    "\n",
    "    helper = Helper()\n",
    "    \n",
    "    tomorrow = (pd.to_datetime(date) + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if time_delta == 'all':\n",
    "        output = df.loc[pd.to_datetime(tomorrow):, target]\n",
    "    else:\n",
    "        output = helper.get_timespan(df, tomorrow, time_delta)[target]\n",
    "    return output\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'get_ytest', get_ytest)\n",
    "del get_ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109153,
     "status": "ok",
     "timestamp": 1607622505591,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "INl50_xGLFTK",
    "outputId": "9272ce37-41b8-40ce-952f-3aee8d411b22",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2023-01-08 00:00:00    0\n",
       "2023-01-08 01:00:00    0\n",
       "2023-01-08 02:00:00    0\n",
       "2023-01-08 03:00:00    0\n",
       "2023-01-08 04:00:00    0\n",
       "                      ..\n",
       "2023-01-10 19:00:00    0\n",
       "2023-01-10 20:00:00    0\n",
       "2023-01-10 21:00:00    0\n",
       "2023-01-10 22:00:00    0\n",
       "2023-01-10 23:00:00    0\n",
       "Name: activity, Length: 72, dtype: int32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "y_test = activity.get_ytest(df, date)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109123,
     "status": "ok",
     "timestamp": 1607622505594,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "mAyHkoLVJAau",
    "outputId": "6e4e698d-d03a-4c92-b58b-6a1452b0d9ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2023-01-08 00:00:00    0\n",
       "2023-01-08 01:00:00    0\n",
       "2023-01-08 02:00:00    0\n",
       "2023-01-08 03:00:00    0\n",
       "2023-01-08 04:00:00    0\n",
       "                      ..\n",
       "2023-01-10 19:00:00    0\n",
       "2023-01-10 20:00:00    0\n",
       "2023-01-10 21:00:00    0\n",
       "2023-01-10 22:00:00    0\n",
       "2023-01-10 23:00:00    0\n",
       "Name: activity, Length: 72, dtype: int32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "time_delta = {'days': 7, 'seconds': -1}\n",
    "\n",
    "y_test = activity.get_ytest(df, date, time_delta=time_delta)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmS0_1n8LW7o"
   },
   "source": [
    "**X_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 109122,
     "status": "ok",
     "timestamp": 1607622505598,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "TXxe0UmALiLu"
   },
   "outputs": [],
   "source": [
    "# start = int (e.g. -100) --> 100 days before the day to be predicted will represent the train data\n",
    "def get_Xtrain(self, df, date, start=-30, target='activity'):\n",
    "    import pandas as pd\n",
    "\n",
    "    if type(start) == int:\n",
    "        start = pd.to_datetime(date) + pd.Timedelta(days= start)\n",
    "        start = pd.to_datetime('2013-11-01') if start < pd.to_datetime('2013-11-01') else start\n",
    "    else:\n",
    "        start = pd.to_datetime(start)\n",
    "\n",
    "    return df.loc[start:date, df.columns != target]\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'get_Xtrain', get_Xtrain)\n",
    "del get_Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 109092,
     "status": "ok",
     "timestamp": 1607622505600,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "boF5_S0DNCMD",
    "outputId": "5d4727d0-e616-42c0-cb41-ee94d51f47c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-25 18:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2022-12-25 18:00:00    18              NaN              NaN              NaN   \n",
       "2022-12-25 19:00:00    19              NaN              NaN              NaN   \n",
       "2022-12-25 20:00:00    20              NaN              NaN              NaN   \n",
       "2022-12-25 21:00:00    21              NaN              NaN              NaN   \n",
       "2022-12-25 22:00:00    22              NaN              NaN              NaN   \n",
       "...                   ...              ...              ...              ...   \n",
       "2023-01-07 19:00:00    19              1.0              0.0              0.0   \n",
       "2023-01-07 20:00:00    20              1.0              0.0              0.0   \n",
       "2023-01-07 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-07 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-07 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2022-12-25 18:00:00                0                  0                1   \n",
       "2022-12-25 19:00:00                0                  0                1   \n",
       "2022-12-25 20:00:00                0                  0                1   \n",
       "2022-12-25 21:00:00                0                  0                1   \n",
       "2022-12-25 22:00:00                0                  0                1   \n",
       "...                              ...                ...              ...   \n",
       "2023-01-07 19:00:00                0                  1                0   \n",
       "2023-01-07 20:00:00                0                  1                0   \n",
       "2023-01-07 21:00:00                0                  1                0   \n",
       "2023-01-07 22:00:00                0                  1                0   \n",
       "2023-01-07 23:00:00                0                  1                0   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2022-12-25 18:00:00                  0                 0                   0  \n",
       "2022-12-25 19:00:00                  0                 0                   0  \n",
       "2022-12-25 20:00:00                  0                 0                   0  \n",
       "2022-12-25 21:00:00                  0                 0                   0  \n",
       "2022-12-25 22:00:00                  0                 0                   0  \n",
       "...                                ...               ...                 ...  \n",
       "2023-01-07 19:00:00                  0                 0                   0  \n",
       "2023-01-07 20:00:00                  0                 0                   0  \n",
       "2023-01-07 21:00:00                  0                 0                   0  \n",
       "2023-01-07 22:00:00                  0                 0                   0  \n",
       "2023-01-07 23:00:00                  0                 0                   0  \n",
       "\n",
       "[318 rows x 10 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "X_train = activity.get_Xtrain(df, date)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 109044,
     "status": "ok",
     "timestamp": 1607622505603,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "wSxGrNSYMh7_",
    "outputId": "1fdd832c-5fe4-4969-ce51-5212aec822be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-05 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2023-01-05 00:00:00     0              0.0              0.0              0.0   \n",
       "2023-01-05 01:00:00     1              0.0              0.0              0.0   \n",
       "2023-01-05 02:00:00     2              0.0              0.0              0.0   \n",
       "2023-01-05 03:00:00     3              0.0              0.0              0.0   \n",
       "2023-01-05 04:00:00     4              0.0              0.0              0.0   \n",
       "...                   ...              ...              ...              ...   \n",
       "2023-01-07 19:00:00    19              1.0              0.0              0.0   \n",
       "2023-01-07 20:00:00    20              1.0              0.0              0.0   \n",
       "2023-01-07 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-07 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-07 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2023-01-05 00:00:00                0                  0                0   \n",
       "2023-01-05 01:00:00                0                  0                0   \n",
       "2023-01-05 02:00:00                0                  0                0   \n",
       "2023-01-05 03:00:00                0                  0                0   \n",
       "2023-01-05 04:00:00                0                  0                0   \n",
       "...                              ...                ...              ...   \n",
       "2023-01-07 19:00:00                0                  1                0   \n",
       "2023-01-07 20:00:00                0                  1                0   \n",
       "2023-01-07 21:00:00                0                  1                0   \n",
       "2023-01-07 22:00:00                0                  1                0   \n",
       "2023-01-07 23:00:00                0                  1                0   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2023-01-05 00:00:00                  1                 0                   0  \n",
       "2023-01-05 01:00:00                  1                 0                   0  \n",
       "2023-01-05 02:00:00                  1                 0                   0  \n",
       "2023-01-05 03:00:00                  1                 0                   0  \n",
       "2023-01-05 04:00:00                  1                 0                   0  \n",
       "...                                ...               ...                 ...  \n",
       "2023-01-07 19:00:00                  0                 0                   0  \n",
       "2023-01-07 20:00:00                  0                 0                   0  \n",
       "2023-01-07 21:00:00                  0                 0                   0  \n",
       "2023-01-07 22:00:00                  0                 0                   0  \n",
       "2023-01-07 23:00:00                  0                 0                   0  \n",
       "\n",
       "[72 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "X_train = activity.get_Xtrain(df, date, start=-2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 109012,
     "status": "ok",
     "timestamp": 1607622505604,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "kI_JHuGiMxLG",
    "outputId": "47991d9a-44c5-491f-c19c-5a9142ef088f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-28 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2022-12-28 00:00:00     0              1.0              0.0              NaN   \n",
       "2022-12-28 01:00:00     1              1.0              0.0              NaN   \n",
       "2022-12-28 02:00:00     2              1.0              0.0              NaN   \n",
       "2022-12-28 03:00:00     3              1.0              0.0              NaN   \n",
       "2022-12-28 04:00:00     4              1.0              0.0              NaN   \n",
       "...                   ...              ...              ...              ...   \n",
       "2023-01-07 19:00:00    19              1.0              0.0              0.0   \n",
       "2023-01-07 20:00:00    20              1.0              0.0              0.0   \n",
       "2023-01-07 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-07 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-07 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2022-12-28 00:00:00                0                  0                0   \n",
       "2022-12-28 01:00:00                0                  0                0   \n",
       "2022-12-28 02:00:00                0                  0                0   \n",
       "2022-12-28 03:00:00                0                  0                0   \n",
       "2022-12-28 04:00:00                0                  0                0   \n",
       "...                              ...                ...              ...   \n",
       "2023-01-07 19:00:00                0                  1                0   \n",
       "2023-01-07 20:00:00                0                  1                0   \n",
       "2023-01-07 21:00:00                0                  1                0   \n",
       "2023-01-07 22:00:00                0                  1                0   \n",
       "2023-01-07 23:00:00                0                  1                0   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2022-12-28 00:00:00                  0                 0                   1  \n",
       "2022-12-28 01:00:00                  0                 0                   1  \n",
       "2022-12-28 02:00:00                  0                 0                   1  \n",
       "2022-12-28 03:00:00                  0                 0                   1  \n",
       "2022-12-28 04:00:00                  0                 0                   1  \n",
       "...                                ...               ...                 ...  \n",
       "2023-01-07 19:00:00                  0                 0                   0  \n",
       "2023-01-07 20:00:00                  0                 0                   0  \n",
       "2023-01-07 21:00:00                  0                 0                   0  \n",
       "2023-01-07 22:00:00                  0                 0                   0  \n",
       "2023-01-07 23:00:00                  0                 0                   0  \n",
       "\n",
       "[264 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "X_train = activity.get_Xtrain(df, date, start=-10)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 108976,
     "status": "ok",
     "timestamp": 1607622505605,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "KRGWJrZGMzUr",
    "outputId": "b1b0caea-16f4-4c0c-8b9f-59bbe3fbf78b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-28 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2022-12-28 00:00:00     0              1.0              0.0              NaN   \n",
       "2022-12-28 01:00:00     1              1.0              0.0              NaN   \n",
       "2022-12-28 02:00:00     2              1.0              0.0              NaN   \n",
       "2022-12-28 03:00:00     3              1.0              0.0              NaN   \n",
       "2022-12-28 04:00:00     4              1.0              0.0              NaN   \n",
       "...                   ...              ...              ...              ...   \n",
       "2023-01-07 19:00:00    19              1.0              0.0              0.0   \n",
       "2023-01-07 20:00:00    20              1.0              0.0              0.0   \n",
       "2023-01-07 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-07 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-07 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2022-12-28 00:00:00                0                  0                0   \n",
       "2022-12-28 01:00:00                0                  0                0   \n",
       "2022-12-28 02:00:00                0                  0                0   \n",
       "2022-12-28 03:00:00                0                  0                0   \n",
       "2022-12-28 04:00:00                0                  0                0   \n",
       "...                              ...                ...              ...   \n",
       "2023-01-07 19:00:00                0                  1                0   \n",
       "2023-01-07 20:00:00                0                  1                0   \n",
       "2023-01-07 21:00:00                0                  1                0   \n",
       "2023-01-07 22:00:00                0                  1                0   \n",
       "2023-01-07 23:00:00                0                  1                0   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2022-12-28 00:00:00                  0                 0                   1  \n",
       "2022-12-28 01:00:00                  0                 0                   1  \n",
       "2022-12-28 02:00:00                  0                 0                   1  \n",
       "2022-12-28 03:00:00                  0                 0                   1  \n",
       "2022-12-28 04:00:00                  0                 0                   1  \n",
       "...                                ...               ...                 ...  \n",
       "2023-01-07 19:00:00                  0                 0                   0  \n",
       "2023-01-07 20:00:00                  0                 0                   0  \n",
       "2023-01-07 21:00:00                  0                 0                   0  \n",
       "2023-01-07 22:00:00                  0                 0                   0  \n",
       "2023-01-07 23:00:00                  0                 0                   0  \n",
       "\n",
       "[264 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "X_train = activity.get_Xtrain(df, date, start=-10)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzgBu1-uOMwr"
   },
   "source": [
    "**y_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 108973,
     "status": "ok",
     "timestamp": 1607622505606,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "4w-fM1QROPQG"
   },
   "outputs": [],
   "source": [
    "def get_ytrain(self, df, date, start=-30, target='activity'):\n",
    "    import pandas as pd\n",
    "\n",
    "    if type(start) == int:\n",
    "        start = pd.to_datetime(date) + pd.Timedelta(days= start)\n",
    "        start = pd.to_datetime('2022-11-20') if start < pd.to_datetime('2022-11-20') else start\n",
    "    else:\n",
    "        start = pd.to_datetime(start)\n",
    "    return df.loc[start:date, target]\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'get_ytrain', get_ytrain)\n",
    "del get_ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108945,
     "status": "ok",
     "timestamp": 1607622505610,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "GBUYXUVWPQN8",
    "outputId": "15e1dbc2-e965-4514-e046-712e56a847fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2022-12-25 18:00:00    1\n",
       "2022-12-25 19:00:00    0\n",
       "2022-12-25 20:00:00    0\n",
       "2022-12-25 21:00:00    0\n",
       "2022-12-25 22:00:00    0\n",
       "                      ..\n",
       "2023-01-07 19:00:00    0\n",
       "2023-01-07 20:00:00    0\n",
       "2023-01-07 21:00:00    0\n",
       "2023-01-07 22:00:00    0\n",
       "2023-01-07 23:00:00    0\n",
       "Name: activity, Length: 318, dtype: int32"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "y_train = activity.get_ytrain(df, date)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108915,
     "status": "ok",
     "timestamp": 1607622505612,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "P-FYucXjNkuO",
    "outputId": "54b8125f-6252-4462-dff3-7e00418cdece"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2023-01-06 00:00:00    0\n",
       "2023-01-06 01:00:00    0\n",
       "2023-01-06 02:00:00    0\n",
       "2023-01-06 03:00:00    0\n",
       "2023-01-06 04:00:00    0\n",
       "2023-01-06 05:00:00    0\n",
       "2023-01-06 06:00:00    0\n",
       "2023-01-06 07:00:00    0\n",
       "2023-01-06 08:00:00    0\n",
       "2023-01-06 09:00:00    0\n",
       "2023-01-06 10:00:00    0\n",
       "2023-01-06 11:00:00    0\n",
       "2023-01-06 12:00:00    0\n",
       "2023-01-06 13:00:00    0\n",
       "2023-01-06 14:00:00    0\n",
       "2023-01-06 15:00:00    0\n",
       "2023-01-06 16:00:00    0\n",
       "2023-01-06 17:00:00    1\n",
       "2023-01-06 18:00:00    1\n",
       "2023-01-06 19:00:00    1\n",
       "2023-01-06 20:00:00    1\n",
       "2023-01-06 21:00:00    0\n",
       "2023-01-06 22:00:00    0\n",
       "2023-01-06 23:00:00    0\n",
       "2023-01-07 00:00:00    0\n",
       "2023-01-07 01:00:00    0\n",
       "2023-01-07 02:00:00    0\n",
       "2023-01-07 03:00:00    0\n",
       "2023-01-07 04:00:00    0\n",
       "2023-01-07 05:00:00    0\n",
       "2023-01-07 06:00:00    0\n",
       "2023-01-07 07:00:00    0\n",
       "2023-01-07 08:00:00    0\n",
       "2023-01-07 09:00:00    0\n",
       "2023-01-07 10:00:00    0\n",
       "2023-01-07 11:00:00    0\n",
       "2023-01-07 12:00:00    0\n",
       "2023-01-07 13:00:00    0\n",
       "2023-01-07 14:00:00    0\n",
       "2023-01-07 15:00:00    0\n",
       "2023-01-07 16:00:00    0\n",
       "2023-01-07 17:00:00    0\n",
       "2023-01-07 18:00:00    0\n",
       "2023-01-07 19:00:00    0\n",
       "2023-01-07 20:00:00    0\n",
       "2023-01-07 21:00:00    0\n",
       "2023-01-07 22:00:00    0\n",
       "2023-01-07 23:00:00    0\n",
       "Name: activity, dtype: int32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "y_train = activity.get_ytrain(df, date, start=-1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108882,
     "status": "ok",
     "timestamp": 1607622505615,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "nuw4b9xmNpdy",
    "outputId": "d5a00b32-7a89-4919-8d5d-3e2e162de5e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2022-12-28 00:00:00    0\n",
       "2022-12-28 01:00:00    0\n",
       "2022-12-28 02:00:00    0\n",
       "2022-12-28 03:00:00    0\n",
       "2022-12-28 04:00:00    0\n",
       "                      ..\n",
       "2023-01-07 19:00:00    0\n",
       "2023-01-07 20:00:00    0\n",
       "2023-01-07 21:00:00    0\n",
       "2023-01-07 22:00:00    0\n",
       "2023-01-07 23:00:00    0\n",
       "Name: activity, Length: 264, dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "y_train = activity.get_ytrain(df, date, start=-10)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108853,
     "status": "ok",
     "timestamp": 1607622505617,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "TPc02_ZqNrle",
    "outputId": "23b0cc37-c72e-4590-bd0c-4933e6f2131e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2022-12-25 18:00:00    1\n",
       "2022-12-25 19:00:00    0\n",
       "2022-12-25 20:00:00    0\n",
       "2022-12-25 21:00:00    0\n",
       "2022-12-25 22:00:00    0\n",
       "                      ..\n",
       "2023-01-07 19:00:00    0\n",
       "2023-01-07 20:00:00    0\n",
       "2023-01-07 21:00:00    0\n",
       "2023-01-07 22:00:00    0\n",
       "2023-01-07 23:00:00    0\n",
       "Name: activity, Length: 318, dtype: int32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "y_train = activity.get_ytrain(df, date, start=-9999)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0gr74BrNwvM"
   },
   "source": [
    "**train_test_split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'red'> Without filling NAs, I cannot procede further. Is it okay? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train start: the day from which training starts\n",
    "def get_train_start(self, df):\n",
    "    import datetime\n",
    "    end_date = min(df.index) + datetime.timedelta(days=3)\n",
    "    # determine train_start date \n",
    "    return str(end_date)[:10]\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'get_train_start', get_train_start)\n",
    "del get_train_start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 108852,
     "status": "ok",
     "timestamp": 1607622505620,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "8V4jjdT7T8vF"
   },
   "outputs": [],
   "source": [
    "def train_test_split(self, df, date, train_start='', test_delta='all', target='activity'):\n",
    "    if train_start == '':\n",
    "        train_start = self.get_train_start(df)\n",
    "    X_train = self.get_Xtrain(df, date, start=train_start, target=target)\n",
    "    y_train = self.get_ytrain(df, date, start=train_start, target=target)\n",
    "    X_test = self.get_Xtest(df, date, time_delta=test_delta, target=target)\n",
    "    y_test = self.get_ytest(df, date, time_delta=test_delta, target=target)\n",
    "    X_test = X_test.fillna(0)\n",
    "    X_train = X_train.fillna(0)\n",
    "    y_test = y_test.fillna(0)\n",
    "    y_train = y_train.fillna(0)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'train_test_split', train_test_split)\n",
    "del train_test_split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108820,
     "status": "ok",
     "timestamp": 1607622505621,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "U0_zEuR9Pnuv",
    "outputId": "68d3365a-8d0b-494e-8e15-82df5e6aa1ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((390, 11), (264, 10), (264,), (72, 10), (72,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "X_train, y_train, X_test, y_test = activity.train_test_split(df, date)\n",
    "df.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108787,
     "status": "ok",
     "timestamp": 1607622505622,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "L6dQ4jJEP6s6",
    "outputId": "963bbf31-8007-4584-a06d-5f685c88b5f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((390, 11), (264, 10), (264,), (72, 10), (72,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "X_train, y_train, X_test, y_test = activity.train_test_split(df, date, train_start=-10, test_delta={'days': 10, 'seconds':-1})\n",
    "df.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108755,
     "status": "ok",
     "timestamp": 1607622505623,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "MjMgWUCmRwoY",
    "outputId": "3cf063e8-38e2-4df8-833e-3860feeeff73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((390, 11), (264, 10), (264,), (24, 10), (24,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "X_train, y_train, X_test, y_test = activity.train_test_split(df, date, test_delta={'days': 1, 'seconds':-1})\n",
    "df.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 108722,
     "status": "ok",
     "timestamp": 1607622505628,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "1vqbvdYkQuc1",
    "outputId": "66d7e32e-df72-4b59-f397-ee1fa50cd5a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-28 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2022-12-28 00:00:00     0              1.0              0.0              0.0   \n",
       "2022-12-28 01:00:00     1              1.0              0.0              0.0   \n",
       "2022-12-28 02:00:00     2              1.0              0.0              0.0   \n",
       "2022-12-28 03:00:00     3              1.0              0.0              0.0   \n",
       "2022-12-28 04:00:00     4              1.0              0.0              0.0   \n",
       "...                   ...              ...              ...              ...   \n",
       "2023-01-07 19:00:00    19              1.0              0.0              0.0   \n",
       "2023-01-07 20:00:00    20              1.0              0.0              0.0   \n",
       "2023-01-07 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-07 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-07 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2022-12-28 00:00:00                0                  0                0   \n",
       "2022-12-28 01:00:00                0                  0                0   \n",
       "2022-12-28 02:00:00                0                  0                0   \n",
       "2022-12-28 03:00:00                0                  0                0   \n",
       "2022-12-28 04:00:00                0                  0                0   \n",
       "...                              ...                ...              ...   \n",
       "2023-01-07 19:00:00                0                  1                0   \n",
       "2023-01-07 20:00:00                0                  1                0   \n",
       "2023-01-07 21:00:00                0                  1                0   \n",
       "2023-01-07 22:00:00                0                  1                0   \n",
       "2023-01-07 23:00:00                0                  1                0   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2022-12-28 00:00:00                  0                 0                   1  \n",
       "2022-12-28 01:00:00                  0                 0                   1  \n",
       "2022-12-28 02:00:00                  0                 0                   1  \n",
       "2022-12-28 03:00:00                  0                 0                   1  \n",
       "2022-12-28 04:00:00                  0                 0                   1  \n",
       "...                                ...               ...                 ...  \n",
       "2023-01-07 19:00:00                  0                 0                   0  \n",
       "2023-01-07 20:00:00                  0                 0                   0  \n",
       "2023-01-07 21:00:00                  0                 0                   0  \n",
       "2023-01-07 22:00:00                  0                 0                   0  \n",
       "2023-01-07 23:00:00                  0                 0                   0  \n",
       "\n",
       "[264 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 108677,
     "status": "ok",
     "timestamp": 1607622505632,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "hUSNw2kFR7Vq",
    "outputId": "2b1599ad-ac5a-4fa8-f6a0-1517631df499"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_24</th>\n",
       "      <th>activity_lag_48</th>\n",
       "      <th>activity_lag_72</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-08 00:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 02:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 03:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 04:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 05:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 06:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 07:00:00</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 08:00:00</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 09:00:00</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 10:00:00</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 11:00:00</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 12:00:00</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 13:00:00</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 14:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 15:00:00</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 16:00:00</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 17:00:00</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 18:00:00</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 19:00:00</th>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 20:00:00</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 21:00:00</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 22:00:00</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08 23:00:00</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       "last_updated                                                                   \n",
       "2023-01-08 00:00:00     0              0.0              0.0              0.0   \n",
       "2023-01-08 01:00:00     1              0.0              0.0              0.0   \n",
       "2023-01-08 02:00:00     2              0.0              0.0              0.0   \n",
       "2023-01-08 03:00:00     3              0.0              0.0              0.0   \n",
       "2023-01-08 04:00:00     4              0.0              0.0              0.0   \n",
       "2023-01-08 05:00:00     5              0.0              0.0              0.0   \n",
       "2023-01-08 06:00:00     6              0.0              0.0              0.0   \n",
       "2023-01-08 07:00:00     7              0.0              0.0              0.0   \n",
       "2023-01-08 08:00:00     8              0.0              0.0              0.0   \n",
       "2023-01-08 09:00:00     9              0.0              0.0              0.0   \n",
       "2023-01-08 10:00:00    10              0.0              0.0              0.0   \n",
       "2023-01-08 11:00:00    11              0.0              0.0              0.0   \n",
       "2023-01-08 12:00:00    12              0.0              0.0              0.0   \n",
       "2023-01-08 13:00:00    13              0.0              0.0              0.0   \n",
       "2023-01-08 14:00:00    14              0.0              0.0              0.0   \n",
       "2023-01-08 15:00:00    15              0.0              0.0              0.0   \n",
       "2023-01-08 16:00:00    16              0.0              0.0              0.0   \n",
       "2023-01-08 17:00:00    17              0.0              1.0              0.0   \n",
       "2023-01-08 18:00:00    18              0.0              1.0              0.0   \n",
       "2023-01-08 19:00:00    19              0.0              1.0              0.0   \n",
       "2023-01-08 20:00:00    20              0.0              1.0              0.0   \n",
       "2023-01-08 21:00:00    21              0.0              0.0              0.0   \n",
       "2023-01-08 22:00:00    22              0.0              0.0              0.0   \n",
       "2023-01-08 23:00:00    23              0.0              0.0              0.0   \n",
       "\n",
       "                     day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       "last_updated                                                               \n",
       "2023-01-08 00:00:00                0                  0                1   \n",
       "2023-01-08 01:00:00                0                  0                1   \n",
       "2023-01-08 02:00:00                0                  0                1   \n",
       "2023-01-08 03:00:00                0                  0                1   \n",
       "2023-01-08 04:00:00                0                  0                1   \n",
       "2023-01-08 05:00:00                0                  0                1   \n",
       "2023-01-08 06:00:00                0                  0                1   \n",
       "2023-01-08 07:00:00                0                  0                1   \n",
       "2023-01-08 08:00:00                0                  0                1   \n",
       "2023-01-08 09:00:00                0                  0                1   \n",
       "2023-01-08 10:00:00                0                  0                1   \n",
       "2023-01-08 11:00:00                0                  0                1   \n",
       "2023-01-08 12:00:00                0                  0                1   \n",
       "2023-01-08 13:00:00                0                  0                1   \n",
       "2023-01-08 14:00:00                0                  0                1   \n",
       "2023-01-08 15:00:00                0                  0                1   \n",
       "2023-01-08 16:00:00                0                  0                1   \n",
       "2023-01-08 17:00:00                0                  0                1   \n",
       "2023-01-08 18:00:00                0                  0                1   \n",
       "2023-01-08 19:00:00                0                  0                1   \n",
       "2023-01-08 20:00:00                0                  0                1   \n",
       "2023-01-08 21:00:00                0                  0                1   \n",
       "2023-01-08 22:00:00                0                  0                1   \n",
       "2023-01-08 23:00:00                0                  0                1   \n",
       "\n",
       "                     day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       "last_updated                                                                  \n",
       "2023-01-08 00:00:00                  0                 0                   0  \n",
       "2023-01-08 01:00:00                  0                 0                   0  \n",
       "2023-01-08 02:00:00                  0                 0                   0  \n",
       "2023-01-08 03:00:00                  0                 0                   0  \n",
       "2023-01-08 04:00:00                  0                 0                   0  \n",
       "2023-01-08 05:00:00                  0                 0                   0  \n",
       "2023-01-08 06:00:00                  0                 0                   0  \n",
       "2023-01-08 07:00:00                  0                 0                   0  \n",
       "2023-01-08 08:00:00                  0                 0                   0  \n",
       "2023-01-08 09:00:00                  0                 0                   0  \n",
       "2023-01-08 10:00:00                  0                 0                   0  \n",
       "2023-01-08 11:00:00                  0                 0                   0  \n",
       "2023-01-08 12:00:00                  0                 0                   0  \n",
       "2023-01-08 13:00:00                  0                 0                   0  \n",
       "2023-01-08 14:00:00                  0                 0                   0  \n",
       "2023-01-08 15:00:00                  0                 0                   0  \n",
       "2023-01-08 16:00:00                  0                 0                   0  \n",
       "2023-01-08 17:00:00                  0                 0                   0  \n",
       "2023-01-08 18:00:00                  0                 0                   0  \n",
       "2023-01-08 19:00:00                  0                 0                   0  \n",
       "2023-01-08 20:00:00                  0                 0                   0  \n",
       "2023-01-08 21:00:00                  0                 0                   0  \n",
       "2023-01-08 22:00:00                  0                 0                   0  \n",
       "2023-01-08 23:00:00                  0                 0                   0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108648,
     "status": "ok",
     "timestamp": 1607622505633,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "YRC3BzB1R9Vm",
    "outputId": "016c8cc1-ec68-4778-b2fa-7037de1ac50b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2022-12-28 00:00:00    0\n",
       "2022-12-28 01:00:00    0\n",
       "2022-12-28 02:00:00    0\n",
       "2022-12-28 03:00:00    0\n",
       "2022-12-28 04:00:00    0\n",
       "                      ..\n",
       "2023-01-07 19:00:00    0\n",
       "2023-01-07 20:00:00    0\n",
       "2023-01-07 21:00:00    0\n",
       "2023-01-07 22:00:00    0\n",
       "2023-01-07 23:00:00    0\n",
       "Name: activity, Length: 264, dtype: int32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108623,
     "status": "ok",
     "timestamp": 1607622505637,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "NzucRWLPR-se",
    "outputId": "e636f0bd-dbb0-4ff5-b05a-a3ada56c130f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2023-01-08 00:00:00    0\n",
       "2023-01-08 01:00:00    0\n",
       "2023-01-08 02:00:00    0\n",
       "2023-01-08 03:00:00    0\n",
       "2023-01-08 04:00:00    0\n",
       "2023-01-08 05:00:00    0\n",
       "2023-01-08 06:00:00    0\n",
       "2023-01-08 07:00:00    0\n",
       "2023-01-08 08:00:00    0\n",
       "2023-01-08 09:00:00    0\n",
       "2023-01-08 10:00:00    0\n",
       "2023-01-08 11:00:00    0\n",
       "2023-01-08 12:00:00    0\n",
       "2023-01-08 13:00:00    0\n",
       "2023-01-08 14:00:00    0\n",
       "2023-01-08 15:00:00    0\n",
       "2023-01-08 16:00:00    1\n",
       "2023-01-08 17:00:00    1\n",
       "2023-01-08 18:00:00    1\n",
       "2023-01-08 19:00:00    0\n",
       "2023-01-08 20:00:00    0\n",
       "2023-01-08 21:00:00    0\n",
       "2023-01-08 22:00:00    0\n",
       "2023-01-08 23:00:00    0\n",
       "Name: activity, dtype: int32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFin5DzZSe4m"
   },
   "source": [
    "### **2.2 Building Models**\n",
    "\n",
    "Within this section, we will demonstrate how different models for predicting the user activity could be added to the activity agent. For this notebook, we chose to implement a pretty simple logistic regression using the statsmodel api which already provides promising results. \n",
    "\n",
    "The functionality of the activity agent will include building models, fitting models and predicting the userâ€™s activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import sklearn\n",
    "import statsmodels\n",
    "from interpret.glassbox.ebm.ebm import ExplainableBoostingClassifier     \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost\n",
    "import statsmodels.api\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_Logit(self, X, y, max_iter=100):\n",
    "    return LogisticRegression(random_state=0, max_iter=max_iter).fit(X, y)\n",
    "\n",
    "def fit_knn(self, X, y, n_neighbors=10, leaf_size=30):\n",
    "    return KNeighborsClassifier(n_neighbors=n_neighbors, leaf_size=leaf_size, algorithm=\"auto\", n_jobs=-1).fit(X, y)\n",
    "\n",
    "def fit_random_forest(self, X, y, max_depth=10, n_estimators=500, max_features=\"sqrt\"):\n",
    "    return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
    "\n",
    "def fit_ADA(self, X, y, learning_rate=0.1, n_estimators=100):\n",
    "    return AdaBoostClassifier(learning_rate=learning_rate, n_estimators=n_estimators).fit(X, y)\n",
    "\n",
    "def fit_XGB(self, X, y, learning_rate=0.1, max_depth=6, reg_lambda=1, reg_alpha=0):\n",
    "    return xgboost.XGBClassifier(verbosity=0, use_label_encoder=False, learning_rate=learning_rate, max_depth=max_depth, reg_lambda=reg_lambda, reg_alpha=reg_alpha).fit(X, y)\n",
    "\n",
    "def fit_EBM(self, X, y): \n",
    "    return ExplainableBoostingClassifier().fit(X,y)\n",
    "\n",
    "def fit_smLogit(self, X, y):\n",
    "    return statsmodels.api.Logit(y, X).fit(disp=False)\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'fit_Logit', fit_Logit)\n",
    "del fit_Logit \n",
    "setattr(Activity_Agent, 'fit_knn', fit_knn)\n",
    "del fit_knn \n",
    "setattr(Activity_Agent, 'fit_random_forest', fit_random_forest)\n",
    "del fit_random_forest \n",
    "setattr(Activity_Agent, 'fit_ADA', fit_ADA)\n",
    "del fit_ADA \n",
    "setattr(Activity_Agent, 'fit_XGB', fit_XGB)\n",
    "del fit_XGB \n",
    "setattr(Activity_Agent, 'fit_EBM', fit_EBM)\n",
    "del fit_EBM \n",
    "setattr(Activity_Agent, 'fit_smLogit', fit_smLogit)\n",
    "del fit_smLogit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did you use statsmodels.api as sm instead of LogisticRegression? any advantages?\n",
    "Logit is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y, model_type, **args):\n",
    "    model = None\n",
    "    if model_type == \"logit\":\n",
    "        model = self.fit_Logit(X, y, **args)\n",
    "    elif model_type == \"ada\":\n",
    "        model = self.fit_ADA(X, y, **args)\n",
    "    elif model_type == \"knn\":\n",
    "        model = self.fit_knn(X, y, **args)\n",
    "    elif model_type == \"random forest\":\n",
    "        model = self.fit_random_forest(X, y, **args)\n",
    "    elif model_type == \"xgboost\":\n",
    "        model = self.fit_XGB(X, y, **args)\n",
    "    elif model_type == \"ebm\":\n",
    "        model = self.fit_EBM(X,y, **args)\n",
    "    elif model_type == \"logit_sm\":\n",
    "        model = self.fit_smLogit(X, y)\n",
    "    else:\n",
    "        raise InputError(\"Unknown model type.\")\n",
    "    return model\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'fit', fit)\n",
    "del fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108973,
     "status": "ok",
     "timestamp": 1607622506027,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "c4VLJHsiT6og",
    "outputId": "e5a9a876-fc6e-4e76-e0e3-648bd04a6bde",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "activity = Activity_Agent(df)\n",
    "model = activity.fit(X_train, y_train, 'logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, model, X):\n",
    "    \n",
    "    if type(model) == sklearn.linear_model.LogisticRegression:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "    elif type(model) == sklearn.neighbors._classification.KNeighborsClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "    elif type(model) == sklearn.ensemble._forest.RandomForestClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "    elif type(model) ==  sklearn.ensemble._weight_boosting.AdaBoostClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "    elif type(model) == xgboost.sklearn.XGBClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "    elif type(model) == ExplainableBoostingClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    elif type(model) == statsmodels.discrete.discrete_model.BinaryResultsWrapper:\n",
    "        y_hat = model.predict(X)\n",
    "        \n",
    "    else:\n",
    "        raise InputError(\"Unknown model type.\")\n",
    "\n",
    "    y_hat = pd.Series(y_hat, index=X.index)\n",
    "\n",
    "    return y_hat\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'predict', predict)\n",
    "del predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEasRNILZOu3"
   },
   "source": [
    "### **2.3 Model Evaluation**\n",
    "\n",
    "A drawback to our approach is that we are not able to apply conventional model evaluation techniques to our model. We will train our model for each day to account for newly available information. Hence, we have different train and test sets for each day and for each day different performance metric based on the respective data sets. Therefore, we created our own evaluation function. \n",
    "\n",
    "Our evaluation function will build a model, fit the model and predict the target for each day for a given prediction period. For each day and fitted model it will calculate a performance metric on the train data. We chose the Area Under the Receiver Operating Characteristic Curve (AUC) as performance metric for our binary classification task. As in our case the test data is only the current date to be predicted (i.e. 24 data cases in the test data, one for each hour of the day), calculating the AUC on the test date immediately would lead to a high volatility in the test AUC per day to be predicted. Therefore, we calculate the test AUC over the activity probabilities of all days after all days have been predicted. To summarize the train AUC in one score, we apply an average over all calculated train AUC scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 108948,
     "status": "ok",
     "timestamp": 1607622506037,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "04O7bOvBZSEB"
   },
   "outputs": [],
   "source": [
    "def auc(self, y_true, y_hat):\n",
    "    import sklearn.metrics\n",
    "    try:\n",
    "        return sklearn.metrics.roc_auc_score(y_true, y_hat)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'auc', auc)\n",
    "del auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity = Activity_Agent(df)\n",
    "model = activity.fit(X_train, y_train, 'logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = activity.predict(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2023-01-08 00:00:00    0\n",
       "2023-01-08 01:00:00    0\n",
       "2023-01-08 02:00:00    0\n",
       "2023-01-08 03:00:00    0\n",
       "2023-01-08 04:00:00    0\n",
       "2023-01-08 05:00:00    0\n",
       "2023-01-08 06:00:00    0\n",
       "2023-01-08 07:00:00    0\n",
       "2023-01-08 08:00:00    0\n",
       "2023-01-08 09:00:00    0\n",
       "2023-01-08 10:00:00    0\n",
       "2023-01-08 11:00:00    0\n",
       "2023-01-08 12:00:00    0\n",
       "2023-01-08 13:00:00    0\n",
       "2023-01-08 14:00:00    0\n",
       "2023-01-08 15:00:00    0\n",
       "2023-01-08 16:00:00    1\n",
       "2023-01-08 17:00:00    1\n",
       "2023-01-08 18:00:00    1\n",
       "2023-01-08 19:00:00    0\n",
       "2023-01-08 20:00:00    0\n",
       "2023-01-08 21:00:00    0\n",
       "2023-01-08 22:00:00    0\n",
       "2023-01-08 23:00:00    0\n",
       "Name: activity, dtype: int32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_updated\n",
       "2023-01-08 00:00:00    0.106468\n",
       "2023-01-08 01:00:00    0.113447\n",
       "2023-01-08 02:00:00    0.120823\n",
       "2023-01-08 03:00:00    0.128608\n",
       "2023-01-08 04:00:00    0.136817\n",
       "2023-01-08 05:00:00    0.145463\n",
       "2023-01-08 06:00:00    0.154557\n",
       "2023-01-08 07:00:00    0.164110\n",
       "2023-01-08 08:00:00    0.174132\n",
       "2023-01-08 09:00:00    0.184631\n",
       "2023-01-08 10:00:00    0.195613\n",
       "2023-01-08 11:00:00    0.207083\n",
       "2023-01-08 12:00:00    0.219041\n",
       "2023-01-08 13:00:00    0.231489\n",
       "2023-01-08 14:00:00    0.244423\n",
       "2023-01-08 15:00:00    0.257837\n",
       "2023-01-08 16:00:00    0.271722\n",
       "2023-01-08 17:00:00    0.531154\n",
       "2023-01-08 18:00:00    0.548873\n",
       "2023-01-08 19:00:00    0.566469\n",
       "2023-01-08 20:00:00    0.583899\n",
       "2023-01-08 21:00:00    0.347692\n",
       "2023-01-08 22:00:00    0.364042\n",
       "2023-01-08 23:00:00    0.380713\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not work with dummy data, but do we currently need the auc scores??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score = activity.auc(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "        self, df, split_params, model_type, predict_start=\"2013-11-30\", predict_end=-1, return_errors=False,\n",
    "        xai=False, weather_sel=False, **args\n",
    "    ):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    dates = (\n",
    "        pd.DataFrame(df.index)\n",
    "        .set_index(df.index)[\"last_updated_ts\"]\n",
    "        .apply(lambda date: str(date)[:10])\n",
    "        .drop_duplicates()\n",
    "    )\n",
    "    predict_start = pd.to_datetime(predict_start)\n",
    "    predict_end = (\n",
    "        pd.to_datetime(dates.iloc[predict_end])\n",
    "        if type(predict_end) == int\n",
    "        else pd.to_datetime(predict_end)\n",
    "     )\n",
    "    dates = dates.loc[predict_start:predict_end]\n",
    "    y_true = []\n",
    "    y_hat_train = {}\n",
    "    y_hat_test = []\n",
    "    y_hat_lime = []\n",
    "    y_hat_shap = []\n",
    "    auc_train_dict = {}\n",
    "    auc_test = []\n",
    "    xai_time_lime = []\n",
    "    xai_time_shap = []\n",
    "\n",
    "    predictions_list = []\n",
    "\n",
    "    if weather_sel:\n",
    "        print(\"Crawl weather data....\")\n",
    "        # Add Weather\n",
    "        ################################\n",
    "        from meteostat import Point, Hourly\n",
    "        from datetime import datetime\n",
    "\n",
    "        lough = Point(52.766593, -1.223511)\n",
    "        time = df.index.to_series(name=\"time\").tolist()\n",
    "        weather = Hourly(lough, time[0], time[len(df) - 1])\n",
    "        weather = weather.fetch()\n",
    "\n",
    "        from sklearn.impute import KNNImputer\n",
    "        import numpy as np\n",
    "\n",
    "        headers = weather.columns.values\n",
    "\n",
    "        empty_train_columns = []\n",
    "        for col in weather.columns.values:\n",
    "            if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                empty_train_columns.append(col)\n",
    "        headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "        weather = imputer.fit_transform(weather)\n",
    "        scaler = MinMaxScaler()\n",
    "        weather = scaler.fit_transform(weather)\n",
    "        weather = pd.DataFrame(weather)\n",
    "        weather[\"time\"] = time[0:len(weather)]\n",
    "        df[\"time\"] = time\n",
    "\n",
    "        weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "        df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "        df = df.set_index(\"time\")\n",
    "        ################################\n",
    "    if not xai:\n",
    "        for date in tqdm(dates):\n",
    "            errors = {}\n",
    "            try:\n",
    "                X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                    df, date, **split_params\n",
    "                )\n",
    "\n",
    "                # fit model\n",
    "                model = self.fit(X_train, y_train, model_type, **args)\n",
    "\n",
    "                y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                y_hat_test += list(self.predict(model, X_test))\n",
    "\n",
    "                # evaluate train data\n",
    "                auc_train_dict.update(\n",
    "                    {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                )\n",
    "                y_true += list(y_test)\n",
    "\n",
    "            except Exception as e:\n",
    "                errors[date] = e\n",
    "    else:\n",
    "        print('The explainability approaches in the Activity Agent are being evaluated for model: ' + str(model_type))\n",
    "        print('Start evaluation with LIME and SHAP')\n",
    "        import time\n",
    "        import lime\n",
    "        from lime import lime_tabular\n",
    "        import shap as shap\n",
    "\n",
    "        for date in tqdm(dates):\n",
    "            errors = {}\n",
    "            try:\n",
    "                X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                    df, date, **split_params\n",
    "                )\n",
    "\n",
    "                # fit model\n",
    "                model = self.fit(X_train, y_train, model_type)\n",
    "\n",
    "                # self.predict uses predict_proba i.e. we get probability estimates and not classes\n",
    "                y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                y_hat_test += list(self.predict(model, X_test))\n",
    "\n",
    "                # evaluate train data\n",
    "                auc_train_dict.update(\n",
    "                    {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                )\n",
    "                y_true += list(y_test)\n",
    "\n",
    "                start_time = time.time()\n",
    "\n",
    "                if model_type == \"xgboost\":\n",
    "                    booster = model.get_booster()\n",
    "\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                                                        feature_names=X_train.columns,\n",
    "                                                                        kernel_width=3, verbose=False)\n",
    "                else:\n",
    "                    explainer = lime_tabular.LimeTabularExplainer(training_data=np.array(X_train),\n",
    "                                                                    mode=\"classification\",\n",
    "                                                                    feature_names=X_train.columns,\n",
    "                                                                    categorical_features=[0])\n",
    "                    \n",
    "                for local in range(len(X_test)):\n",
    "\n",
    "                    if model_type == \"xgboost\":\n",
    "                        exp = explainer.explain_instance(X_test.iloc[local, :].values, model.predict_proba)\n",
    "                    else:\n",
    "                        exp = explainer.explain_instance(data_row=X_test.iloc[local], predict_fn=model.predict_proba)\n",
    "\n",
    "                    y_hat_lime += list(exp.local_pred)\n",
    "\n",
    "\n",
    "                # take time for each day:\n",
    "                end_time = time.time()\n",
    "                difference_time = end_time - start_time\n",
    "\n",
    "                xai_time_lime.append(difference_time)\n",
    "                # SHAP\n",
    "                # ==============================================================================\n",
    "                start_time = time.time()\n",
    "\n",
    "                if model_type == \"logit\":\n",
    "                    X_train_summary = shap.sample(X_train, 100)\n",
    "                    explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                elif model_type == \"ada\":\n",
    "                    X_train_summary = shap.sample(X_train, 100)\n",
    "                    explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                elif model_type == \"knn\":\n",
    "                    X_train_summary = shap.sample(X_train, 100)\n",
    "                    explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                elif model_type == \"random forest\":\n",
    "                    X_train_summary = shap.sample(X_train, 100)\n",
    "                    explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                elif model_type == \"xgboost\":\n",
    "                    explainer = shap.TreeExplainer(model, X_train, model_output='predict_proba')\n",
    "                \n",
    "                elif model_type == \"logit_sm\":\n",
    "                    explainer = shap.TreeExplainer(model.predict, X_train_summary)\n",
    "\n",
    "                else:\n",
    "                    raise InputError(\"Unknown model type.\")\n",
    "\n",
    "                base_value = explainer.expected_value[1]  # the mean prediction\n",
    "\n",
    "                for local in range(len(X_test)):\n",
    "\n",
    "                    shap_values = explainer.shap_values(\n",
    "                        X_test.iloc[local, :])\n",
    "\n",
    "                    contribution_to_class_1 = np.array(shap_values).sum(axis=1)[1]\n",
    "                    shap_prediction = base_value + contribution_to_class_1\n",
    "\n",
    "                    # Prediction from XAI:\n",
    "                    y_hat_shap += list([shap_prediction])\n",
    "\n",
    "\n",
    "                # take time for each day:\n",
    "                end_time = time.time()\n",
    "                difference_time = end_time - start_time\n",
    "                xai_time_shap.append(difference_time)\n",
    "\n",
    "            except Exception as e:\n",
    "                errors[date] = e\n",
    "\n",
    "    auc_test = self.auc(y_true, y_hat_test)\n",
    "    auc_train = np.mean(list(auc_train_dict.values()))\n",
    "    predictions_list.append(y_true)\n",
    "    predictions_list.append(y_hat_test)\n",
    "    predictions_list.append(y_hat_lime)\n",
    "    predictions_list.append(y_hat_shap)\n",
    "\n",
    "    # Efficiency\n",
    "    time_mean_lime = np.mean(xai_time_lime)\n",
    "    time_mean_shap = np.mean(xai_time_shap)\n",
    "    print('Mean time nedded by appraoches: ' + str(time_mean_lime) + ' ' + str(time_mean_shap))\n",
    "\n",
    "    if return_errors:\n",
    "        return auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list, errors\n",
    "    else:\n",
    "        return auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list\n",
    "    \n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'evaluate', evaluate)\n",
    "del evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The explainability approaches in the Activity Agent are being evaluated for model: random forest\n",
      "Start evaluation with LIME and SHAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 10%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                          | 1/10 [00:44<06:42, 44.76s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                  | 2/10 [01:49<07:31, 56.46s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 30%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                                          | 3/10 [02:54<07:01, 60.26s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                 | 4/10 [04:01<06:17, 62.88s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                         | 5/10 [05:07<05:20, 64.19s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                 | 6/10 [06:23<04:33, 68.30s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 7/10 [07:43<03:35, 71.90s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 8/10 [09:10<02:33, 76.78s/it]X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [10:38<00:00, 63.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time nedded by appraoches: 27.35768877135383 42.07292551464505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split_params = {'train_start': '', 'test_delta': {'days':1, 'seconds':-1}, 'target': 'activity'}\n",
    "activity = Activity_Agent(df)\n",
    "auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list = activity.evaluate(df, split_params, \"random forest\",\n",
    "                                                                                                          predict_start=\"2023-01-01\" ,xai=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model performance] train auc score: 0.9984400502086719\n",
      "[model performance] test auc score: 0.8412416851441241\n"
     ]
    }
   ],
   "source": [
    "# printing the scores\n",
    "print(f'[model performance] train auc score: {auc_train}\\n[model performance] test auc score: {auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIXhmu5fsaHC"
   },
   "source": [
    "### **2.4 Pipeline Function**\n",
    "\n",
    "The pipeline function of the activity agent will receive a date as input, create the appropriate train test split, fit the selected model to the data and return the activity predictions for the day to be predicted. The subsequent recommendation agent will process these activity probabilities to provide recommendations to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline function: predicting user activity\n",
    "# -------------------------------------------------------------------------------------------\n",
    "def pipeline(self, df, date, model_type, split_params, weather_sel=False):\n",
    "\n",
    "    if weather_sel:\n",
    "\n",
    "        # Add Weather\n",
    "        ################################\n",
    "        from meteostat import Point, Hourly\n",
    "        from datetime import datetime\n",
    "\n",
    "        lough = Point(52.766593, -1.223511)\n",
    "        time = df.index.to_series(name=\"time\").tolist()\n",
    "        weather = Hourly(lough, time[0], time[len(df) - 1])\n",
    "        weather = weather.fetch()\n",
    "\n",
    "        from sklearn.impute import KNNImputer\n",
    "        import numpy as np\n",
    "\n",
    "        headers = weather.columns.values\n",
    "\n",
    "        empty_train_columns = []\n",
    "        for col in weather.columns.values:\n",
    "            if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                empty_train_columns.append(col)\n",
    "        headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "        weather = imputer.fit_transform(weather)\n",
    "        scaler = MinMaxScaler()\n",
    "        weather = scaler.fit_transform(weather)\n",
    "        weather = pd.DataFrame(weather)\n",
    "        weather[\"time\"] = time[0:len(weather)]\n",
    "        df[\"time\"] = time\n",
    "\n",
    "        weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "        df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "        df = df.set_index(\"time\")\n",
    "        ################################\n",
    "\n",
    "    # train test split\n",
    "    X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "        df, date, **split_params\n",
    "    )\n",
    "\n",
    "    # fit model\n",
    "    model = self.fit(X_train, y_train, model_type)\n",
    "\n",
    "    # predict\n",
    "    return self.predict(model, X_test)\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'pipeline', pipeline)\n",
    "del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline function: predicting user activity with xai\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "def pipeline_xai(self, df, date, model_type, split_params, weather_sel=False):\n",
    "\n",
    "    if weather_sel:\n",
    "\n",
    "        # Add Weather\n",
    "        ################################\n",
    "        from meteostat import Point, Hourly\n",
    "        from datetime import datetime\n",
    "\n",
    "        lough = Point(52.766593, -1.223511)\n",
    "        time = df.index.to_series(name=\"time\").tolist()\n",
    "        weather = Hourly(lough, time[0], time[len(df) - 1])\n",
    "        weather = weather.fetch()\n",
    "\n",
    "        from sklearn.impute import KNNImputer\n",
    "        import numpy as np\n",
    "\n",
    "        headers = weather.columns.values\n",
    "\n",
    "        empty_train_columns = []\n",
    "        for col in weather.columns.values:\n",
    "            if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                empty_train_columns.append(col)\n",
    "        headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "        weather = imputer.fit_transform(weather)\n",
    "        scaler = MinMaxScaler()\n",
    "        weather = scaler.fit_transform(weather)\n",
    "        weather = pd.DataFrame(weather)\n",
    "        weather[\"time\"] = time[0:len(weather)]\n",
    "        df[\"time\"] = time\n",
    "\n",
    "        weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "        df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "        df = df.set_index(\"time\")\n",
    "\n",
    "        ################################\n",
    "\n",
    "    # train test split\n",
    "    X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "        df, date, **split_params\n",
    "    )\n",
    "\n",
    "    # fit model\n",
    "    model = self.fit(X_train, y_train, model_type)\n",
    "\n",
    "    # predict\n",
    "    return self.predict(model, X_test), X_train, X_test, model\n",
    "    \n",
    "# add to Activity agent\n",
    "setattr(Activity_Agent, 'pipeline_xai', pipeline_xai)\n",
    "del pipeline_xai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-8ff2uCtxuF"
   },
   "source": [
    "## **Appendix A1: Complete Activity Agent Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 128322,
     "status": "ok",
     "timestamp": 1607622525554,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "FOFcx9a_t0wq"
   },
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# activity agent ##################################################################################\n",
    "###################################################################################################\n",
    "class Activity_Agent:\n",
    "    def __init__(self, activity_input_df):\n",
    "        self.input = activity_input_df\n",
    "\n",
    "    # train test split\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "    def get_Xtest(self, df, date, time_delta='all', target='activity'):\n",
    "        import pandas as pd\n",
    "        from helper_functions import Helper\n",
    "\n",
    "        helper = Helper()\n",
    "\n",
    "        tomorrow = (pd.to_datetime(date) + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        if time_delta == 'all':\n",
    "            output = df.loc[pd.to_datetime(tomorrow):, df.columns != target]\n",
    "        else:\n",
    "            df = helper.get_timespan(df, tomorrow, time_delta)\n",
    "            output = df.loc[:, df.columns != target]\n",
    "        return output\n",
    "\n",
    "    def get_ytest(self, df, date, time_delta='all', target='activity'):\n",
    "        import pandas as pd\n",
    "        from helper_functions import Helper\n",
    "\n",
    "        helper = Helper()\n",
    "\n",
    "        tomorrow = (pd.to_datetime(date) + pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        if time_delta == 'all':\n",
    "            output = df.loc[pd.to_datetime(tomorrow):, target]\n",
    "        else:\n",
    "            output = helper.get_timespan(df, tomorrow, time_delta)[target]\n",
    "        return output\n",
    "\n",
    "    def get_Xtrain(self, df, date, start=-30, target='activity'):\n",
    "        import pandas as pd\n",
    "\n",
    "        if type(start) == int:\n",
    "            start = pd.to_datetime(date) + pd.Timedelta(days= start)\n",
    "            start = pd.to_datetime('2022-12-31') if start < pd.to_datetime('2022-12-31') else start\n",
    "        else:\n",
    "            start = pd.to_datetime(start)\n",
    "\n",
    "        return df.loc[start:date, df.columns != target]\n",
    "\n",
    "\n",
    "    def get_ytrain(self, df, date, start=-30, target='activity'):\n",
    "        import pandas as pd\n",
    "\n",
    "        if type(start) == int:\n",
    "            start = pd.to_datetime(date) + pd.Timedelta(days= start)\n",
    "            start = pd.to_datetime('2022-12-31') if start < pd.to_datetime('2022-12-31') else start\n",
    "        else:\n",
    "            start = pd.to_datetime(start)\n",
    "        return df.loc[start:date, target]\n",
    "    \n",
    "    #train start: the day from which training starts\n",
    "    def get_train_start(self, df):\n",
    "        import datetime\n",
    "        end_date = min(df.index) + datetime.timedelta(days=3)\n",
    "        # determine train_start date \n",
    "        return str(end_date)[:10]\n",
    "\n",
    "    def train_test_split(self, df, date, train_start=-30, test_delta='all', target='activity'):\n",
    "        if train_start == '':\n",
    "            train_start = self.get_train_start(df)\n",
    "        X_train = self.get_Xtrain(df, date, start=train_start, target=target)\n",
    "        y_train = self.get_ytrain(df, date, start=train_start, target=target)\n",
    "        X_test = self.get_Xtest(df, date, time_delta=test_delta, target=target)\n",
    "        y_test = self.get_ytest(df, date, time_delta=test_delta, target=target)\n",
    "        X_test = X_test.fillna(0)\n",
    "        X_train = X_train.fillna(0)\n",
    "        y_test = y_test.fillna(0)\n",
    "        y_train = y_train.fillna(0)\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    # model training and evaluation\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def fit_Logit(self, X, y, max_iter=100):\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        return LogisticRegression(random_state=0, max_iter=max_iter).fit(X, y)\n",
    "\n",
    "    def fit_knn(self, X, y, n_neighbors=10, leaf_size=30):\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        return KNeighborsClassifier(n_neighbors=n_neighbors, leaf_size=leaf_size, algorithm=\"auto\", n_jobs=-1).fit(X, y)\n",
    "\n",
    "    def fit_random_forest(self, X, y, max_depth=10, n_estimators=500, max_features=\"sqrt\"):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
    "\n",
    "    def fit_ADA(self, X, y, learning_rate=0.1, n_estimators=100):\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        return AdaBoostClassifier(learning_rate=learning_rate, n_estimators=n_estimators).fit(X, y)\n",
    "\n",
    "    def fit_XGB(self, X, y, learning_rate=0.1, max_depth=6, reg_lambda=1, reg_alpha=0):\n",
    "        import xgboost\n",
    "        return xgboost.XGBClassifier(verbosity=0, use_label_encoder=False, learning_rate=learning_rate, max_depth=max_depth, reg_lambda=reg_lambda, reg_alpha=reg_alpha).fit(X, y)\n",
    "\n",
    "    def fit_EBM(self, X, y): \n",
    "        from interpret.glassbox.ebm.ebm import ExplainableBoostingClassifier  \n",
    "        return ExplainableBoostingClassifier().fit(X,y)\n",
    "\n",
    "    def fit_smLogit(self, X, y):\n",
    "        import statsmodels\n",
    "        return statsmodels.api.Logit(y, X).fit(disp=False)\n",
    "    \n",
    "    def fit(self, X, y, model_type, **args):\n",
    "        model = None\n",
    "        if model_type == \"logit\":\n",
    "            model = self.fit_Logit(X, y, **args)\n",
    "        elif model_type == \"ada\":\n",
    "            model = self.fit_ADA(X, y, **args)\n",
    "        elif model_type == \"knn\":\n",
    "            model = self.fit_knn(X, y, **args)\n",
    "        elif model_type == \"random forest\":\n",
    "            model = self.fit_random_forest(X, y, **args)\n",
    "        elif model_type == \"xgboost\":\n",
    "            model = self.fit_XGB(X, y, **args)\n",
    "        elif model_type == \"ebm\":\n",
    "            model = self.fit_EBM(X,y, **args)\n",
    "        elif model_type == \"logit_sm\":\n",
    "            model = self.fit_smLogit(X, y)\n",
    "        else:\n",
    "            raise InputError(\"Unknown model type.\")\n",
    "        return model\n",
    "    \n",
    "    def predict(self, model, X):\n",
    "        import sklearn\n",
    "        import statsmodels\n",
    "        from interpret.glassbox.ebm.ebm import ExplainableBoostingClassifier     \n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        import xgboost\n",
    "        if type(model) == sklearn.linear_model.LogisticRegression:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "        elif type(model) == sklearn.neighbors._classification.KNeighborsClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "        elif type(model) == sklearn.ensemble._forest.RandomForestClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "        elif type(model) ==  sklearn.ensemble._weight_boosting.AdaBoostClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "        elif type(model) == xgboost.sklearn.XGBClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "        elif type(model) == ExplainableBoostingClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "\n",
    "        elif type(model) == statsmodels.discrete.discrete_model.BinaryResultsWrapper:\n",
    "            y_hat = model.predict(X)\n",
    "\n",
    "        else:\n",
    "            raise InputError(\"Unknown model type.\")\n",
    "\n",
    "        y_hat = pd.Series(y_hat, index=X.index)\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def auc(self, y_true, y_hat):\n",
    "        import sklearn.metrics\n",
    "        try:\n",
    "            return sklearn.metrics.roc_auc_score(y_true, y_hat)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    def plot_model_performance(self, auc_train, auc_test, ylim=\"default\"):\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.plot(list(auc_train.keys()), list(auc_train.values()))\n",
    "        plt.plot(list(auc_train.keys()), list(auc_test.values()))\n",
    "        plt.xticks(list(auc_train.keys()), \" \")\n",
    "        plt.ylim(ylim) if ylim != \"default\" else None\n",
    "\n",
    "    def evaluate(\n",
    "            self, df, split_params, model_type, \n",
    "        predict_start='2013-11-30', \n",
    "        predict_end=-1, return_errors=False,\n",
    "            xai=False, weather_sel=False, **args\n",
    "        ):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        dates = (\n",
    "            pd.DataFrame(df.index)\n",
    "            .set_index(df.index)[\"last_updated_ts\"]\n",
    "            .apply(lambda date: str(date)[:10])\n",
    "            .drop_duplicates()\n",
    "        )\n",
    "        predict_start = pd.to_datetime(predict_start)\n",
    "        predict_end = (\n",
    "            pd.to_datetime(dates.iloc[predict_end])\n",
    "            if type(predict_end) == int\n",
    "            else pd.to_datetime(predict_end)\n",
    "         )\n",
    "        dates = dates.loc[predict_start:predict_end]\n",
    "        y_true = []\n",
    "        y_hat_train = {}\n",
    "        y_hat_test = []\n",
    "        y_hat_lime = []\n",
    "        y_hat_shap = []\n",
    "        auc_train_dict = {}\n",
    "        auc_test = []\n",
    "        xai_time_lime = []\n",
    "        xai_time_shap = []\n",
    "\n",
    "        predictions_list = []\n",
    "\n",
    "        if weather_sel:\n",
    "            print(\"Crawl weather data....\")\n",
    "            # Add Weather\n",
    "            ################################\n",
    "            from meteostat import Point, Hourly\n",
    "            from datetime import datetime\n",
    "            \n",
    "            #### need to be coded differently!!####################################\n",
    "            lough = Point(52.766593, -1.223511)\n",
    "            \n",
    "            time = df.index.to_series(name=\"time\").tolist()\n",
    "            weather = Hourly(lough, time[0], time[len(df) - 1])\n",
    "            weather = weather.fetch()\n",
    "\n",
    "            from sklearn.impute import KNNImputer\n",
    "            import numpy as np\n",
    "\n",
    "            headers = weather.columns.values\n",
    "\n",
    "            empty_train_columns = []\n",
    "            for col in weather.columns.values:\n",
    "                if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                    empty_train_columns.append(col)\n",
    "            headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "            imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "            weather = imputer.fit_transform(weather)\n",
    "            scaler = MinMaxScaler()\n",
    "            weather = scaler.fit_transform(weather)\n",
    "            weather = pd.DataFrame(weather)\n",
    "            weather[\"time\"] = time[0:len(weather)]\n",
    "            df[\"time\"] = time\n",
    "\n",
    "            weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "            df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "            df = df.set_index(\"time\")\n",
    "            ################################\n",
    "        if not xai:\n",
    "            for date in tqdm(dates):\n",
    "                errors = {}\n",
    "                try:\n",
    "                    X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                        df, date, **split_params\n",
    "                    )\n",
    "\n",
    "                    # fit model\n",
    "                    model = self.fit(X_train, y_train, model_type, **args)\n",
    "\n",
    "                    y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                    y_hat_test += list(self.predict(model, X_test))\n",
    "\n",
    "                    # evaluate train data\n",
    "                    auc_train_dict.update(\n",
    "                        {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                    )\n",
    "                    y_true += list(y_test)\n",
    "\n",
    "                except Exception as e:\n",
    "                    errors[date] = e\n",
    "        else:\n",
    "            print('The explainability approaches in the Activity Agent are being evaluated for model: ' + str(model_type))\n",
    "            print('Start evaluation with LIME and SHAP')\n",
    "            import time\n",
    "            import lime\n",
    "            from lime import lime_tabular\n",
    "            import shap as shap\n",
    "\n",
    "            for date in tqdm(dates):\n",
    "                errors = {}\n",
    "                try:\n",
    "                    X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                        df, date, **split_params\n",
    "                    )\n",
    "\n",
    "                    # fit model\n",
    "                    model = self.fit(X_train, y_train, model_type)\n",
    "\n",
    "                    # self.predict uses predict_proba i.e. we get probability estimates and not classes\n",
    "                    y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                    y_hat_test += list(self.predict(model, X_test))\n",
    "\n",
    "                    # evaluate train data\n",
    "                    auc_train_dict.update(\n",
    "                        {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                    )\n",
    "                    y_true += list(y_test)\n",
    "\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    if model_type == \"xgboost\":\n",
    "                        booster = model.get_booster()\n",
    "\n",
    "                        explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                                                            feature_names=X_train.columns,\n",
    "                                                                            kernel_width=3, verbose=False)\n",
    "                    else:\n",
    "                        explainer = lime_tabular.LimeTabularExplainer(training_data=np.array(X_train),\n",
    "                                                                        mode=\"classification\",\n",
    "                                                                        feature_names=X_train.columns,\n",
    "                                                                        categorical_features=[0])\n",
    "\n",
    "                    for local in range(len(X_test)):\n",
    "\n",
    "                        if model_type == \"xgboost\":\n",
    "                            exp = explainer.explain_instance(X_test.iloc[local, :].values, model.predict_proba)\n",
    "                        else:\n",
    "                            exp = explainer.explain_instance(data_row=X_test.iloc[local], predict_fn=model.predict_proba)\n",
    "\n",
    "                        y_hat_lime += list(exp.local_pred)\n",
    "\n",
    "\n",
    "                    # take time for each day:\n",
    "                    end_time = time.time()\n",
    "                    difference_time = end_time - start_time\n",
    "\n",
    "                    xai_time_lime.append(difference_time)\n",
    "                    # SHAP\n",
    "                    # ==============================================================================\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    if model_type == \"logit\":\n",
    "                        X_train_summary = shap.sample(X_train, 100)\n",
    "                        explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                    elif model_type == \"ada\":\n",
    "                        X_train_summary = shap.sample(X_train, 100)\n",
    "                        explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                    elif model_type == \"knn\":\n",
    "                        X_train_summary = shap.sample(X_train, 100)\n",
    "                        explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                    elif model_type == \"random forest\":\n",
    "                        X_train_summary = shap.sample(X_train, 100)\n",
    "                        explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                    elif model_type == \"xgboost\":\n",
    "                        explainer = shap.TreeExplainer(model, X_train, model_output='predict_proba')\n",
    "\n",
    "                    elif model_type == \"logit_sm\":\n",
    "                        explainer = shap.TreeExplainer(model.predict, X_train_summary)\n",
    "\n",
    "                    else:\n",
    "                        raise InputError(\"Unknown model type.\")\n",
    "\n",
    "                    base_value = explainer.expected_value[1]  # the mean prediction\n",
    "\n",
    "                    for local in range(len(X_test)):\n",
    "\n",
    "                        shap_values = explainer.shap_values(\n",
    "                            X_test.iloc[local, :])\n",
    "\n",
    "                        contribution_to_class_1 = np.array(shap_values).sum(axis=1)[1]\n",
    "                        shap_prediction = base_value + contribution_to_class_1\n",
    "\n",
    "                        # Prediction from XAI:\n",
    "                        y_hat_shap += list([shap_prediction])\n",
    "\n",
    "\n",
    "                    # take time for each day:\n",
    "                    end_time = time.time()\n",
    "                    difference_time = end_time - start_time\n",
    "                    xai_time_shap.append(difference_time)\n",
    "\n",
    "                except Exception as e:\n",
    "                    errors[date] = e\n",
    "\n",
    "        auc_test = self.auc(y_true, y_hat_test)\n",
    "        auc_train = np.mean(list(auc_train_dict.values()))\n",
    "        predictions_list.append(y_true)\n",
    "        predictions_list.append(y_hat_test)\n",
    "        predictions_list.append(y_hat_lime)\n",
    "        predictions_list.append(y_hat_shap)\n",
    "\n",
    "        # Efficiency\n",
    "        time_mean_lime = np.mean(xai_time_lime)\n",
    "        time_mean_shap = np.mean(xai_time_shap)\n",
    "        print('Mean time nedded by appraoches: ' + str(time_mean_lime) + ' ' + str(time_mean_shap))\n",
    "\n",
    "        if return_errors:\n",
    "            return auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list, errors\n",
    "        else:\n",
    "            return auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list\n",
    "    \n",
    "    \n",
    "    # pipeline function: predicting user activity\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def pipeline(self, df, date, model_type, split_params, weather_sel=False):\n",
    "\n",
    "        if weather_sel:\n",
    "\n",
    "            # Add Weather\n",
    "            ################################\n",
    "            from meteostat import Point, Hourly\n",
    "            from datetime import datetime\n",
    "\n",
    "            lough = Point(52.766593, -1.223511)\n",
    "            time = df.index.to_series(name=\"time\").tolist()\n",
    "            weather = Hourly(lough, time[0], time[len(df) - 1])\n",
    "            weather = weather.fetch()\n",
    "\n",
    "            from sklearn.impute import KNNImputer\n",
    "            import numpy as np\n",
    "\n",
    "            headers = weather.columns.values\n",
    "\n",
    "            empty_train_columns = []\n",
    "            for col in weather.columns.values:\n",
    "                if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                    empty_train_columns.append(col)\n",
    "            headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "            imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "            weather = imputer.fit_transform(weather)\n",
    "            scaler = MinMaxScaler()\n",
    "            weather = scaler.fit_transform(weather)\n",
    "            weather = pd.DataFrame(weather)\n",
    "            weather[\"time\"] = time[0:len(weather)]\n",
    "            df[\"time\"] = time\n",
    "\n",
    "            weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "            df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "            df = df.set_index(\"time\")\n",
    "            ################################\n",
    "\n",
    "        # train test split\n",
    "        X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "            df, date, **split_params\n",
    "        )\n",
    "\n",
    "        # fit model\n",
    "        model = self.fit(X_train, y_train, model_type)\n",
    "\n",
    "        # predict\n",
    "        return self.predict(model, X_test)\n",
    "\n",
    "    # pipeline function: predicting user activity with xai\n",
    "        # -------------------------------------------------------------------------------------------\n",
    "    def pipeline_xai(self, df, date, model_type, split_params, weather_sel=False):\n",
    "\n",
    "        if weather_sel:\n",
    "\n",
    "            # Add Weather\n",
    "            ################################\n",
    "            from meteostat import Point, Hourly\n",
    "            from datetime import datetime\n",
    "\n",
    "            lough = Point(52.766593, -1.223511)\n",
    "            time = df.index.to_series(name=\"time\").tolist()\n",
    "            weather = Hourly(lough, time[0], time[len(df) - 1])\n",
    "            weather = weather.fetch()\n",
    "\n",
    "            from sklearn.impute import KNNImputer\n",
    "            import numpy as np\n",
    "\n",
    "            headers = weather.columns.values\n",
    "\n",
    "            empty_train_columns = []\n",
    "            for col in weather.columns.values:\n",
    "                if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                    empty_train_columns.append(col)\n",
    "            headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "            imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "            weather = imputer.fit_transform(weather)\n",
    "            scaler = MinMaxScaler()\n",
    "            weather = scaler.fit_transform(weather)\n",
    "            weather = pd.DataFrame(weather)\n",
    "            weather[\"time\"] = time[0:len(weather)]\n",
    "            df[\"time\"] = time\n",
    "\n",
    "            weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "            df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "            df = df.set_index(\"time\")\n",
    "\n",
    "            ################################\n",
    "\n",
    "        # train test split\n",
    "        X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "            df, date, **split_params\n",
    "        )\n",
    "\n",
    "        # fit model\n",
    "        model = self.fit(X_train, y_train, model_type)\n",
    "\n",
    "        # predict\n",
    "        return self.predict(model, X_test), X_train, X_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1926,
     "status": "ok",
     "timestamp": 1607622704123,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "knvuAmV2tFpD",
    "outputId": "c9c721aa-2206-490f-9e1f-133d03a0de86",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(last_updated\n",
       " 2023-01-10 00:00:00    0.000000\n",
       " 2023-01-10 01:00:00    0.000000\n",
       " 2023-01-10 02:00:00    0.000000\n",
       " 2023-01-10 03:00:00    0.000000\n",
       " 2023-01-10 04:00:00    0.000000\n",
       " 2023-01-10 05:00:00    0.000000\n",
       " 2023-01-10 06:00:00    0.000000\n",
       " 2023-01-10 07:00:00    0.020174\n",
       " 2023-01-10 08:00:00    0.021150\n",
       " 2023-01-10 09:00:00    0.007169\n",
       " 2023-01-10 10:00:00    0.007351\n",
       " 2023-01-10 11:00:00    0.027342\n",
       " 2023-01-10 12:00:00    0.030069\n",
       " 2023-01-10 13:00:00    0.039465\n",
       " 2023-01-10 14:00:00    0.052502\n",
       " 2023-01-10 15:00:00    0.090741\n",
       " 2023-01-10 16:00:00    0.022990\n",
       " 2023-01-10 17:00:00    0.029199\n",
       " 2023-01-10 18:00:00    0.032115\n",
       " 2023-01-10 19:00:00    0.201129\n",
       " 2023-01-10 20:00:00    0.073589\n",
       " 2023-01-10 21:00:00    0.005285\n",
       " 2023-01-10 22:00:00    0.004285\n",
       " 2023-01-10 23:00:00    0.004285\n",
       " dtype: float64,\n",
       "                      hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       " last_updated                                                                   \n",
       " 2022-12-28 00:00:00     0              1.0              0.0              0.0   \n",
       " 2022-12-28 01:00:00     1              1.0              0.0              0.0   \n",
       " 2022-12-28 02:00:00     2              1.0              0.0              0.0   \n",
       " 2022-12-28 03:00:00     3              1.0              0.0              0.0   \n",
       " 2022-12-28 04:00:00     4              1.0              0.0              0.0   \n",
       " ...                   ...              ...              ...              ...   \n",
       " 2023-01-09 19:00:00    19              0.0              0.0              1.0   \n",
       " 2023-01-09 20:00:00    20              0.0              0.0              1.0   \n",
       " 2023-01-09 21:00:00    21              0.0              0.0              0.0   \n",
       " 2023-01-09 22:00:00    22              0.0              0.0              0.0   \n",
       " 2023-01-09 23:00:00    23              0.0              0.0              0.0   \n",
       " \n",
       "                      day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       " last_updated                                                               \n",
       " 2022-12-28 00:00:00                0                  0                0   \n",
       " 2022-12-28 01:00:00                0                  0                0   \n",
       " 2022-12-28 02:00:00                0                  0                0   \n",
       " 2022-12-28 03:00:00                0                  0                0   \n",
       " 2022-12-28 04:00:00                0                  0                0   \n",
       " ...                              ...                ...              ...   \n",
       " 2023-01-09 19:00:00                1                  0                0   \n",
       " 2023-01-09 20:00:00                1                  0                0   \n",
       " 2023-01-09 21:00:00                1                  0                0   \n",
       " 2023-01-09 22:00:00                1                  0                0   \n",
       " 2023-01-09 23:00:00                1                  0                0   \n",
       " \n",
       "                      day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       " last_updated                                                                  \n",
       " 2022-12-28 00:00:00                  0                 0                   1  \n",
       " 2022-12-28 01:00:00                  0                 0                   1  \n",
       " 2022-12-28 02:00:00                  0                 0                   1  \n",
       " 2022-12-28 03:00:00                  0                 0                   1  \n",
       " 2022-12-28 04:00:00                  0                 0                   1  \n",
       " ...                                ...               ...                 ...  \n",
       " 2023-01-09 19:00:00                  0                 0                   0  \n",
       " 2023-01-09 20:00:00                  0                 0                   0  \n",
       " 2023-01-09 21:00:00                  0                 0                   0  \n",
       " 2023-01-09 22:00:00                  0                 0                   0  \n",
       " 2023-01-09 23:00:00                  0                 0                   0  \n",
       " \n",
       " [312 rows x 10 columns],\n",
       "                      hour  activity_lag_24  activity_lag_48  activity_lag_72  \\\n",
       " last_updated                                                                   \n",
       " 2023-01-10 00:00:00     0              0.0              0.0              0.0   \n",
       " 2023-01-10 01:00:00     1              0.0              0.0              0.0   \n",
       " 2023-01-10 02:00:00     2              0.0              0.0              0.0   \n",
       " 2023-01-10 03:00:00     3              0.0              0.0              0.0   \n",
       " 2023-01-10 04:00:00     4              0.0              0.0              0.0   \n",
       " 2023-01-10 05:00:00     5              0.0              0.0              0.0   \n",
       " 2023-01-10 06:00:00     6              0.0              0.0              0.0   \n",
       " 2023-01-10 07:00:00     7              0.0              0.0              0.0   \n",
       " 2023-01-10 08:00:00     8              0.0              0.0              0.0   \n",
       " 2023-01-10 09:00:00     9              1.0              0.0              0.0   \n",
       " 2023-01-10 10:00:00    10              1.0              0.0              0.0   \n",
       " 2023-01-10 11:00:00    11              0.0              0.0              0.0   \n",
       " 2023-01-10 12:00:00    12              0.0              0.0              0.0   \n",
       " 2023-01-10 13:00:00    13              0.0              0.0              0.0   \n",
       " 2023-01-10 14:00:00    14              0.0              0.0              0.0   \n",
       " 2023-01-10 15:00:00    15              0.0              0.0              0.0   \n",
       " 2023-01-10 16:00:00    16              0.0              1.0              0.0   \n",
       " 2023-01-10 17:00:00    17              0.0              1.0              0.0   \n",
       " 2023-01-10 18:00:00    18              0.0              1.0              0.0   \n",
       " 2023-01-10 19:00:00    19              0.0              0.0              0.0   \n",
       " 2023-01-10 20:00:00    20              0.0              0.0              0.0   \n",
       " 2023-01-10 21:00:00    21              0.0              0.0              0.0   \n",
       " 2023-01-10 22:00:00    22              0.0              0.0              0.0   \n",
       " 2023-01-10 23:00:00    23              0.0              0.0              0.0   \n",
       " \n",
       "                      day_name_Monday  day_name_Saturday  day_name_Sunday  \\\n",
       " last_updated                                                               \n",
       " 2023-01-10 00:00:00                0                  0                0   \n",
       " 2023-01-10 01:00:00                0                  0                0   \n",
       " 2023-01-10 02:00:00                0                  0                0   \n",
       " 2023-01-10 03:00:00                0                  0                0   \n",
       " 2023-01-10 04:00:00                0                  0                0   \n",
       " 2023-01-10 05:00:00                0                  0                0   \n",
       " 2023-01-10 06:00:00                0                  0                0   \n",
       " 2023-01-10 07:00:00                0                  0                0   \n",
       " 2023-01-10 08:00:00                0                  0                0   \n",
       " 2023-01-10 09:00:00                0                  0                0   \n",
       " 2023-01-10 10:00:00                0                  0                0   \n",
       " 2023-01-10 11:00:00                0                  0                0   \n",
       " 2023-01-10 12:00:00                0                  0                0   \n",
       " 2023-01-10 13:00:00                0                  0                0   \n",
       " 2023-01-10 14:00:00                0                  0                0   \n",
       " 2023-01-10 15:00:00                0                  0                0   \n",
       " 2023-01-10 16:00:00                0                  0                0   \n",
       " 2023-01-10 17:00:00                0                  0                0   \n",
       " 2023-01-10 18:00:00                0                  0                0   \n",
       " 2023-01-10 19:00:00                0                  0                0   \n",
       " 2023-01-10 20:00:00                0                  0                0   \n",
       " 2023-01-10 21:00:00                0                  0                0   \n",
       " 2023-01-10 22:00:00                0                  0                0   \n",
       " 2023-01-10 23:00:00                0                  0                0   \n",
       " \n",
       "                      day_name_Thursday  day_name_Tuesday  day_name_Wednesday  \n",
       " last_updated                                                                  \n",
       " 2023-01-10 00:00:00                  0                 1                   0  \n",
       " 2023-01-10 01:00:00                  0                 1                   0  \n",
       " 2023-01-10 02:00:00                  0                 1                   0  \n",
       " 2023-01-10 03:00:00                  0                 1                   0  \n",
       " 2023-01-10 04:00:00                  0                 1                   0  \n",
       " 2023-01-10 05:00:00                  0                 1                   0  \n",
       " 2023-01-10 06:00:00                  0                 1                   0  \n",
       " 2023-01-10 07:00:00                  0                 1                   0  \n",
       " 2023-01-10 08:00:00                  0                 1                   0  \n",
       " 2023-01-10 09:00:00                  0                 1                   0  \n",
       " 2023-01-10 10:00:00                  0                 1                   0  \n",
       " 2023-01-10 11:00:00                  0                 1                   0  \n",
       " 2023-01-10 12:00:00                  0                 1                   0  \n",
       " 2023-01-10 13:00:00                  0                 1                   0  \n",
       " 2023-01-10 14:00:00                  0                 1                   0  \n",
       " 2023-01-10 15:00:00                  0                 1                   0  \n",
       " 2023-01-10 16:00:00                  0                 1                   0  \n",
       " 2023-01-10 17:00:00                  0                 1                   0  \n",
       " 2023-01-10 18:00:00                  0                 1                   0  \n",
       " 2023-01-10 19:00:00                  0                 1                   0  \n",
       " 2023-01-10 20:00:00                  0                 1                   0  \n",
       " 2023-01-10 21:00:00                  0                 1                   0  \n",
       " 2023-01-10 22:00:00                  0                 1                   0  \n",
       " 2023-01-10 23:00:00                  0                 1                   0  ,\n",
       " RandomForestClassifier(max_depth=10, n_estimators=500, n_jobs=-1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity = Activity_Agent(df)\n",
    "\n",
    "date = '2023-01-09'\n",
    "split_params = {'train_start': '', 'test_delta': {'days':1, 'seconds':-1}, 'target': 'activity'}\n",
    "\n",
    "output = activity.pipeline_xai(df, date, 'random forest', split_params)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "executionInfo": {
     "elapsed": 1605,
     "status": "ok",
     "timestamp": 1607622706657,
     "user": {
      "displayName": "Leon H",
      "photoUrl": "",
      "userId": "10150017554198726068"
     },
     "user_tz": -60
    },
    "id": "tmtVlt5AsnqB",
    "outputId": "cf03c690-1404-47b3-fb50-3f08e786adee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output[0].plot();''\n",
    "plt.ylim(-.1, 1.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03a_Activity-Agent.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "272px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "fd19f899bcdfa6c353e9525ef244de6eb28a54f3ba596d530144acef4e3bc685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
