{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DRnXoeZJqNX"
   },
   "source": [
    "# **Usage Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwtXD6qiJx3r"
   },
   "source": [
    "The **Usage Agent's** functionnality is to estimate the probability that a particular device will be used on the following day. Within the general recommendation framework, this function is used in order to limit unnecessary recommendations that could irritate the user. Whenever a device is unlikely to be used on the next day (estimated likelihood below a certain threshold), no recommendation will be made.\n",
    "\n",
    "In the present notebook, we will describe how these probabilities are estimated in detail and define the **Usage Agent** class that will be integrated into the recommendation agent.\n",
    "\n",
    "The Usage Agent will use a ML-algorithm on features extracted from the household's electricity consumption data in order to predict the likelihood of use of devices on the next day. For instance, at a given day t-1, it will use all available consumption data until day t-1 in order to predict device usage on day t. The features we will use can be divided into 3 categories: \n",
    "1. Whether activity has been detected in the house in the preceding days (activity detected by electricity consumption).\n",
    "2. Whether the to-be-prediced-device has been used in the previous days.\n",
    "3. Time dummies.\n",
    "\n",
    "Given the limited number of observations for each household, we will need to restrict the complexity of the ML-Algorithm in use. This is the reason why we will use a logit model with a limited number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1xY9gp_4KqO"
   },
   "source": [
    "## **1. Load And Preprocess Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNx0bpISOLUE"
   },
   "source": [
    "This part's only purpose is to load the data used in the Usage Agent. This process is described in detail in the Preparation Agent. \n",
    "\n",
    "**Note: When computing the script with another Household than Household 1 you might need to adapt some parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17JxNkMHKa27"
   },
   "source": [
    "### **1.1 Initialize And Load Python Scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 24993,
     "status": "ok",
     "timestamp": 1607623227444,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "XSEU7zeN3udE"
   },
   "outputs": [],
   "source": [
    "#please change to the ones where you have codes.\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "os.chdir('/Users/sofyakonchakova/Desktop/HU_Berlin/SIS/codes/')\n",
    "from helper_functions import Helper\n",
    "from PreparationAgent import Preparation_Agent\n",
    "os.chdir('/Users/sofyakonchakova/Desktop/')\n",
    "dbfile = 'home-assistant_Chris.db'\n",
    "helper = Helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###add it to helper function\n",
    "def export_sql(file=dbfile):\n",
    "    with sqlite3.connect(file) as con:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT * FROM states\")\n",
    "        states = cur.fetchall()\n",
    "    from_states_db = []\n",
    "    for result in states:\n",
    "        result = list(result)\n",
    "        from_states_db.append(result)\n",
    "    columns = [\"state_id\",\"entity_id\",\"state\",\"attributes\",\"event_id\",\"last_changed\",\"last_updated\",\"old_state_id\",\"attributes_id\",\"context_id\",\"context_user_id\",\"context_parent_id\",\"origin_idx\"]\n",
    "    states_df = pd.DataFrame(from_states_db, columns = columns)\n",
    "\n",
    "    with sqlite3.connect(file) as con:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"SELECT * FROM state_attributes\")\n",
    "        state_attributes = cur.fetchall()\n",
    "    from_state_attributes_db = []\n",
    "    for result in state_attributes:\n",
    "        result = list(result)\n",
    "        from_state_attributes_db.append(result)\n",
    "    columns = [\"attributes_id\",\"hash\",\"shared_attributes\"]\n",
    "    state_attributes_df = pd.DataFrame(from_state_attributes_db, columns = columns)\n",
    "\n",
    "    output = pd.merge(states_df, state_attributes_df, how= \"left\", on = 'attributes_id')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Preparation_Agent(export_sql(dbfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load household data\n",
    "\n",
    "active_appliances = [573,579,603, 605]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuV9dYlD4Vkv"
   },
   "source": [
    "### **1.2 Set Parameters For Pre-processing Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 24987,
     "status": "ok",
     "timestamp": 1607623227445,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "qw4N4Sq45663"
   },
   "outputs": [],
   "source": [
    "truncation_params = {\n",
    "    'features': 'all', \n",
    "    'factor': 1.5, \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "scale_params = {\n",
    "    'features': 'all', \n",
    "    'kind': 'MinMax', \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "aggregate_params = {\n",
    "    'resample_param': '60T'\n",
    "}\n",
    "aggregate_params24_H = {\n",
    "    'resample_param': '24H'\n",
    "}\n",
    "\n",
    "\n",
    "activity_params = {\n",
    "    'active_appliances': [573,579,603, 605],\n",
    "    'threshold': .15\n",
    "}\n",
    "\n",
    "time_params = {\n",
    "    'features': ['hour', 'day_name']\n",
    "}\n",
    "\n",
    "activity_lag_params = {\n",
    "    'features': ['activity'],\n",
    "    'lags': [24, 48, 72]\n",
    "}\n",
    "\n",
    "shiftable_devices = {573,579}\n",
    "\n",
    "device = {\n",
    "    'threshold' : .15}\n",
    "\n",
    "activity_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'activity': activity_params,\n",
    "    'aggregate_hour': aggregate_params,\n",
    "    'aggregate_day': aggregate_params24_H,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params,\n",
    "    'shiftable_devices' : shiftable_devices,\n",
    "    'device': device\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsQY8RSZKsqL"
   },
   "source": [
    "### **1.3 Pre-process Data For Input In Device_Usage Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 73997,
     "status": "ok",
     "timestamp": 1607623276471,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "AOK_zrFr4aK9",
    "outputId": "239cbff3-d8d0-4a8e-a517-d8e30f8aae3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>579_usage</th>\n",
       "      <th>573_usage</th>\n",
       "      <th>periods_since_last_activity</th>\n",
       "      <th>periods_since_last_579_usage</th>\n",
       "      <th>periods_since_last_573_usage</th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_1</th>\n",
       "      <th>activity_lag_2</th>\n",
       "      <th>activity_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>573_usage_lag_1</th>\n",
       "      <th>573_usage_lag_2</th>\n",
       "      <th>573_usage_lag_3</th>\n",
       "      <th>active_last_2_days</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              activity  579_usage  573_usage  periods_since_last_activity  \\\n",
       "last_updated                                                                \n",
       "2022-11-21           1          0          1                          0.0   \n",
       "2022-11-22           0          0          0                          1.0   \n",
       "2022-11-23           0          0          0                          2.0   \n",
       "2022-11-24           0          0          0                          3.0   \n",
       "2022-11-25           0          0          0                          4.0   \n",
       "\n",
       "              periods_since_last_579_usage  periods_since_last_573_usage  \\\n",
       "last_updated                                                               \n",
       "2022-11-21                             0.0                           0.0   \n",
       "2022-11-22                             2.0                           1.0   \n",
       "2022-11-23                             3.0                           2.0   \n",
       "2022-11-24                             4.0                           3.0   \n",
       "2022-11-25                             5.0                           4.0   \n",
       "\n",
       "              hour  activity_lag_1  activity_lag_2  activity_lag_3  ...  \\\n",
       "last_updated                                                        ...   \n",
       "2022-11-21       0             0.0             0.0             0.0  ...   \n",
       "2022-11-22       0             1.0             0.0             0.0  ...   \n",
       "2022-11-23       0             0.0             1.0             0.0  ...   \n",
       "2022-11-24       0             0.0             0.0             1.0  ...   \n",
       "2022-11-25       0             0.0             0.0             0.0  ...   \n",
       "\n",
       "              573_usage_lag_1  573_usage_lag_2  573_usage_lag_3  \\\n",
       "last_updated                                                      \n",
       "2022-11-21                0.0              0.0              0.0   \n",
       "2022-11-22                1.0              0.0              0.0   \n",
       "2022-11-23                0.0              1.0              0.0   \n",
       "2022-11-24                0.0              0.0              1.0   \n",
       "2022-11-25                0.0              0.0              0.0   \n",
       "\n",
       "              active_last_2_days  day_name_Monday  day_name_Saturday  \\\n",
       "last_updated                                                           \n",
       "2022-11-21                     0                1                  0   \n",
       "2022-11-22                     1                0                  0   \n",
       "2022-11-23                     1                0                  0   \n",
       "2022-11-24                     0                0                  0   \n",
       "2022-11-25                     0                0                  0   \n",
       "\n",
       "              day_name_Sunday  day_name_Thursday  day_name_Tuesday  \\\n",
       "last_updated                                                         \n",
       "2022-11-21                  0                  0                 0   \n",
       "2022-11-22                  0                  0                 1   \n",
       "2022-11-23                  0                  0                 0   \n",
       "2022-11-24                  0                  1                 0   \n",
       "2022-11-25                  0                  0                 0   \n",
       "\n",
       "              day_name_Wednesday  \n",
       "last_updated                      \n",
       "2022-11-21                     0  \n",
       "2022-11-22                     0  \n",
       "2022-11-23                     1  \n",
       "2022-11-24                     0  \n",
       "2022-11-25                     0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the preparation pipeline\n",
    "prep = Preparation_Agent(export_sql(dbfile))\n",
    "df = prep.pipeline_usage(prep.input, activity_pipe_params)\n",
    "\n",
    "#display all potential variables for predicting device usage likelihood\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL6F5tn6dTsf"
   },
   "source": [
    "## **2.  Constructing the Usage Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aU7AQfEYSS6"
   },
   "source": [
    "### **2.1 Initialize Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T09RUToXR93t"
   },
   "source": [
    "First we define the **Usage Agent class**. It takes as input the data generated by the prep.pipeline_usage function computed above, and the name of the device for which predictions should be made (e.g \"Washing Machine\", \"Dishwasher\"etc...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 73988,
     "status": "ok",
     "timestamp": 1607623276472,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "hZgoXyrpdVfn"
   },
   "outputs": [],
   "source": [
    "class Usage_Agent:\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self, input_df, device):\n",
    "        self.input = input_df\n",
    "        self.device = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxZlevgn5nrr"
   },
   "source": [
    "Here we initialize the agent for the device \"Dishwasher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 73985,
     "status": "ok",
     "timestamp": 1607623276473,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "Uh-a4Lmi5l_v"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Usage_Agent_i = Usage_Agent(df, 573) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlu2qQ8BYXl9"
   },
   "source": [
    "### **2.2 Train_test_split function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQ_GrCnOVc2X"
   },
   "source": [
    "The number of data points available to make a prediction for day t increases by one, each time t increases by one. Therefore, we define a custom train_test_split function that automatically puts all data available until day t-1 (incl.) into the training set. The Data for day t (= prediction day) comes into the test set.\n",
    "\n",
    "In order to limit over-fitting the function also filters out the number of features to be taken into account to train the model. Here these are the following:\n",
    "\n",
    "1. Indicator of device usage at day t-1.\n",
    "2. Indicator of device usage at day t-2.\n",
    "3. Indicator of activity in the household in the past two days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 73981,
     "status": "ok",
     "timestamp": 1607623276474,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "UYOZSfdNVKCd"
   },
   "outputs": [],
   "source": [
    "#date: the day of prediction\n",
    "#train start: the day from which training starts\n",
    "def train_test_split(self, df, date, train_start='2022-11-22'):\n",
    "    #restrict number of variables\n",
    "    select_vars =  [str(self.device) + '_usage', str(self.device)+ '_usage_lag_1', str(self.device)+ '_usage_lag_2',\t'active_last_2_days']\n",
    "    df = df[select_vars]\n",
    "    #spli train and test\n",
    "    X_train = df.loc[train_start:date, df.columns != str(self.device) + '_usage']\n",
    "    y_train = df.loc[train_start:date, df.columns == str(self.device) + '_usage']\n",
    "    X_test  = df.loc[date, df.columns != str(self.device) + '_usage']\n",
    "    y_test  = df.loc[date , df.columns == str(self.device) + '_usage']\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'train_test_split', train_test_split)\n",
    "del train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BeEm4w6ZP1n"
   },
   "source": [
    "Ouput:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 73978,
     "status": "ok",
     "timestamp": 1607623276474,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "1eQ_lkg_l9-C"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = Usage_Agent_i.train_test_split(df, \"2022-11-30\", train_start='2012-11-22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 73976,
     "status": "ok",
     "timestamp": 1607623276476,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "UCSNjGPUX3aT",
    "outputId": "8c49dba4-26f3-4a25-d1b6-0b69675816ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>573_usage_lag_1</th>\n",
       "      <th>573_usage_lag_2</th>\n",
       "      <th>active_last_2_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              573_usage_lag_1  573_usage_lag_2  active_last_2_days\n",
       "last_updated                                                      \n",
       "2022-11-21                0.0              0.0                   0\n",
       "2022-11-22                1.0              0.0                   1\n",
       "2022-11-23                0.0              1.0                   1\n",
       "2022-11-24                0.0              0.0                   0\n",
       "2022-11-25                0.0              0.0                   0\n",
       "2022-11-26                0.0              0.0                   0\n",
       "2022-11-27                0.0              0.0                   0\n",
       "2022-11-28                0.0              0.0                   0\n",
       "2022-11-29                0.0              0.0                   0\n",
       "2022-11-30                0.0              0.0                   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73968,
     "status": "ok",
     "timestamp": 1607623276477,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "_iFxM9dUX693",
    "outputId": "e46df0a4-d69e-4c47-daa2-3d1996eaf48b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573_usage_lag_1       0.0\n",
       "573_usage_lag_2       0.0\n",
       "active_last_2_days    1.0\n",
       "Name: 2022-11-30 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 73963,
     "status": "ok",
     "timestamp": 1607623276478,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "mcO6tljKX9wf",
    "outputId": "d42133da-e6be-457a-e269-7ef0d08f35e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>573_usage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              573_usage\n",
       "last_updated           \n",
       "2022-11-21            1\n",
       "2022-11-22            0\n",
       "2022-11-23            0\n",
       "2022-11-24            0\n",
       "2022-11-25            0\n",
       "2022-11-26            0\n",
       "2022-11-27            0\n",
       "2022-11-28            0\n",
       "2022-11-29            0\n",
       "2022-11-30            1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73957,
     "status": "ok",
     "timestamp": 1607623276479,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "TIqYYx7AX_7c",
    "outputId": "6b956628-c21b-4aa7-fa70-a471a0fa1404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573_usage    1.0\n",
       "Name: 2022-11-30 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yp_Q2mbNq7SI"
   },
   "source": [
    "### **2.3 Fitting Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "901Rnq25Y58c"
   },
   "source": [
    "Now that we have the function to perform the split-sampling we can fit the model on training data. For that purpose, we define a Logit-fitting function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 73953,
     "status": "ok",
     "timestamp": 1607623276480,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "IuwCUQb9q9tH"
   },
   "outputs": [],
   "source": [
    "def fit_smLogit(self, X, y):\n",
    "    import statsmodels.api as sm\n",
    "    return sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'fit_smLogit', fit_smLogit)\n",
    "del fit_smLogit \n",
    "\n",
    "def fit(self, X, y, model_type):\n",
    "    if model_type == 'logit':\n",
    "        model = self.fit_smLogit(X, y)\n",
    "    else:\n",
    "        raise InputError('Unknown model type.')\n",
    "    return model\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'fit', fit)\n",
    "del fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMxMWE5zZ1PE"
   },
   "source": [
    "Using this function on the training split, we can train our first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74957,
     "status": "ok",
     "timestamp": 1607623277488,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "38OdZOcTrve-",
    "outputId": "d79773c9-60b9-4f27-8dba-aa67c27e07b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:              573_usage   No. Observations:                   10\n",
      "Model:                          Logit   Df Residuals:                        7\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Tue, 13 Dec 2022   Pseudo R-squ.:                 0.03037\n",
      "Time:                        17:09:49   Log-Likelihood:                -4.8520\n",
      "converged:                      False   LL-Null:                       -5.0040\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.8590\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "573_usage_lag_1      -54.7482   8.78e+06  -6.24e-06      1.000   -1.72e+07    1.72e+07\n",
      "573_usage_lag_2      -54.7482   8.78e+06  -6.24e-06      1.000   -1.72e+07    1.72e+07\n",
      "active_last_2_days    22.7723   8.81e+04      0.000      1.000   -1.73e+05    1.73e+05\n",
      "======================================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.30 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofyakonchakova/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    }
   ],
   "source": [
    "usage = Usage_Agent(df, 573)\n",
    "model = usage.fit(X_train, y_train, 'logit')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 74954,
     "status": "ok",
     "timestamp": 1607623277490,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "a0iwlva2Hy-n",
    "outputId": "7d2d46a3-c8ce-4345-e153-83c3ec54b4ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>573_usage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-21</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-22</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-23</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-29</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              573_usage\n",
       "last_updated           \n",
       "2022-11-21            1\n",
       "2022-11-22            0\n",
       "2022-11-23            0\n",
       "2022-11-24            0\n",
       "2022-11-25            0\n",
       "2022-11-26            0\n",
       "2022-11-27            0\n",
       "2022-11-28            0\n",
       "2022-11-29            0\n",
       "2022-11-30            1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_my8fyn4d-k"
   },
   "source": [
    "Once the model is fitted to the training data, a prediction can be made for the test day. This prediction function is defined in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 74947,
     "status": "ok",
     "timestamp": 1607623277491,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "HVtiJ92utWbo"
   },
   "outputs": [],
   "source": [
    "def predict(self, model, X):\n",
    "    import statsmodels\n",
    "    import numpy as np\n",
    "    X = np.array(X)\n",
    "\n",
    "    if type(model) == statsmodels.discrete.discrete_model.BinaryResultsWrapper:\n",
    "        y_hat = model.predict(X)\n",
    "    else:\n",
    "        raise InputError('Unknown model type.')\n",
    "    return y_hat\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'predict', predict)\n",
    "del predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74944,
     "status": "ok",
     "timestamp": 1607623277492,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "DbbWXy2Ftd5v",
    "outputId": "b9a38e75-e08e-42fc-b694-f5434f9f7705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute prediction at day t (see date used for split sampling)\n",
    "import numpy as np\n",
    "y_hat = usage.predict(model, X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLOHQvFv_GXI"
   },
   "source": [
    "### **2.4 Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuQrieip1S6X"
   },
   "source": [
    "Finally, we wrap up all the previously defined functions into the **pipeline** function. This allows to generate a prediction by simply inputting:\n",
    "* the pre-processed usage data\n",
    "* the prediction date\n",
    "* the model type (limited to logit for now)\n",
    "* the date at which the model has started to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 74939,
     "status": "ok",
     "timestamp": 1607623277492,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "_i8kTixg_Nvu"
   },
   "outputs": [],
   "source": [
    "def pipeline(self, df, date, model_type, train_start):\n",
    "    X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)\n",
    "\n",
    "    # fit model\n",
    "    model = self.fit(X_train, y_train, model_type)\n",
    "\n",
    "    # predict\n",
    "    return self.predict(model, X_test)\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'pipeline', pipeline)\n",
    "del pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAexapts5BYv"
   },
   "source": [
    "A prediction for the \"2013-12-08\" based on the data starting on the '2013-11-01' can finally be made for the device with which we initialized the class (here: \"Dishwasher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74936,
     "status": "ok",
     "timestamp": 1607623277493,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "CXUmgFdK_Z03",
    "outputId": "dd3f42a0-89fe-437d-b00f-cde1b4bb9030"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofyakonchakova/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = \"2022-11-30\"\n",
    "train_start = '2022-11-21'\n",
    "usage.pipeline(df, date, 'logit', train_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5cE1DjO6ojI"
   },
   "source": [
    "### **2.5 Model Evaluation**\n",
    "\n",
    "Finally, we want to assess the accuracy of our model before using it in the Recommendation Agent. \n",
    "\n",
    "A drawback to our approach is that we are not able to apply conventional model evaluation techniques to our model. We will train our model for each day to account for newly available information. Hence, we have different train and test sets for each day and for each day different performance metric based on the respective data sets. Therefore, we created our own evaluation function. \n",
    "\n",
    "Our evaluation function will build a model, fit the model and predict the target for each day for a given prediction period. For each day and fitted model it will calculate a performance metric on the train data. We chose the Area Under the Receiver Operating Characteristic Curve (AUC) as performance metric for our binary classification task. As in our case the test data is only the current date to be predicted, we calculate the test AUC over the usage probabilities of all day after all days have been predicted. To summarize the train AUC in one score, we apply an average over all calculated train AUC scores (Note: This approach is the same as for the activity predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 74932,
     "status": "ok",
     "timestamp": 1607623277494,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "GumQPIhDOM5m"
   },
   "outputs": [],
   "source": [
    "def auc(self, y_true, y_hat):\n",
    "    import sklearn.metrics\n",
    "    return sklearn.metrics.roc_auc_score(y_true, y_hat)\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'auc', auc)\n",
    "del auc\n",
    "\n",
    "def evaluate(self, df, model_type, train_start, predict_start='2022-11-21', predict_end=-1):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    dates = pd.DataFrame(df.index)\n",
    "    dates = dates.set_index(df.index)['last_updated']\n",
    "    predict_start = pd.to_datetime(predict_start)\n",
    "    predict_end = pd.to_datetime(dates.iloc[predict_end]) if type(predict_end) == int else pd.to_datetime(predict_end)\n",
    "    dates = dates.loc[predict_start:predict_end]\n",
    "    y_true = []\n",
    "    y_hat_train = {}\n",
    "    y_hat_test = []\n",
    "    auc_train_dict = {}\n",
    "    auc_test = []\n",
    "\n",
    "    for date in dates.index:\n",
    "        # train test split\n",
    "        #train_test_split(self, df, date, train_start='2013-11-01', test_delta='all', target='activity')\n",
    "        X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)\n",
    "\n",
    "        # fit model\n",
    "        model = self.fit(X_train, y_train, model_type)\n",
    "\n",
    "        # predict\n",
    "        y_hat_train.update({date: self.predict(model, X_train)})\n",
    "        y_hat_test += list(self.predict(model, X_test))\n",
    "\n",
    "        # evaluate train data\n",
    "        auc_train_dict.update({date: self.auc(y_train, list(y_hat_train.values())[-1])})\n",
    "        \n",
    "        y_true += list(y_test)\n",
    "    \n",
    "    auc_test = self.auc(y_true, y_hat_test)\n",
    "    auc_train = np.mean(list(auc_train_dict.values()))\n",
    "\n",
    "    return auc_train, auc_test, auc_train_dict\n",
    "\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'evaluate', evaluate)\n",
    "del evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYtHJpERPikJ"
   },
   "source": [
    "Finally, we can evaluate the simple Logit model for the \"Dishwasher\", for instance for all predictions after the \"2014-08-01\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79708,
     "status": "ok",
     "timestamp": 1607623282273,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "xqaxt7-b9SfE",
    "outputId": "86e00cfb-e9fc-4ba2-cc23-a33c7a1c2755"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nz/fr0fhqq53cl3b9cq3jwbk1640000gn/T/ipykernel_23718/1114519845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_train_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"logit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2022-12-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2022-11-21'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_end\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean_auc_on_train = \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" | test_auc = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/nz/fr0fhqq53cl3b9cq3jwbk1640000gn/T/ipykernel_23718/463613682.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, df, model_type, train_start, predict_start, predict_end)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/nz/fr0fhqq53cl3b9cq3jwbk1640000gn/T/ipykernel_23718/4277350195.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, model_type)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'logit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_smLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mInputError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown model type.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/nz/fr0fhqq53cl3b9cq3jwbk1640000gn/T/ipykernel_23718/4277350195.py\u001b[0m in \u001b[0;36mfit_smLogit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_smLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# add to Activity agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# unconditional check, requires no extra kwargs added by subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_rank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendog\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/discrete/discrete_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_rank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_rank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_on_perfect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'missing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hasconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[1;32m     93\u001b[0m                                       **kwargs)\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[1;32m    674\u001b[0m                  **kwargs)\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/statsmodels/base/data.py\u001b[0m in \u001b[0;36m_handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# detect where the constant is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mcheck_implicit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mexog_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mMissingDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exog contains inf or nans'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2752\u001b[0m     \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m     \"\"\"\n\u001b[0;32m-> 2754\u001b[0;31m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[1;32m   2755\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Conda/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "auc_train, auc_test, auc_train_dict = usage.evaluate(df, \"logit\", '2022-12-01', predict_start='2022-11-21', predict_end= -1)\n",
    "print(\"mean_auc_on_train = \"+ str(auc_train) + \" | test_auc = \" + str(auc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nf8rKaVRNW-"
   },
   "source": [
    "As can be seen above, the model's performance is quite disappointing. It is not surprising that we do not have a very high accuracy, given the little amount of data we have. However, there must be potential for improvment. A first step in that direction would be a proper feature selection methodology taking into account different devices and households. Moreover, there has been a large decrease in model accuracy after changing the pre-processing pipeline methodology. Therefore, it seems that the model is sensitive to the way we detect the devices' activity. In the next steps we should investigate how and why these pre-processing steps impact the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYF4hPeeDFtA"
   },
   "source": [
    "## **Appendix A1: Complete Usage Agent Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 79706,
     "status": "ok",
     "timestamp": 1607623282274,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "FllI0166G0lz"
   },
   "outputs": [],
   "source": [
    "class Usage_Agent:\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self, input_df, device):\n",
    "        self.input = input_df\n",
    "        self.device = device\n",
    "\n",
    "    # train test split\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def train_test_split(self, df, date, train_start=\"2013-11-01\"):\n",
    "        select_vars = [\n",
    "            self.device + \"_usage\",\n",
    "            self.device + \"_usage_lag_1\",\n",
    "            self.device + \"_usage_lag_2\",\n",
    "            \"active_last_2_days\",\n",
    "        ]\n",
    "        df = df[select_vars]\n",
    "        X_train = df.loc[train_start:date, df.columns != self.device + \"_usage\"]\n",
    "        y_train = df.loc[train_start:date, df.columns == self.device + \"_usage\"]\n",
    "        X_test = df.loc[date, df.columns != self.device + \"_usage\"]\n",
    "        y_test = df.loc[date, df.columns == self.device + \"_usage\"]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    # model training and evaluation\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def fit_smLogit(self, X, y):\n",
    "        import statsmodels.api as sm\n",
    "\n",
    "        return sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "    def fit(self, X, y, model_type):\n",
    "        if model_type == \"logit\":\n",
    "            model = self.fit_smLogit(X, y)\n",
    "        else:\n",
    "            raise InputError(\"Unknown model type.\")\n",
    "        return model\n",
    "\n",
    "    def predict(self, model, X):\n",
    "        import statsmodels\n",
    "        import numpy as np\n",
    "\n",
    "        X = np.array(X)\n",
    "\n",
    "        if type(model) == statsmodels.discrete.discrete_model.BinaryResultsWrapper:\n",
    "            y_hat = model.predict(X)\n",
    "        else:\n",
    "            raise InputError(\"Unknown model type.\")\n",
    "        return y_hat\n",
    "\n",
    "    \n",
    "    def auc(self, y_true, y_hat):\n",
    "        import sklearn.metrics\n",
    "        return sklearn.metrics.roc_auc_score(y_true, y_hat)\n",
    "    \n",
    "    def evaluate(\n",
    "        self, df, model_type, train_start, predict_start=\"2014-01-01\", predict_end=-1, return_errors=False\n",
    "    ):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        dates = pd.DataFrame(df.index)\n",
    "        dates = dates.set_index(df.index)[\"Time\"]\n",
    "        predict_start = pd.to_datetime(predict_start)\n",
    "        predict_end = (\n",
    "            pd.to_datetime(dates.iloc[predict_end])\n",
    "            if type(predict_end) == int\n",
    "            else pd.to_datetime(predict_end)\n",
    "        )\n",
    "        dates = dates.loc[predict_start:predict_end]\n",
    "        y_true = []\n",
    "        y_hat_train = {}\n",
    "        y_hat_test = []\n",
    "        auc_train_dict = {}\n",
    "        auc_test = []\n",
    "\n",
    "        for date in tqdm(dates.index):\n",
    "            errors = {}\n",
    "            try:\n",
    "                X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                    df, date, train_start\n",
    "                )\n",
    "                # fit model\n",
    "                model = self.fit(X_train, y_train, model_type)\n",
    "                # predict\n",
    "                y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                y_hat_test += list(self.predict(model, X_test))\n",
    "                # evaluate train data\n",
    "                auc_train_dict.update(\n",
    "                    {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                )\n",
    "                y_true += list(y_test)\n",
    "            except Exception as e:\n",
    "                errors[date] = e\n",
    "\n",
    "        auc_test = self.auc(y_true, y_hat_test)\n",
    "        auc_train = np.mean(list(auc_train_dict.values()))\n",
    "\n",
    "        if return_errors:\n",
    "            return auc_train, auc_test, auc_train_dict, errors\n",
    "        else:\n",
    "            return auc_train, auc_test, auc_train_dict\n",
    "        \n",
    "    # pipeline function: predicting device usage\n",
    "    # -------------------------------------------------------------------------------------------        \n",
    "    def pipeline(self, df, date, model_type, train_start):\n",
    "        X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)\n",
    "        model = self.fit(X_train, y_train, model_type)\n",
    "        return self.predict(model, X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03b_Usage_Agent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd19f899bcdfa6c353e9525ef244de6eb28a54f3ba596d530144acef4e3bc685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
