{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DRnXoeZJqNX"
   },
   "source": [
    "# **Usage Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwtXD6qiJx3r"
   },
   "source": [
    "The **Usage Agent's** functionnality is to estimate the probability that a particular device will be used on the following day. Within the general recommendation framework, this function is used in order to limit unnecessary recommendations that could irritate the user. Whenever a device is unlikely to be used on the next day (estimated likelihood below a certain threshold), no recommendation will be made.\n",
    "\n",
    "In the present notebook, we will describe how these probabilities are estimated in detail and define the **Usage Agent** class that will be integrated into the recommendation agent.\n",
    "\n",
    "The Usage Agent will use a ML-algorithm on features extracted from the household's electricity consumption data in order to predict the likelihood of use of devices on the next day. For instance, at a given day t-1, it will use all available consumption data until day t-1 in order to predict device usage on day t. The features we will use can be divided into 3 categories: \n",
    "1. Whether activity has been detected in the house in the preceding days (activity detected by electricity consumption).\n",
    "2. Whether the to-be-prediced-device has been used in the previous days.\n",
    "3. Time dummies.\n",
    "\n",
    "Given the limited number of observations for each household, we will need to restrict the complexity of the ML-Algorithm in use. This is the reason why we will use a logit model with a limited number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1xY9gp_4KqO"
   },
   "source": [
    "## **1. Load And Preprocess Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNx0bpISOLUE"
   },
   "source": [
    "This part's only purpose is to load the data used in the Usage Agent. This process is described in detail in the Preparation Agent. \n",
    "\n",
    "**Note: When computing the script with another Household than Household 1 you might need to adapt some parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17JxNkMHKa27"
   },
   "source": [
    "### **1.1 Initialize And Load Python Scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "dir = 'D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main'\n",
    "os.chdir(dir)\n",
    "\n",
    "from helper_functions import Helper\n",
    "from agents import Preparation_Agent\n",
    "import pandas as pd\n",
    "\n",
    "helper = Helper()\n",
    "\n",
    "dbfile  = \"D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main/home-assistant_Chris_v3.db\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import sklearn\n",
    "import statsmodels\n",
    "from interpret.glassbox.ebm.ebm import ExplainableBoostingClassifier     \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost\n",
    "import statsmodels.api\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuV9dYlD4Vkv"
   },
   "source": [
    "### **1.2 Set Parameters For Pre-processing Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 24987,
     "status": "ok",
     "timestamp": 1607623227445,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "qw4N4Sq45663"
   },
   "outputs": [],
   "source": [
    "shiftable_devices = [\"sensor.shellyplug_s_4022d88961b4_power\", \"sensor.shellyplug_s_4022d88984b8_power\"]\n",
    "\n",
    "truncation_params = {\n",
    "    'features': 'all', \n",
    "    'factor': 1.5, \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "scale_params = {\n",
    "    'features': 'all', \n",
    "    'kind': 'MinMax', \n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "aggregate_params = {\n",
    "    'resample_param': '60T'\n",
    "}\n",
    "aggregate_params24_H = {\n",
    "    'resample_param': '24H'\n",
    "}\n",
    "\n",
    "\n",
    "activity_params = {\n",
    "    'active_appliances': shiftable_devices,\n",
    "    'threshold': .15\n",
    "}\n",
    "\n",
    "time_params = {\n",
    "    'features': ['hour', 'day_name']\n",
    "}\n",
    "\n",
    "activity_lag_params = {\n",
    "    'features': ['activity'],\n",
    "    'lags': [24, 48, 72]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "device = {\n",
    "    'threshold' : .15}\n",
    "\n",
    "usage_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'activity': activity_params,\n",
    "    'aggregate_hour': aggregate_params,\n",
    "    'aggregate_day': aggregate_params24_H,\n",
    "    'time': time_params,\n",
    "    'activity_lag': activity_lag_params,\n",
    "    'shiftable_devices' : shiftable_devices,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "date = '2023-01-08'\n",
    "model_type = 'random forest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsQY8RSZKsqL"
   },
   "source": [
    "### **1.3 Pre-process Data For Input In Device_Usage Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 73997,
     "status": "ok",
     "timestamp": 1607623276471,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "AOK_zrFr4aK9",
    "outputId": "239cbff3-d8d0-4a8e-a517-d8e30f8aae3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>sensor.shellyplug_s_4022d88961b4_power_usage</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power_usage</th>\n",
       "      <th>periods_since_last_activity</th>\n",
       "      <th>periods_since_last_sensor.shellyplug_s_4022d88961b4_power_usage</th>\n",
       "      <th>periods_since_last_sensor.shellyplug_s_4022d88984b8_power_usage</th>\n",
       "      <th>hour</th>\n",
       "      <th>activity_lag_1</th>\n",
       "      <th>activity_lag_2</th>\n",
       "      <th>activity_lag_3</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power_usage_lag_1</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power_usage_lag_2</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power_usage_lag_3</th>\n",
       "      <th>active_last_2_days</th>\n",
       "      <th>day_name_Monday</th>\n",
       "      <th>day_name_Saturday</th>\n",
       "      <th>day_name_Sunday</th>\n",
       "      <th>day_name_Thursday</th>\n",
       "      <th>day_name_Tuesday</th>\n",
       "      <th>day_name_Wednesday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              activity  sensor.shellyplug_s_4022d88961b4_power_usage  \\\n",
       "last_updated                                                           \n",
       "2022-12-25           1                                             1   \n",
       "2022-12-26           1                                             1   \n",
       "2022-12-27           1                                             1   \n",
       "2022-12-28           0                                             0   \n",
       "2022-12-29           1                                             1   \n",
       "2022-12-30           1                                             1   \n",
       "2022-12-31           1                                             0   \n",
       "2023-01-01           1                                             0   \n",
       "2023-01-02           1                                             1   \n",
       "2023-01-03           0                                             0   \n",
       "2023-01-04           0                                             0   \n",
       "2023-01-05           0                                             0   \n",
       "2023-01-06           1                                             0   \n",
       "2023-01-07           0                                             0   \n",
       "2023-01-08           1                                             1   \n",
       "2023-01-09           1                                             0   \n",
       "\n",
       "              sensor.shellyplug_s_4022d88984b8_power_usage  \\\n",
       "last_updated                                                 \n",
       "2022-12-25                                               1   \n",
       "2022-12-26                                               1   \n",
       "2022-12-27                                               1   \n",
       "2022-12-28                                               0   \n",
       "2022-12-29                                               0   \n",
       "2022-12-30                                               1   \n",
       "2022-12-31                                               1   \n",
       "2023-01-01                                               1   \n",
       "2023-01-02                                               0   \n",
       "2023-01-03                                               0   \n",
       "2023-01-04                                               0   \n",
       "2023-01-05                                               0   \n",
       "2023-01-06                                               1   \n",
       "2023-01-07                                               0   \n",
       "2023-01-08                                               0   \n",
       "2023-01-09                                               1   \n",
       "\n",
       "              periods_since_last_activity  \\\n",
       "last_updated                                \n",
       "2022-12-25                            NaN   \n",
       "2022-12-26                            1.0   \n",
       "2022-12-27                            1.0   \n",
       "2022-12-28                            1.0   \n",
       "2022-12-29                            2.0   \n",
       "2022-12-30                            1.0   \n",
       "2022-12-31                            1.0   \n",
       "2023-01-01                            1.0   \n",
       "2023-01-02                            1.0   \n",
       "2023-01-03                            1.0   \n",
       "2023-01-04                            2.0   \n",
       "2023-01-05                            3.0   \n",
       "2023-01-06                            4.0   \n",
       "2023-01-07                            1.0   \n",
       "2023-01-08                            2.0   \n",
       "2023-01-09                            1.0   \n",
       "\n",
       "              periods_since_last_sensor.shellyplug_s_4022d88961b4_power_usage  \\\n",
       "last_updated                                                                    \n",
       "2022-12-25                                                  NaN                 \n",
       "2022-12-26                                                  1.0                 \n",
       "2022-12-27                                                  1.0                 \n",
       "2022-12-28                                                  1.0                 \n",
       "2022-12-29                                                  2.0                 \n",
       "2022-12-30                                                  1.0                 \n",
       "2022-12-31                                                  1.0                 \n",
       "2023-01-01                                                  2.0                 \n",
       "2023-01-02                                                  3.0                 \n",
       "2023-01-03                                                  1.0                 \n",
       "2023-01-04                                                  2.0                 \n",
       "2023-01-05                                                  3.0                 \n",
       "2023-01-06                                                  4.0                 \n",
       "2023-01-07                                                  5.0                 \n",
       "2023-01-08                                                  6.0                 \n",
       "2023-01-09                                                  1.0                 \n",
       "\n",
       "              periods_since_last_sensor.shellyplug_s_4022d88984b8_power_usage  \\\n",
       "last_updated                                                                    \n",
       "2022-12-25                                                  NaN                 \n",
       "2022-12-26                                                  1.0                 \n",
       "2022-12-27                                                  1.0                 \n",
       "2022-12-28                                                  1.0                 \n",
       "2022-12-29                                                  2.0                 \n",
       "2022-12-30                                                  3.0                 \n",
       "2022-12-31                                                  1.0                 \n",
       "2023-01-01                                                  1.0                 \n",
       "2023-01-02                                                  1.0                 \n",
       "2023-01-03                                                  2.0                 \n",
       "2023-01-04                                                  3.0                 \n",
       "2023-01-05                                                  4.0                 \n",
       "2023-01-06                                                  5.0                 \n",
       "2023-01-07                                                  1.0                 \n",
       "2023-01-08                                                  2.0                 \n",
       "2023-01-09                                                  3.0                 \n",
       "\n",
       "              hour  activity_lag_1  activity_lag_2  activity_lag_3  ...  \\\n",
       "last_updated                                                        ...   \n",
       "2022-12-25       0             NaN             NaN             NaN  ...   \n",
       "2022-12-26       0             1.0             NaN             NaN  ...   \n",
       "2022-12-27       0             1.0             1.0             NaN  ...   \n",
       "2022-12-28       0             1.0             1.0             1.0  ...   \n",
       "2022-12-29       0             0.0             1.0             1.0  ...   \n",
       "2022-12-30       0             1.0             0.0             1.0  ...   \n",
       "2022-12-31       0             1.0             1.0             0.0  ...   \n",
       "2023-01-01       0             1.0             1.0             1.0  ...   \n",
       "2023-01-02       0             1.0             1.0             1.0  ...   \n",
       "2023-01-03       0             1.0             1.0             1.0  ...   \n",
       "2023-01-04       0             0.0             1.0             1.0  ...   \n",
       "2023-01-05       0             0.0             0.0             1.0  ...   \n",
       "2023-01-06       0             0.0             0.0             0.0  ...   \n",
       "2023-01-07       0             1.0             0.0             0.0  ...   \n",
       "2023-01-08       0             0.0             1.0             0.0  ...   \n",
       "2023-01-09       0             1.0             0.0             1.0  ...   \n",
       "\n",
       "              sensor.shellyplug_s_4022d88984b8_power_usage_lag_1  \\\n",
       "last_updated                                                       \n",
       "2022-12-25                                                  NaN    \n",
       "2022-12-26                                                  1.0    \n",
       "2022-12-27                                                  1.0    \n",
       "2022-12-28                                                  1.0    \n",
       "2022-12-29                                                  0.0    \n",
       "2022-12-30                                                  0.0    \n",
       "2022-12-31                                                  1.0    \n",
       "2023-01-01                                                  1.0    \n",
       "2023-01-02                                                  1.0    \n",
       "2023-01-03                                                  0.0    \n",
       "2023-01-04                                                  0.0    \n",
       "2023-01-05                                                  0.0    \n",
       "2023-01-06                                                  0.0    \n",
       "2023-01-07                                                  1.0    \n",
       "2023-01-08                                                  0.0    \n",
       "2023-01-09                                                  0.0    \n",
       "\n",
       "              sensor.shellyplug_s_4022d88984b8_power_usage_lag_2  \\\n",
       "last_updated                                                       \n",
       "2022-12-25                                                  NaN    \n",
       "2022-12-26                                                  NaN    \n",
       "2022-12-27                                                  1.0    \n",
       "2022-12-28                                                  1.0    \n",
       "2022-12-29                                                  1.0    \n",
       "2022-12-30                                                  0.0    \n",
       "2022-12-31                                                  0.0    \n",
       "2023-01-01                                                  1.0    \n",
       "2023-01-02                                                  1.0    \n",
       "2023-01-03                                                  1.0    \n",
       "2023-01-04                                                  0.0    \n",
       "2023-01-05                                                  0.0    \n",
       "2023-01-06                                                  0.0    \n",
       "2023-01-07                                                  0.0    \n",
       "2023-01-08                                                  1.0    \n",
       "2023-01-09                                                  0.0    \n",
       "\n",
       "              sensor.shellyplug_s_4022d88984b8_power_usage_lag_3  \\\n",
       "last_updated                                                       \n",
       "2022-12-25                                                  NaN    \n",
       "2022-12-26                                                  NaN    \n",
       "2022-12-27                                                  NaN    \n",
       "2022-12-28                                                  1.0    \n",
       "2022-12-29                                                  1.0    \n",
       "2022-12-30                                                  1.0    \n",
       "2022-12-31                                                  0.0    \n",
       "2023-01-01                                                  0.0    \n",
       "2023-01-02                                                  1.0    \n",
       "2023-01-03                                                  1.0    \n",
       "2023-01-04                                                  1.0    \n",
       "2023-01-05                                                  0.0    \n",
       "2023-01-06                                                  0.0    \n",
       "2023-01-07                                                  0.0    \n",
       "2023-01-08                                                  0.0    \n",
       "2023-01-09                                                  1.0    \n",
       "\n",
       "              active_last_2_days  day_name_Monday  day_name_Saturday  \\\n",
       "last_updated                                                           \n",
       "2022-12-25                     0                0                  0   \n",
       "2022-12-26                     1                1                  0   \n",
       "2022-12-27                     1                0                  0   \n",
       "2022-12-28                     1                0                  0   \n",
       "2022-12-29                     1                0                  0   \n",
       "2022-12-30                     1                0                  0   \n",
       "2022-12-31                     1                0                  1   \n",
       "2023-01-01                     1                0                  0   \n",
       "2023-01-02                     1                1                  0   \n",
       "2023-01-03                     1                0                  0   \n",
       "2023-01-04                     1                0                  0   \n",
       "2023-01-05                     0                0                  0   \n",
       "2023-01-06                     0                0                  0   \n",
       "2023-01-07                     1                0                  1   \n",
       "2023-01-08                     1                0                  0   \n",
       "2023-01-09                     1                1                  0   \n",
       "\n",
       "              day_name_Sunday  day_name_Thursday  day_name_Tuesday  \\\n",
       "last_updated                                                         \n",
       "2022-12-25                  1                  0                 0   \n",
       "2022-12-26                  0                  0                 0   \n",
       "2022-12-27                  0                  0                 1   \n",
       "2022-12-28                  0                  0                 0   \n",
       "2022-12-29                  0                  1                 0   \n",
       "2022-12-30                  0                  0                 0   \n",
       "2022-12-31                  0                  0                 0   \n",
       "2023-01-01                  1                  0                 0   \n",
       "2023-01-02                  0                  0                 0   \n",
       "2023-01-03                  0                  0                 1   \n",
       "2023-01-04                  0                  0                 0   \n",
       "2023-01-05                  0                  1                 0   \n",
       "2023-01-06                  0                  0                 0   \n",
       "2023-01-07                  0                  0                 0   \n",
       "2023-01-08                  1                  0                 0   \n",
       "2023-01-09                  0                  0                 0   \n",
       "\n",
       "              day_name_Wednesday  \n",
       "last_updated                      \n",
       "2022-12-25                     0  \n",
       "2022-12-26                     0  \n",
       "2022-12-27                     0  \n",
       "2022-12-28                     1  \n",
       "2022-12-29                     0  \n",
       "2022-12-30                     0  \n",
       "2022-12-31                     0  \n",
       "2023-01-01                     0  \n",
       "2023-01-02                     0  \n",
       "2023-01-03                     0  \n",
       "2023-01-04                     1  \n",
       "2023-01-05                     0  \n",
       "2023-01-06                     0  \n",
       "2023-01-07                     0  \n",
       "2023-01-08                     0  \n",
       "2023-01-09                     0  \n",
       "\n",
       "[16 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the preparation pipeline\n",
    "prep = Preparation_Agent(dbfile, shiftable_devices)\n",
    "df = prep.pipeline_usage(prep.input, usage_pipe_params)\n",
    "\n",
    "#display all potential variables for predicting device usage likelihood\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL6F5tn6dTsf"
   },
   "source": [
    "## **2.  Constructing the Usage Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aU7AQfEYSS6"
   },
   "source": [
    "### **2.1 Initialize Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T09RUToXR93t"
   },
   "source": [
    "First we define the **Usage Agent class**. It takes as input the data generated by the prep.pipeline_usage function computed above, and the name of the device for which predictions should be made (e.g \"Washing Machine\", \"Dishwasher\"etc...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 73988,
     "status": "ok",
     "timestamp": 1607623276472,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "hZgoXyrpdVfn"
   },
   "outputs": [],
   "source": [
    "class Usage_Agent:\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self, input_df, device):\n",
    "        self.input = input_df\n",
    "        self.device = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxZlevgn5nrr"
   },
   "source": [
    "Here we initialize the agent for the device \"Dishwasher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 73985,
     "status": "ok",
     "timestamp": 1607623276473,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "Uh-a4Lmi5l_v"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Usage_Agent_i = Usage_Agent(df, shiftable_devices[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlu2qQ8BYXl9"
   },
   "source": [
    "### **2.2 Train_test_split function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train start: the day from which training starts\n",
    "def get_train_start(self, df):\n",
    "    import datetime\n",
    "    end_date = min(df.index) + datetime.timedelta(days=3)\n",
    "    # determine train_start date \n",
    "    return str(end_date)[:10]\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'get_train_start', get_train_start)\n",
    "del get_train_start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-28'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Usage_Agent_i = Usage_Agent(df, shiftable_devices[0])\n",
    "train_start = Usage_Agent_i.get_train_start(df)\n",
    "train_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQ_GrCnOVc2X"
   },
   "source": [
    "The number of data points available to make a prediction for day t increases by one, each time t increases by one. Therefore, we define a custom train_test_split function that automatically puts all data available until day t-1 (incl.) into the training set. The Data for day t (= prediction day) comes into the test set.\n",
    "\n",
    "In order to limit over-fitting the function also filters out the number of features to be taken into account to train the model. Here these are the following:\n",
    "\n",
    "1. Indicator of device usage at day t-1.\n",
    "2. Indicator of device usage at day t-2.\n",
    "3. Indicator of activity in the household in the past two days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 73981,
     "status": "ok",
     "timestamp": 1607623276474,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "UYOZSfdNVKCd"
   },
   "outputs": [],
   "source": [
    "#date: the day of prediction\n",
    "#train start: the day from which training starts\n",
    "def train_test_split(self, df, date, train_start = ''):\n",
    "    if train_start == '':\n",
    "        train_start = self.get_train_start(df)\n",
    "    \n",
    "    #restrict number of variables\n",
    "    select_vars =  [str(self.device) + '_usage', str(self.device)+ '_usage_lag_1', str(self.device)+ '_usage_lag_2',\t'active_last_2_days']\n",
    "    df = df[select_vars]\n",
    "    #spli train and test\n",
    "    X_train = df.loc[train_start:date, df.columns != str(self.device) + '_usage']\n",
    "    y_train = df.loc[train_start:date, df.columns == str(self.device) + '_usage']\n",
    "    X_test  = df.loc[date, df.columns != str(self.device) + '_usage']\n",
    "    y_test  = df.loc[date , df.columns == str(self.device) + '_usage']\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'train_test_split', train_test_split)\n",
    "del train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BeEm4w6ZP1n"
   },
   "source": [
    "Ouput:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 73978,
     "status": "ok",
     "timestamp": 1607623276474,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "1eQ_lkg_l9-C"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = Usage_Agent_i.train_test_split(df, date, train_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 73976,
     "status": "ok",
     "timestamp": 1607623276476,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "UCSNjGPUX3aT",
    "outputId": "8c49dba4-26f3-4a25-d1b6-0b69675816ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor.shellyplug_s_4022d88961b4_power_usage_lag_1</th>\n",
       "      <th>sensor.shellyplug_s_4022d88961b4_power_usage_lag_2</th>\n",
       "      <th>active_last_2_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sensor.shellyplug_s_4022d88961b4_power_usage_lag_1  \\\n",
       "last_updated                                                       \n",
       "2022-12-28                                                  1.0    \n",
       "2022-12-29                                                  0.0    \n",
       "2022-12-30                                                  1.0    \n",
       "2022-12-31                                                  1.0    \n",
       "2023-01-01                                                  0.0    \n",
       "2023-01-02                                                  0.0    \n",
       "2023-01-03                                                  1.0    \n",
       "2023-01-04                                                  0.0    \n",
       "2023-01-05                                                  0.0    \n",
       "2023-01-06                                                  0.0    \n",
       "2023-01-07                                                  0.0    \n",
       "2023-01-08                                                  0.0    \n",
       "\n",
       "              sensor.shellyplug_s_4022d88961b4_power_usage_lag_2  \\\n",
       "last_updated                                                       \n",
       "2022-12-28                                                  1.0    \n",
       "2022-12-29                                                  1.0    \n",
       "2022-12-30                                                  0.0    \n",
       "2022-12-31                                                  1.0    \n",
       "2023-01-01                                                  1.0    \n",
       "2023-01-02                                                  0.0    \n",
       "2023-01-03                                                  0.0    \n",
       "2023-01-04                                                  1.0    \n",
       "2023-01-05                                                  0.0    \n",
       "2023-01-06                                                  0.0    \n",
       "2023-01-07                                                  0.0    \n",
       "2023-01-08                                                  0.0    \n",
       "\n",
       "              active_last_2_days  \n",
       "last_updated                      \n",
       "2022-12-28                     1  \n",
       "2022-12-29                     1  \n",
       "2022-12-30                     1  \n",
       "2022-12-31                     1  \n",
       "2023-01-01                     1  \n",
       "2023-01-02                     1  \n",
       "2023-01-03                     1  \n",
       "2023-01-04                     1  \n",
       "2023-01-05                     0  \n",
       "2023-01-06                     0  \n",
       "2023-01-07                     1  \n",
       "2023-01-08                     1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73968,
     "status": "ok",
     "timestamp": 1607623276477,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "_iFxM9dUX693",
    "outputId": "e46df0a4-d69e-4c47-daa2-3d1996eaf48b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sensor.shellyplug_s_4022d88961b4_power_usage_lag_1    0.0\n",
       "sensor.shellyplug_s_4022d88961b4_power_usage_lag_2    0.0\n",
       "active_last_2_days                                    1.0\n",
       "Name: 2023-01-08 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 73963,
     "status": "ok",
     "timestamp": 1607623276478,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "mcO6tljKX9wf",
    "outputId": "d42133da-e6be-457a-e269-7ef0d08f35e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor.shellyplug_s_4022d88961b4_power_usage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sensor.shellyplug_s_4022d88961b4_power_usage\n",
       "last_updated                                              \n",
       "2022-12-28                                               0\n",
       "2022-12-29                                               1\n",
       "2022-12-30                                               1\n",
       "2022-12-31                                               0\n",
       "2023-01-01                                               0\n",
       "2023-01-02                                               1\n",
       "2023-01-03                                               0\n",
       "2023-01-04                                               0\n",
       "2023-01-05                                               0\n",
       "2023-01-06                                               0\n",
       "2023-01-07                                               0\n",
       "2023-01-08                                               1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73957,
     "status": "ok",
     "timestamp": 1607623276479,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "TIqYYx7AX_7c",
    "outputId": "6b956628-c21b-4aa7-fa70-a471a0fa1404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sensor.shellyplug_s_4022d88961b4_power_usage    1.0\n",
       "Name: 2023-01-08 00:00:00, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yp_Q2mbNq7SI"
   },
   "source": [
    "### **2.3 Fitting Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "901Rnq25Y58c"
   },
   "source": [
    "Now that we have the function to perform the split-sampling we can fit the model on training data. For that purpose, we define a Logit-fitting function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 73953,
     "status": "ok",
     "timestamp": 1607623276480,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "IuwCUQb9q9tH"
   },
   "outputs": [],
   "source": [
    "def fit_Logit(self, X, y, max_iter=100):\n",
    "    return LogisticRegression(random_state=0, max_iter=max_iter).fit(X, y)\n",
    "\n",
    "def fit_knn(self, X, y, n_neighbors=10, leaf_size=30):\n",
    "    return KNeighborsClassifier(n_neighbors=n_neighbors, leaf_size=leaf_size, algorithm=\"auto\", n_jobs=-1).fit(X, y)\n",
    "\n",
    "def fit_random_forest(self, X, y, max_depth=10, n_estimators=500, max_features=\"sqrt\"):\n",
    "    return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
    "\n",
    "def fit_ADA(self, X, y, learning_rate=0.1, n_estimators=100):\n",
    "    return AdaBoostClassifier(learning_rate=learning_rate, n_estimators=n_estimators).fit(X, y)\n",
    "\n",
    "def fit_XGB(self, X, y, learning_rate=0.1, max_depth=6, reg_lambda=1, reg_alpha=0):\n",
    "    return xgboost.XGBClassifier(verbosity=0, use_label_encoder=False, learning_rate=learning_rate, max_depth=max_depth, reg_lambda=reg_lambda, reg_alpha=reg_alpha).fit(X, y)\n",
    "\n",
    "def fit_EBM(self, X, y): \n",
    "    return ExplainableBoostingClassifier().fit(X,y)\n",
    "\n",
    "def fit_smLogit(self, X, y):\n",
    "    return statsmodels.api.Logit(y, X).fit(disp=False)\n",
    "\n",
    "# add to Activity agent\n",
    "setattr(Usage_Agent, 'fit_Logit', fit_Logit)\n",
    "del fit_Logit \n",
    "setattr(Usage_Agent, 'fit_knn', fit_knn)\n",
    "del fit_knn \n",
    "setattr(Usage_Agent, 'fit_random_forest', fit_random_forest)\n",
    "del fit_random_forest \n",
    "setattr(Usage_Agent, 'fit_ADA', fit_ADA)\n",
    "del fit_ADA \n",
    "setattr(Usage_Agent, 'fit_XGB', fit_XGB)\n",
    "del fit_XGB \n",
    "setattr(Usage_Agent, 'fit_EBM', fit_EBM)\n",
    "del fit_EBM \n",
    "setattr(Usage_Agent, 'fit_smLogit', fit_smLogit)\n",
    "del fit_smLogit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y, model_type, **args):\n",
    "    model = None\n",
    "    if model_type == \"logit\":\n",
    "        model = self.fit_Logit(X, y, **args)\n",
    "    elif model_type == \"ada\":\n",
    "        model = self.fit_ADA(X, y, **args)\n",
    "    elif model_type == \"knn\":\n",
    "        model = self.fit_knn(X, y, **args)\n",
    "    elif model_type == \"random forest\":\n",
    "        model = self.fit_random_forest(X,y, **args)\n",
    "    elif model_type == \"xgboost\":\n",
    "        model = self.fit_XGB(X,y, **args)\n",
    "    elif model_type == \"ebm\":\n",
    "        model = self.fit_EBM(X,y, **args)\n",
    "    elif model_type == \"logit_sm\":\n",
    "        model = self.fit_smLogit(X, y)\n",
    "    else:\n",
    "        raise InputError(\"Unknown model type.\")\n",
    "    return model\n",
    "# add to Usage agent\n",
    "setattr(Usage_Agent, 'fit', fit)\n",
    "del fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMxMWE5zZ1PE"
   },
   "source": [
    "Using this function on the training split, we can train our first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74957,
     "status": "ok",
     "timestamp": 1607623277488,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "38OdZOcTrve-",
    "outputId": "d79773c9-60b9-4f27-8dba-aa67c27e07b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=500, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=500, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=500, n_jobs=-1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage = Usage_Agent(df, shiftable_devices[0])\n",
    "model = usage.fit(X_train, y_train, model_type)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "executionInfo": {
     "elapsed": 74954,
     "status": "ok",
     "timestamp": 1607623277490,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "a0iwlva2Hy-n",
    "outputId": "7d2d46a3-c8ce-4345-e153-83c3ec54b4ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor.shellyplug_s_4022d88961b4_power_usage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-01</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-02</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-05</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-06</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-07</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-08</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sensor.shellyplug_s_4022d88961b4_power_usage\n",
       "last_updated                                              \n",
       "2022-12-28                                               0\n",
       "2022-12-29                                               1\n",
       "2022-12-30                                               1\n",
       "2022-12-31                                               0\n",
       "2023-01-01                                               0\n",
       "2023-01-02                                               1\n",
       "2023-01-03                                               0\n",
       "2023-01-04                                               0\n",
       "2023-01-05                                               0\n",
       "2023-01-06                                               0\n",
       "2023-01-07                                               0\n",
       "2023-01-08                                               1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_my8fyn4d-k"
   },
   "source": [
    "Once the model is fitted to the training data, a prediction can be made for the test day. This prediction function is defined in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 74947,
     "status": "ok",
     "timestamp": 1607623277491,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "HVtiJ92utWbo"
   },
   "outputs": [],
   "source": [
    "def predict(self, model, X):\n",
    "    import numpy as np\n",
    "    import pandas\n",
    "    res = 3\n",
    "    cols = [\"temp\", \"dwpt\", \"rhum\", \"wdir\", \"wspd\"]\n",
    "    for e in cols:\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            if e in X.columns:\n",
    "                res += 1\n",
    "        if isinstance(X, pd.Series):\n",
    "            if e in X.index:\n",
    "                res += 1\n",
    "    X = np.array(X).reshape(-1, res)\n",
    "    if type(model) == sklearn.linear_model.LogisticRegression:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "    elif type(model) == sklearn.neighbors._classification.KNeighborsClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "    elif type(model) == sklearn.ensemble._forest.RandomForestClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "    elif type(model) ==  sklearn.ensemble._weight_boosting.AdaBoostClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "    elif type(model) == xgboost.sklearn.XGBClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "    elif type(model) == ExplainableBoostingClassifier:\n",
    "        y_hat = model.predict_proba(X)[:,1]\n",
    "    elif type(model) == statsmodels.discrete.discrete_model.BinaryResultsWrapper:\n",
    "        y_hat = model.predict(X)\n",
    "    else:\n",
    "        raise InputError(\"Unknown model type.\")\n",
    "\n",
    "    return y_hat\n",
    "# add to Usage agent\n",
    "setattr(Usage_Agent, 'predict', predict)\n",
    "del predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74944,
     "status": "ok",
     "timestamp": 1607623277492,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "DbbWXy2Ftd5v",
    "outputId": "b9a38e75-e08e-42fc-b694-f5434f9f7705"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.65719048])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute prediction at day t (see date used for split sampling)\n",
    "import numpy as np\n",
    "y_hat = usage.predict(model, X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLOHQvFv_GXI"
   },
   "source": [
    "### **2.4 Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuQrieip1S6X"
   },
   "source": [
    "Finally, we wrap up all the previously defined functions into the **pipeline** function. This allows to generate a prediction by simply inputting:\n",
    "* the pre-processed usage data\n",
    "* the prediction date\n",
    "* the model type (limited to logit for now)\n",
    "* the date at which the model has started to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline function: predicting device usage\n",
    "# -------------------------------------------------------------------------------------------\n",
    "def pipeline(self, df, date, model_type, train_start='', weather_sel=False):\n",
    "\n",
    "    if weather_sel:\n",
    "        # Add Weather\n",
    "        ################################\n",
    "        from meteostat import Point, Daily\n",
    "        from datetime import datetime, timedelta\n",
    "\n",
    "        lough = Point(52.766593, -1.223511)\n",
    "        time = df.index.to_series(name=\"time\").tolist()\n",
    "        start = time[0]\n",
    "        end = time[len(time) - 1]\n",
    "        weather = Daily(lough, start, end)\n",
    "        weather = weather.fetch()\n",
    "\n",
    "        from sklearn.impute import KNNImputer\n",
    "        import numpy as np\n",
    "\n",
    "        headers = weather.columns.values\n",
    "\n",
    "        empty_train_columns = []\n",
    "        for col in weather.columns.values:\n",
    "            if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                empty_train_columns.append(col)\n",
    "        headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "        weather = imputer.fit_transform(weather)\n",
    "        scaler = MinMaxScaler()\n",
    "        weather = scaler.fit_transform(weather)\n",
    "        weather = pd.DataFrame(weather)\n",
    "        weather[\"time\"] = time[0:len(weather)]\n",
    "        df[\"time\"] = time\n",
    "\n",
    "        weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "        df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "        df = df.set_index(\"time\")\n",
    "        ################################\n",
    "\n",
    "    X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)\n",
    "    model = self.fit(X_train, y_train, model_type)\n",
    "    return self.predict(model, X_test)\n",
    "\n",
    "# add to Usage_Agent\n",
    "setattr(Usage_Agent, 'pipeline', pipeline)\n",
    "del pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline function: predicting device usage\n",
    "# -------------------------------------------------------------------------------------------\n",
    "def pipeline_xai(self, df, date, model_type, train_start='', weather_sel=False):\n",
    "\n",
    "    if weather_sel:\n",
    "        # Add Weather\n",
    "        ################################\n",
    "        from meteostat import Point, Daily\n",
    "        from datetime import datetime, timedelta\n",
    "\n",
    "        lough = Point(52.766593, -1.223511)\n",
    "        time = df.index.to_series(name=\"time\").tolist()\n",
    "        start = time[0]\n",
    "        end = time[len(time) - 1]\n",
    "        weather = Daily(lough, start, end)\n",
    "        weather = weather.fetch()\n",
    "\n",
    "        from sklearn.impute import KNNImputer\n",
    "        import numpy as np\n",
    "\n",
    "        headers = weather.columns.values\n",
    "\n",
    "        empty_train_columns = []\n",
    "        for col in weather.columns.values:\n",
    "            if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                empty_train_columns.append(col)\n",
    "        headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "        weather = imputer.fit_transform(weather)\n",
    "        scaler = MinMaxScaler()\n",
    "        weather = scaler.fit_transform(weather)\n",
    "        weather = pd.DataFrame(weather)\n",
    "        weather[\"time\"] = time[0:len(weather)]\n",
    "        df[\"time\"] = time\n",
    "\n",
    "        weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "        df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "        df = df.set_index(\"time\")\n",
    "        ################################\n",
    "\n",
    "    X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)\n",
    "    model = self.fit(X_train, y_train, model_type)\n",
    "    return self.predict(model, X_test), X_train, X_test, model\n",
    "\n",
    "# add to Usage_Agent\n",
    "setattr(Usage_Agent, 'pipeline_xai', pipeline_xai)\n",
    "del pipeline_xai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAexapts5BYv"
   },
   "source": [
    "A prediction for the \"2013-12-08\" based on the data starting on the '2013-11-01' can finally be made for the device with which we initialized the class (here: \"Dishwasher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74936,
     "status": "ok",
     "timestamp": 1607623277493,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "CXUmgFdK_Z03",
    "outputId": "dd3f42a0-89fe-437d-b00f-cde1b4bb9030"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.41667434])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.pipeline(df, date, 'logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.42481799]),\n",
       "               sensor.shellyplug_s_4022d88961b4_power_usage_lag_1  \\\n",
       " last_updated                                                       \n",
       " 2022-12-29                                                  0.0    \n",
       " 2022-12-30                                                  1.0    \n",
       " 2022-12-31                                                  1.0    \n",
       " 2023-01-01                                                  0.0    \n",
       " 2023-01-02                                                  0.0    \n",
       " 2023-01-03                                                  1.0    \n",
       " 2023-01-04                                                  0.0    \n",
       " 2023-01-05                                                  0.0    \n",
       " 2023-01-06                                                  0.0    \n",
       " 2023-01-07                                                  0.0    \n",
       " 2023-01-08                                                  0.0    \n",
       " \n",
       "               sensor.shellyplug_s_4022d88961b4_power_usage_lag_2  \\\n",
       " last_updated                                                       \n",
       " 2022-12-29                                                  1.0    \n",
       " 2022-12-30                                                  0.0    \n",
       " 2022-12-31                                                  1.0    \n",
       " 2023-01-01                                                  1.0    \n",
       " 2023-01-02                                                  0.0    \n",
       " 2023-01-03                                                  0.0    \n",
       " 2023-01-04                                                  1.0    \n",
       " 2023-01-05                                                  0.0    \n",
       " 2023-01-06                                                  0.0    \n",
       " 2023-01-07                                                  0.0    \n",
       " 2023-01-08                                                  0.0    \n",
       " \n",
       "               active_last_2_days  \n",
       " last_updated                      \n",
       " 2022-12-29                     1  \n",
       " 2022-12-30                     1  \n",
       " 2022-12-31                     1  \n",
       " 2023-01-01                     1  \n",
       " 2023-01-02                     1  \n",
       " 2023-01-03                     1  \n",
       " 2023-01-04                     1  \n",
       " 2023-01-05                     0  \n",
       " 2023-01-06                     0  \n",
       " 2023-01-07                     1  \n",
       " 2023-01-08                     1  ,\n",
       " sensor.shellyplug_s_4022d88961b4_power_usage_lag_1    0.0\n",
       " sensor.shellyplug_s_4022d88961b4_power_usage_lag_2    0.0\n",
       " active_last_2_days                                    1.0\n",
       " Name: 2023-01-08 00:00:00, dtype: float64,\n",
       " LogisticRegression(random_state=0))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage.pipeline_xai(df, date, 'logit', train_start = '2022-12-29')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5cE1DjO6ojI"
   },
   "source": [
    "### **2.5 Model Evaluation**\n",
    "\n",
    "Finally, we want to assess the accuracy of our model before using it in the Recommendation Agent. \n",
    "\n",
    "A drawback to our approach is that we are not able to apply conventional model evaluation techniques to our model. We will train our model for each day to account for newly available information. Hence, we have different train and test sets for each day and for each day different performance metric based on the respective data sets. Therefore, we created our own evaluation function. \n",
    "\n",
    "Our evaluation function will build a model, fit the model and predict the target for each day for a given prediction period. For each day and fitted model it will calculate a performance metric on the train data. We chose the Area Under the Receiver Operating Characteristic Curve (AUC) as performance metric for our binary classification task. As in our case the test data is only the current date to be predicted, we calculate the test AUC over the usage probabilities of all day after all days have been predicted. To summarize the train AUC in one score, we apply an average over all calculated train AUC scores (Note: This approach is the same as for the activity predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(self, y_true, y_hat):\n",
    "    import sklearn.metrics\n",
    "    return sklearn.metrics.roc_auc_score(y_true, y_hat)\n",
    "# add to Usage agent\n",
    "setattr(Usage_Agent, 'auc', auc)\n",
    "del auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "        self, df, model_type, train_start='', predict_start=\"2014-01-01\", predict_end=-1, return_errors=False,\n",
    "        weather_sel=False, xai=False, **args\n",
    "):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    dates = pd.DataFrame(df.index)\n",
    "    dates = dates.set_index(df.index)[\"last_updated\"]\n",
    "    predict_start = pd.to_datetime(predict_start)\n",
    "    predict_end = (\n",
    "        pd.to_datetime(dates.iloc[predict_end])\n",
    "        if type(predict_end) == int\n",
    "        else pd.to_datetime(predict_end)\n",
    "    )\n",
    "    dates = dates.loc[predict_start:predict_end]\n",
    "    y_true = []\n",
    "    y_hat_train = {}\n",
    "    y_hat_test = []\n",
    "    y_hat_lime = []\n",
    "    y_hat_shap = []\n",
    "    auc_train_dict = {}\n",
    "    auc_test = []\n",
    "    xai_time_lime = []\n",
    "    xai_time_shap = []\n",
    "\n",
    "    predictions_list = []\n",
    "\n",
    "    if weather_sel:\n",
    "        print('Crawl weather data....')\n",
    "        # Add Weather\n",
    "        ################################\n",
    "        from meteostat import Point, Daily\n",
    "        from datetime import datetime, timedelta\n",
    "\n",
    "        lough = Point(52.766593, -1.223511)\n",
    "        time = df.index.to_series(name=\"time\").tolist()\n",
    "        start = time[0]\n",
    "        end = time[len(time) - 1]\n",
    "        weather = Daily(lough, start, end)\n",
    "        weather = weather.fetch()\n",
    "\n",
    "        from sklearn.impute import KNNImputer\n",
    "        import numpy as np\n",
    "\n",
    "        headers = weather.columns.values\n",
    "\n",
    "        empty_train_columns = []\n",
    "        for col in weather.columns.values:\n",
    "            if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                empty_train_columns.append(col)\n",
    "        headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "        imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "        weather = imputer.fit_transform(weather)\n",
    "        scaler = MinMaxScaler()\n",
    "        weather = scaler.fit_transform(weather)\n",
    "        weather = pd.DataFrame(weather)\n",
    "        weather[\"time\"] = time[0:len(weather)]\n",
    "        df[\"time\"] = time\n",
    "\n",
    "        weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "        df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "        df = df.set_index(\"time\")\n",
    "\n",
    "        ################################\n",
    "\n",
    "    if not xai:\n",
    "        for date in tqdm(dates.index):\n",
    "            errors = {}\n",
    "            try:\n",
    "                X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                    df, date, train_start\n",
    "                )\n",
    "                # fit model\n",
    "                model = self.fit(X_train, y_train, model_type, **args)\n",
    "                # predict\n",
    "                y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                y_hat_test += list(self.predict(model, X_test))\n",
    "                # evaluate train data\n",
    "                auc_train_dict.update(\n",
    "                    {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                )\n",
    "                y_true += list(y_test)\n",
    "\n",
    "            except Exception as e:\n",
    "                errors[date] = e\n",
    "    else:\n",
    "        print('The explainability approaches in the Usage Agent are being evaluated for model: ' + str(model_type))\n",
    "        print('Start evaluation with LIME and SHAP')\n",
    "        import time\n",
    "        import lime\n",
    "        import shap as shap\n",
    "        from lime import lime_tabular\n",
    "\n",
    "        for date in tqdm(dates.index):\n",
    "            errors = {}\n",
    "            try:\n",
    "                X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                    df, date, train_start\n",
    "                )\n",
    "                # fit model\n",
    "                model = self.fit(X_train, y_train, model_type)\n",
    "                # predict\n",
    "                y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                y_hat_test += list(self.predict(model, X_test))\n",
    "                # evaluate train data\n",
    "                auc_train_dict.update(\n",
    "                    {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                )\n",
    "                y_true += list(y_test)\n",
    "                start_time = time.time()\n",
    "\n",
    "                if model_type == \"xgboost\":\n",
    "                    booster = model.get_booster()\n",
    "\n",
    "                    explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                                                       feature_names=X_train.columns,\n",
    "                                                                       kernel_width=3, verbose=False)\n",
    "\n",
    "                else:\n",
    "                    explainer = lime_tabular.LimeTabularExplainer(training_data=np.array(X_train),\n",
    "                                                                  mode=\"classification\",\n",
    "                                                                  feature_names=X_train.columns,\n",
    "                                                                  categorical_features=[0])\n",
    "\n",
    "                if model_type == \"xgboost\":\n",
    "                    exp = explainer.explain_instance(X_test, model.predict_proba)\n",
    "                else:\n",
    "                    exp = explainer.explain_instance(data_row=X_test, predict_fn=model.predict_proba)\n",
    "\n",
    "                y_hat_lime += list(exp.local_pred)\n",
    "\n",
    "                # take time for each day:\n",
    "                end_time = time.time()\n",
    "                difference_time = end_time - start_time\n",
    "\n",
    "                xai_time_lime.append(difference_time)\n",
    "                # SHAP\n",
    "                # =========================================================================\n",
    "                start_time = time.time()\n",
    "\n",
    "                if model_type == \"logit\":\n",
    "                    X_train_summary = shap.sample(X_train, 100)\n",
    "                    explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "\n",
    "                elif model_type == \"ada\":\n",
    "                    X_train_summary = shap.sample(X_train, 100)\n",
    "                    explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                elif model_type == \"knn\":\n",
    "                    X_train_summary = shap.sample(X_train, 100)\n",
    "                    explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "\n",
    "                elif model_type == \"random forest\":\n",
    "                    X_train_summary = shap.sample(X_train, 100)\n",
    "                    explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                elif model_type == \"xgboost\":\n",
    "                    explainer = shap.TreeExplainer(model, X_train, model_output='predict_proba')\n",
    "\n",
    "                else:\n",
    "                    raise InputError(\"Unknown model type.\")\n",
    "\n",
    "                base_value = explainer.expected_value[1]  # the mean prediction\n",
    "\n",
    "\n",
    "                shap_values = explainer.shap_values(\n",
    "                    X_test)\n",
    "                contribution_to_class_1 = np.array(shap_values).sum(axis=1)[1]  # the red part of the diagram\n",
    "                shap_prediction = base_value + contribution_to_class_1\n",
    "                # Prediction from XAI:\n",
    "                y_hat_shap += list([shap_prediction])\n",
    "\n",
    "\n",
    "                # take time for each day:\n",
    "                end_time = time.time()\n",
    "                difference_time = end_time - start_time\n",
    "                xai_time_shap.append(difference_time)\n",
    "\n",
    "            except Exception as e:\n",
    "                errors[date] = e\n",
    "    \n",
    "    auc_test = self.auc(y_true, y_hat_test)\n",
    "    auc_train = np.mean(list(auc_train_dict.values()))\n",
    "    predictions_list.append(y_true)\n",
    "    predictions_list.append(y_hat_test)\n",
    "    predictions_list.append(y_hat_lime)\n",
    "    predictions_list.append(y_hat_shap)\n",
    "\n",
    "    # Efficiency\n",
    "    time_mean_lime = np.mean(xai_time_lime)\n",
    "    time_mean_shap = np.mean(xai_time_shap)\n",
    "    print('Mean time needed by appraoches: ' + str(time_mean_lime) + ' ' + str(time_mean_shap))\n",
    "\n",
    "    if return_errors:\n",
    "        return auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list, errors\n",
    "    else:\n",
    "        return auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list\n",
    "# add to Usage agent\n",
    "setattr(Usage_Agent, 'evaluate', evaluate)\n",
    "del evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_end=-1\n",
    "return_errors=False\n",
    "weather_sel=False\n",
    "xai=True\n",
    "model_type = \"random forest\"\n",
    "predict_start='2022-12-27'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYtHJpERPikJ"
   },
   "source": [
    "Finally, we can evaluate the simple Logit model for the \"Dishwasher\", for instance for all predictions after the \"2014-08-01\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79708,
     "status": "ok",
     "timestamp": 1607623282273,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "xqaxt7-b9SfE",
    "outputId": "86e00cfb-e9fc-4ba2-cc23-a33c7a1c2755",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:00<?, ?it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                       | 2/14 [00:00<00:04,  2.92it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 21%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                 | 3/14 [00:01<00:05,  1.91it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                           | 4/14 [00:02<00:06,  1.61it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                                     | 5/14 [00:03<00:06,  1.42it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                               | 6/14 [00:03<00:05,  1.34it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                         | 7/14 [00:04<00:05,  1.29it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                   | 8/14 [00:05<00:04,  1.25it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                             | 9/14 [00:06<00:04,  1.22it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                       | 10/14 [00:07<00:03,  1.20it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 | 11/14 [00:08<00:02,  1.21it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž           | 12/14 [00:09<00:01,  1.20it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 13/14 [00:09<00:00,  1.19it/s]C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3690306017.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:10<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time needed by appraoches: nan nan\n",
      "mean_auc_on_train = 0.8912657076719577 | test_auc = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list, = usage.evaluate(df, model_type = model_type, predict_start=predict_start, predict_end= -1)\n",
    "print(\"mean_auc_on_train = \"+ str(auc_train) + \" | test_auc = \" + str(auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.682,\n",
       "  0.74,\n",
       "  0.07,\n",
       "  0.4480333333333333,\n",
       "  0.8893666666666664,\n",
       "  0.4869666666666669,\n",
       "  0.3407857142857144,\n",
       "  0.3046666666666667,\n",
       "  0.108,\n",
       "  0.46620000000000006,\n",
       "  0.6358730158730163,\n",
       "  0.33423809523809545],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nf8rKaVRNW-"
   },
   "source": [
    "As can be seen above, the model's performance is quite disappointing. It is not surprising that we do not have a very high accuracy, given the little amount of data we have. However, there must be potential for improvment. A first step in that direction would be a proper feature selection methodology taking into account different devices and households. Moreover, there has been a large decrease in model accuracy after changing the pre-processing pipeline methodology. Therefore, it seems that the model is sensitive to the way we detect the devices' activity. In the next steps we should investigate how and why these pre-processing steps impact the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYF4hPeeDFtA"
   },
   "source": [
    "## **Appendix A1: Complete Usage Agent Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 79706,
     "status": "ok",
     "timestamp": 1607623282274,
     "user": {
      "displayName": "Felix Germaine",
      "photoUrl": "",
      "userId": "07033484937606028650"
     },
     "user_tz": -60
    },
    "id": "FllI0166G0lz"
   },
   "outputs": [],
   "source": [
    "class Usage_Agent:\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self, input_df, device):\n",
    "        self.input = input_df\n",
    "        self.device = device\n",
    "\n",
    "    # train test split\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #train start: the day from which training starts\n",
    "    def get_train_start(self, df):\n",
    "        end_date = min(df.index) + datetime.timedelta(days=3)\n",
    "        # determine train_start date \n",
    "        return str(end_date)[:10]\n",
    "    \n",
    "    def train_test_split(self, df, date, train_start=''):\n",
    "        \n",
    "        select_vars =  [str(self.device) + '_usage', \n",
    "                        str(self.device)+ '_usage_lag_1', \n",
    "                        str(self.device)+ '_usage_lag_2', 'active_last_2_days']\n",
    "        \n",
    "        if train_start == '':\n",
    "            train_start = self.get_train_start(df)\n",
    "            \n",
    "        # Add weather possibly\n",
    "        if \"temp\" in df.columns:\n",
    "            select_vars.append(\"temp\")\n",
    "            df[\"temp\"].fillna(method=\"backfill\", inplace=True)\n",
    "        if \"dwpt\" in df.columns:\n",
    "            select_vars.append(\"dwpt\")\n",
    "            df[\"dwpt\"].fillna(method=\"backfill\", inplace=True)\n",
    "        if \"rhum\" in df.columns:\n",
    "            select_vars.append(\"rhum\")\n",
    "            df[\"rhum\"].fillna(method=\"backfill\", inplace=True)\n",
    "        if \"wdir\" in df.columns:\n",
    "            select_vars.append(\"wdir\")\n",
    "            df[\"wdir\"].fillna(method=\"backfill\", inplace=True)\n",
    "        if \"wspd\" in df.columns:\n",
    "            select_vars.append(\"wspd\")\n",
    "            df[\"wspd\"].fillna(method=\"backfill\", inplace=True)\n",
    "        \n",
    "        df = df[select_vars]\n",
    "        X_train = df.loc[train_start:date, df.columns != str(self.device) + \"_usage\"]\n",
    "        y_train = df.loc[train_start:date, df.columns == str(self.device) + \"_usage\"]\n",
    "        X_test = df.loc[date, df.columns != str(self.device) + \"_usage\"]\n",
    "        y_test = df.loc[date, df.columns == str(self.device) + \"_usage\"]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    # model training and evaluation\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def fit_Logit(self, X, y, max_iter=100):\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        return LogisticRegression(random_state=0, max_iter=max_iter).fit(X, y)\n",
    "\n",
    "    def fit_knn(self, X, y, n_neighbors=10, leaf_size=30):\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        return KNeighborsClassifier(n_neighbors=n_neighbors, leaf_size=leaf_size, algorithm=\"auto\", n_jobs=-1).fit(X, y)\n",
    "\n",
    "    def fit_random_forest(self, X, y, max_depth=10, n_estimators=500, max_features=\"sqrt\"):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
    "\n",
    "    def fit_ADA(self, X, y, learning_rate=0.1, n_estimators=100):\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        return AdaBoostClassifier(learning_rate=learning_rate, n_estimators=n_estimators).fit(X, y)\n",
    "\n",
    "    def fit_XGB(self, X, y, learning_rate=0.1, max_depth=6, reg_lambda=1, reg_alpha=0):\n",
    "        import xgboost\n",
    "        return xgboost.XGBClassifier(verbosity=0, use_label_encoder=False, learning_rate=learning_rate, max_depth=max_depth, reg_lambda=reg_lambda, reg_alpha=reg_alpha).fit(X, y)\n",
    "\n",
    "    def fit_EBM(self, X, y): \n",
    "        from interpret.glassbox.ebm.ebm import ExplainableBoostingClassifier  \n",
    "        return ExplainableBoostingClassifier().fit(X,y)\n",
    "\n",
    "    def fit_smLogit(self, X, y):\n",
    "        import statsmodels\n",
    "        return statsmodels.api.Logit(y, X).fit(disp=False)\n",
    "    \n",
    "    def fit(self, X, y, model_type, **args):\n",
    "        model = None\n",
    "        if model_type == \"logit\":\n",
    "            model = self.fit_Logit(X, y, **args)\n",
    "        elif model_type == \"ada\":\n",
    "            model = self.fit_ADA(X, y, **args)\n",
    "        elif model_type == \"knn\":\n",
    "            model = self.fit_knn(X, y, **args)\n",
    "        elif model_type == \"random forest\":\n",
    "            model = self.fit_random_forest(X, y, **args)\n",
    "        elif model_type == \"xgboost\":\n",
    "            model = self.fit_XGB(X, y, **args)\n",
    "        elif model_type == \"ebm\":\n",
    "            model = self.fit_EBM(X,y, **args)\n",
    "        elif model_type == \"logit_sm\":\n",
    "            model = self.fit_smLogit(X, y)\n",
    "        else:\n",
    "            raise InputError(\"Unknown model type.\")\n",
    "        return model\n",
    "\n",
    "    def predict(self, model, X):\n",
    "        import sklearn\n",
    "        import statsmodels\n",
    "        from interpret.glassbox.ebm.ebm import ExplainableBoostingClassifier     \n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        import xgboost\n",
    "        import numpy as np\n",
    "        import pandas\n",
    "        res = 3\n",
    "        cols = [\"temp\", \"dwpt\", \"rhum\", \"wdir\", \"wspd\"]\n",
    "        for e in cols:\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                if e in X.columns:\n",
    "                    res += 1\n",
    "            if isinstance(X, pd.Series):\n",
    "                if e in X.index:\n",
    "                    res += 1\n",
    "        X = np.array(X).reshape(-1, res)\n",
    "        if type(model) == sklearn.linear_model.LogisticRegression:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "        elif type(model) == sklearn.neighbors._classification.KNeighborsClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "        elif type(model) == sklearn.ensemble._forest.RandomForestClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "        elif type(model) ==  sklearn.ensemble._weight_boosting.AdaBoostClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "        elif type(model) == xgboost.sklearn.XGBClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "        elif type(model) == ExplainableBoostingClassifier:\n",
    "            y_hat = model.predict_proba(X)[:,1]\n",
    "        elif type(model) == statsmodels.discrete.discrete_model.BinaryResultsWrapper:\n",
    "            y_hat = model.predict(X)\n",
    "        else:\n",
    "            raise InputError(\"Unknown model type.\")\n",
    "        return y_hat\n",
    "\n",
    "    def auc(self, y_true, y_hat):\n",
    "        import sklearn.metrics\n",
    "        return sklearn.metrics.roc_auc_score(y_true, y_hat)\n",
    "    \n",
    "    def evaluate(\n",
    "            self, df, model_type, train_start = '', predict_start=\"2014-01-01\", predict_end=-1, return_errors=False,\n",
    "            weather_sel=False, xai=False, **args\n",
    "    ):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        dates = pd.DataFrame(df.index)\n",
    "        dates = dates.set_index(df.index)[\"last_updated\"]\n",
    "        predict_start = pd.to_datetime(predict_start)\n",
    "        predict_end = (\n",
    "            pd.to_datetime(dates.iloc[predict_end])\n",
    "            if type(predict_end) == int\n",
    "            else pd.to_datetime(predict_end)\n",
    "        )\n",
    "        dates = dates.loc[predict_start:predict_end]\n",
    "        y_true = []\n",
    "        y_hat_train = {}\n",
    "        y_hat_test = []\n",
    "        y_hat_lime = []\n",
    "        y_hat_shap = []\n",
    "        auc_train_dict = {}\n",
    "        auc_test = []\n",
    "        xai_time_lime = []\n",
    "        xai_time_shap = []\n",
    "\n",
    "        predictions_list = []\n",
    "\n",
    "        if weather_sel:\n",
    "            print('Crawl weather data....')\n",
    "            # Add Weather\n",
    "            ################################\n",
    "            from meteostat import Point, Daily\n",
    "            from datetime import datetime, timedelta\n",
    "\n",
    "            lough = Point(52.766593, -1.223511)\n",
    "            time = df.index.to_series(name=\"time\").tolist()\n",
    "            start = time[0]\n",
    "            end = time[len(time) - 1]\n",
    "            weather = Daily(lough, start, end)\n",
    "            weather = weather.fetch()\n",
    "\n",
    "            from sklearn.impute import KNNImputer\n",
    "            import numpy as np\n",
    "\n",
    "            headers = weather.columns.values\n",
    "\n",
    "            empty_train_columns = []\n",
    "            for col in weather.columns.values:\n",
    "                if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                    empty_train_columns.append(col)\n",
    "            headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "            imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "            weather = imputer.fit_transform(weather)\n",
    "            scaler = MinMaxScaler()\n",
    "            weather = scaler.fit_transform(weather)\n",
    "            weather = pd.DataFrame(weather)\n",
    "            weather[\"time\"] = time[0:len(weather)]\n",
    "            df[\"time\"] = time\n",
    "\n",
    "            weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "            df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "            df = df.set_index(\"time\")\n",
    "\n",
    "            ################################\n",
    "\n",
    "        if not xai:\n",
    "            for date in tqdm(dates.index):\n",
    "                errors = {}\n",
    "                try:\n",
    "                    X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                        df, date, train_start\n",
    "                    )\n",
    "                    # fit model\n",
    "                    model = self.fit(X_train, y_train, model_type, **args)\n",
    "                    # predict\n",
    "                    y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                    y_hat_test += list(self.predict(model, X_test))\n",
    "                    # evaluate train data\n",
    "                    auc_train_dict.update(\n",
    "                        {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                    )\n",
    "                    y_true += list(y_test)\n",
    "\n",
    "                except Exception as e:\n",
    "                    errors[date] = e\n",
    "        else:\n",
    "            print('The explainability approaches in the Usage Agent are being evaluated for model: ' + str(model_type))\n",
    "            print('Start evaluation with LIME and SHAP')\n",
    "            import time\n",
    "            import lime\n",
    "            import shap as shap\n",
    "            from lime import lime_tabular\n",
    "\n",
    "            for date in tqdm(dates.index):\n",
    "                errors = {}\n",
    "                try:\n",
    "                    X_train, y_train, X_test, y_test = self.train_test_split(\n",
    "                        df, date, train_start\n",
    "                    )\n",
    "                    # fit model\n",
    "                    model = self.fit(X_train, y_train, model_type)\n",
    "                    # predict\n",
    "                    y_hat_train.update({date: self.predict(model, X_train)})\n",
    "                    y_hat_test += list(self.predict(model, X_test))\n",
    "                    # evaluate train data\n",
    "                    auc_train_dict.update(\n",
    "                        {date: self.auc(y_train, list(y_hat_train.values())[-1])}\n",
    "                    )\n",
    "                    y_true += list(y_test)\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    if model_type == \"xgboost\":\n",
    "                        booster = model.get_booster()\n",
    "\n",
    "                        explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values,\n",
    "                                                                           feature_names=X_train.columns,\n",
    "                                                                           kernel_width=3, verbose=False)\n",
    "\n",
    "                    else:\n",
    "                        explainer = lime_tabular.LimeTabularExplainer(training_data=np.array(X_train),\n",
    "                                                                      mode=\"classification\",\n",
    "                                                                      feature_names=X_train.columns,\n",
    "                                                                      categorical_features=[0])\n",
    "\n",
    "                    if model_type == \"xgboost\":\n",
    "                        exp = explainer.explain_instance(X_test, model.predict_proba)\n",
    "                    else:\n",
    "                        exp = explainer.explain_instance(data_row=X_test, predict_fn=model.predict_proba)\n",
    "\n",
    "                    y_hat_lime += list(exp.local_pred)\n",
    "\n",
    "                    # take time for each day:\n",
    "                    end_time = time.time()\n",
    "                    difference_time = end_time - start_time\n",
    "\n",
    "                    xai_time_lime.append(difference_time)\n",
    "                    # SHAP\n",
    "                    # =========================================================================\n",
    "                    start_time = time.time()\n",
    "\n",
    "                    if model_type == \"logit\":\n",
    "                        X_train_summary = shap.sample(X_train, 100)\n",
    "                        explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "\n",
    "                    elif model_type == \"ada\":\n",
    "                        X_train_summary = shap.sample(X_train, 100)\n",
    "                        explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                    elif model_type == \"knn\":\n",
    "                        X_train_summary = shap.sample(X_train, 100)\n",
    "                        explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "\n",
    "                    elif model_type == \"random forest\":\n",
    "                        X_train_summary = shap.sample(X_train, 100)\n",
    "                        explainer = shap.KernelExplainer(model.predict_proba, X_train_summary)\n",
    "\n",
    "                    elif model_type == \"xgboost\":\n",
    "                        explainer = shap.TreeExplainer(model, X_train, model_output='predict_proba')\n",
    "\n",
    "                    else:\n",
    "                        raise InputError(\"Unknown model type.\")\n",
    "\n",
    "                    base_value = explainer.expected_value[1]  # the mean prediction\n",
    "\n",
    "\n",
    "                    shap_values = explainer.shap_values(\n",
    "                        X_test)\n",
    "                    contribution_to_class_1 = np.array(shap_values).sum(axis=1)[1]  # the red part of the diagram\n",
    "                    shap_prediction = base_value + contribution_to_class_1\n",
    "                    # Prediction from XAI:\n",
    "                    y_hat_shap += list([shap_prediction])\n",
    "\n",
    "\n",
    "                    # take time for each day:\n",
    "                    end_time = time.time()\n",
    "                    difference_time = end_time - start_time\n",
    "                    xai_time_shap.append(difference_time)\n",
    "\n",
    "                except Exception as e:\n",
    "                    errors[date] = e\n",
    "\n",
    "        auc_test = self.auc(y_true, y_hat_test)\n",
    "        auc_train = np.mean(list(auc_train_dict.values()))\n",
    "        predictions_list.append(y_true)\n",
    "        predictions_list.append(y_hat_test)\n",
    "        predictions_list.append(y_hat_lime)\n",
    "        predictions_list.append(y_hat_shap)\n",
    "\n",
    "        # Efficiency\n",
    "        time_mean_lime = np.mean(xai_time_lime)\n",
    "        time_mean_shap = np.mean(xai_time_shap)\n",
    "        print('Mean time nedded by appraoches: ' + str(time_mean_lime) + ' ' + str(time_mean_shap))\n",
    "\n",
    "        if return_errors:\n",
    "            return auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list, errors\n",
    "        else:\n",
    "            return auc_train, auc_test, auc_train_dict, time_mean_lime, time_mean_shap, predictions_list\n",
    "        \n",
    "    # pipeline function: predicting device usage\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def pipeline(self, df, date, model_type, train_start = '', weather_sel=False):\n",
    "\n",
    "        if weather_sel:\n",
    "            # Add Weather\n",
    "            ################################\n",
    "            from meteostat import Point, Daily\n",
    "            from datetime import datetime, timedelta\n",
    "\n",
    "            lough = Point(52.766593, -1.223511)\n",
    "            time = df.index.to_series(name=\"time\").tolist()\n",
    "            start = time[0]\n",
    "            end = time[len(time) - 1]\n",
    "            weather = Daily(lough, start, end)\n",
    "            weather = weather.fetch()\n",
    "\n",
    "            from sklearn.impute import KNNImputer\n",
    "            import numpy as np\n",
    "\n",
    "            headers = weather.columns.values\n",
    "\n",
    "            empty_train_columns = []\n",
    "            for col in weather.columns.values:\n",
    "                if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                    empty_train_columns.append(col)\n",
    "            headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "            imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "            weather = imputer.fit_transform(weather)\n",
    "            scaler = MinMaxScaler()\n",
    "            weather = scaler.fit_transform(weather)\n",
    "            weather = pd.DataFrame(weather)\n",
    "            weather[\"time\"] = time[0:len(weather)]\n",
    "            df[\"time\"] = time\n",
    "\n",
    "            weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "            df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "            df = df.set_index(\"time\")\n",
    "            ################################\n",
    "\n",
    "        X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)\n",
    "        model = self.fit(X_train, y_train, model_type)\n",
    "        return self.predict(model, X_test)\n",
    "\n",
    "\n",
    "    # pipeline function: predicting device usage\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def pipeline_xai(self, df, date, model_type, train_start = '', weather_sel=False):\n",
    "\n",
    "        if weather_sel:\n",
    "            # Add Weather\n",
    "            ################################\n",
    "            from meteostat import Point, Daily\n",
    "            from datetime import datetime, timedelta\n",
    "\n",
    "            lough = Point(52.766593, -1.223511)\n",
    "            time = df.index.to_series(name=\"time\").tolist()\n",
    "            start = time[0]\n",
    "            end = time[len(time) - 1]\n",
    "            weather = Daily(lough, start, end)\n",
    "            weather = weather.fetch()\n",
    "\n",
    "            from sklearn.impute import KNNImputer\n",
    "            import numpy as np\n",
    "\n",
    "            headers = weather.columns.values\n",
    "\n",
    "            empty_train_columns = []\n",
    "            for col in weather.columns.values:\n",
    "                if sum(weather[col].isnull()) == weather.shape[0]:\n",
    "                    empty_train_columns.append(col)\n",
    "            headers = np.setdiff1d(headers, empty_train_columns)\n",
    "\n",
    "            imputer = KNNImputer(missing_values=np.nan, n_neighbors=7, weights=\"distance\")\n",
    "            weather = imputer.fit_transform(weather)\n",
    "            scaler = MinMaxScaler()\n",
    "            weather = scaler.fit_transform(weather)\n",
    "            weather = pd.DataFrame(weather)\n",
    "            weather[\"time\"] = time[0:len(weather)]\n",
    "            df[\"time\"] = time\n",
    "\n",
    "            weather.columns = np.append(headers, \"time\")\n",
    "\n",
    "            df = pd.merge(df, weather, how=\"right\", on=\"time\")\n",
    "            df = df.set_index(\"time\")\n",
    "            ################################\n",
    "\n",
    "        X_train, y_train, X_test, y_test = self.train_test_split(df, date, train_start)\n",
    "        model = self.fit(X_train, y_train, model_type)\n",
    "        return self.predict(model, X_test), X_train, X_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3757562704.py:62: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.67094762]),\n",
       "               sensor.shellyplug_s_4022d88961b4_power_usage_lag_1  \\\n",
       " last_updated                                                       \n",
       " 2022-12-28                                                  1.0    \n",
       " 2022-12-29                                                  0.0    \n",
       " 2022-12-30                                                  1.0    \n",
       " 2022-12-31                                                  1.0    \n",
       " 2023-01-01                                                  0.0    \n",
       " 2023-01-02                                                  0.0    \n",
       " 2023-01-03                                                  1.0    \n",
       " 2023-01-04                                                  0.0    \n",
       " 2023-01-05                                                  0.0    \n",
       " 2023-01-06                                                  0.0    \n",
       " 2023-01-07                                                  0.0    \n",
       " 2023-01-08                                                  0.0    \n",
       " \n",
       "               sensor.shellyplug_s_4022d88961b4_power_usage_lag_2  \\\n",
       " last_updated                                                       \n",
       " 2022-12-28                                                  1.0    \n",
       " 2022-12-29                                                  1.0    \n",
       " 2022-12-30                                                  0.0    \n",
       " 2022-12-31                                                  1.0    \n",
       " 2023-01-01                                                  1.0    \n",
       " 2023-01-02                                                  0.0    \n",
       " 2023-01-03                                                  0.0    \n",
       " 2023-01-04                                                  1.0    \n",
       " 2023-01-05                                                  0.0    \n",
       " 2023-01-06                                                  0.0    \n",
       " 2023-01-07                                                  0.0    \n",
       " 2023-01-08                                                  0.0    \n",
       " \n",
       "               active_last_2_days  \n",
       " last_updated                      \n",
       " 2022-12-28                     1  \n",
       " 2022-12-29                     1  \n",
       " 2022-12-30                     1  \n",
       " 2022-12-31                     1  \n",
       " 2023-01-01                     1  \n",
       " 2023-01-02                     1  \n",
       " 2023-01-03                     1  \n",
       " 2023-01-04                     1  \n",
       " 2023-01-05                     0  \n",
       " 2023-01-06                     0  \n",
       " 2023-01-07                     1  \n",
       " 2023-01-08                     1  ,\n",
       " sensor.shellyplug_s_4022d88961b4_power_usage_lag_1    0.0\n",
       " sensor.shellyplug_s_4022d88961b4_power_usage_lag_2    0.0\n",
       " active_last_2_days                                    1.0\n",
       " Name: 2023-01-08 00:00:00, dtype: float64,\n",
       " RandomForestClassifier(max_depth=10, n_estimators=500, n_jobs=-1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usage_1 = Usage_Agent(df, shiftable_devices[0])\n",
    "usage_2 = Usage_Agent(df, shiftable_devices[1])\n",
    "date = '2023-01-08'\n",
    "train_start = ''\n",
    "output = usage_1.pipeline_xai(df, date, 'random forest', train_start)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Local\\Temp\\ipykernel_13508\\3757562704.py:62: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, max_features=max_features, n_jobs=-1).fit(X, y)\n",
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.01449524]),\n",
       "               sensor.shellyplug_s_4022d88984b8_power_usage_lag_1  \\\n",
       " last_updated                                                       \n",
       " 2022-12-28                                                  1.0    \n",
       " 2022-12-29                                                  0.0    \n",
       " 2022-12-30                                                  0.0    \n",
       " 2022-12-31                                                  1.0    \n",
       " 2023-01-01                                                  1.0    \n",
       " 2023-01-02                                                  1.0    \n",
       " 2023-01-03                                                  0.0    \n",
       " 2023-01-04                                                  0.0    \n",
       " 2023-01-05                                                  0.0    \n",
       " 2023-01-06                                                  0.0    \n",
       " 2023-01-07                                                  1.0    \n",
       " 2023-01-08                                                  0.0    \n",
       " \n",
       "               sensor.shellyplug_s_4022d88984b8_power_usage_lag_2  \\\n",
       " last_updated                                                       \n",
       " 2022-12-28                                                  1.0    \n",
       " 2022-12-29                                                  1.0    \n",
       " 2022-12-30                                                  0.0    \n",
       " 2022-12-31                                                  0.0    \n",
       " 2023-01-01                                                  1.0    \n",
       " 2023-01-02                                                  1.0    \n",
       " 2023-01-03                                                  1.0    \n",
       " 2023-01-04                                                  0.0    \n",
       " 2023-01-05                                                  0.0    \n",
       " 2023-01-06                                                  0.0    \n",
       " 2023-01-07                                                  0.0    \n",
       " 2023-01-08                                                  1.0    \n",
       " \n",
       "               active_last_2_days  \n",
       " last_updated                      \n",
       " 2022-12-28                     1  \n",
       " 2022-12-29                     1  \n",
       " 2022-12-30                     1  \n",
       " 2022-12-31                     1  \n",
       " 2023-01-01                     1  \n",
       " 2023-01-02                     1  \n",
       " 2023-01-03                     1  \n",
       " 2023-01-04                     1  \n",
       " 2023-01-05                     0  \n",
       " 2023-01-06                     0  \n",
       " 2023-01-07                     1  \n",
       " 2023-01-08                     1  ,\n",
       " sensor.shellyplug_s_4022d88984b8_power_usage_lag_1    0.0\n",
       " sensor.shellyplug_s_4022d88984b8_power_usage_lag_2    1.0\n",
       " active_last_2_days                                    1.0\n",
       " Name: 2023-01-08 00:00:00, dtype: float64,\n",
       " RandomForestClassifier(max_depth=10, n_estimators=500, n_jobs=-1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = usage_2.pipeline_xai(df, date, 'random forest', train_start)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03b_Usage_Agent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "fd19f899bcdfa6c353e9525ef244de6eb28a54f3ba596d530144acef4e3bc685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
