{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbaaa9ac",
   "metadata": {},
   "source": [
    "# Explaibability Agent\n",
    "\n",
    "Explaibability Agent (Creates the explainable output of the recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e139c",
   "metadata": {},
   "source": [
    "## **1. Load And Preprocess Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e651b08",
   "metadata": {},
   "source": [
    "This part's only purpose is to load the data used in the Explainability Agent. This process is described in detail in the Preparation Agent. \n",
    "\n",
    "**Note: When computing the script with another Household than Household 1 you might need to adapt some parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e56a7",
   "metadata": {},
   "source": [
    "### **1.1 Initialize And Load Python Scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd511beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\envs\\recomm\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "dir = 'D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main'\n",
    "os.chdir(dir)\n",
    "\n",
    "from helper_functions import Helper\n",
    "from agents import Preparation_Agent\n",
    "import pandas as pd\n",
    "\n",
    "helper = Helper()\n",
    "\n",
    "dbfile  = \"D:/Master BWL HU/3. Semester/Seminar Information Systems/Seminar-Information-Systems-main/home-assistant_Chris_v3.db\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ebf8b",
   "metadata": {},
   "source": [
    "### **1.2 Set Parameters For Pre-processing Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acea7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "shiftable_devices = [\"sensor.shellyplug_s_4022d88961b4_power\", \"sensor.shellyplug_s_4022d88984b8_power\"]\n",
    "date = '2023-01-09'\n",
    "\n",
    "\n",
    "truncation_params = {\n",
    "    'features': 'all', \n",
    "    'factor': 1.5, \n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "scale_params = {\n",
    "    'features': 'all', \n",
    "    'kind': 'MinMax', \n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "aggregate_params = {\n",
    "    'resample_param': '60T'\n",
    "}\n",
    "#update with active appliances attributes_ids\n",
    "activity_params = {\n",
    "    'active_appliances': shiftable_devices,\n",
    "    'threshold': .15\n",
    "}\n",
    "\n",
    "time_params = {\n",
    "    'features': ['hour', 'day_name']\n",
    "}\n",
    "\n",
    "activity_lag_params = {\n",
    "    'features': ['activity'],\n",
    "    'lags': [24, 48, 72]\n",
    "}\n",
    "\n",
    "device_params = {\n",
    "    'threshold': 1\n",
    "}\n",
    "\n",
    "load_pipe_params = {\n",
    "    'truncate': truncation_params,\n",
    "    'scale': scale_params,\n",
    "    'aggregate': aggregate_params,\n",
    "    'shiftable_devices': shiftable_devices, \n",
    "    'device': device_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2be56",
   "metadata": {},
   "source": [
    "### **1.3 Pre-process Data For Input In Device_Usage Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af196a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor.shellyplug_s_4022d88961b4_power</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-25 18:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 19:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 20:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 21:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 22:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 19:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 20:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 21:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 22:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sensor.shellyplug_s_4022d88961b4_power  \\\n",
       "last_updated                                                  \n",
       "2022-12-25 18:00:00                                     0.0   \n",
       "2022-12-25 19:00:00                                     0.0   \n",
       "2022-12-25 20:00:00                                     0.0   \n",
       "2022-12-25 21:00:00                                     0.0   \n",
       "2022-12-25 22:00:00                                     0.0   \n",
       "...                                                     ...   \n",
       "2023-01-10 19:00:00                                     0.0   \n",
       "2023-01-10 20:00:00                                     0.0   \n",
       "2023-01-10 21:00:00                                     0.0   \n",
       "2023-01-10 22:00:00                                     0.0   \n",
       "2023-01-10 23:00:00                                     0.0   \n",
       "\n",
       "                     sensor.shellyplug_s_4022d88984b8_power  \n",
       "last_updated                                                 \n",
       "2022-12-25 18:00:00                                     0.0  \n",
       "2022-12-25 19:00:00                                     0.0  \n",
       "2022-12-25 20:00:00                                     0.0  \n",
       "2022-12-25 21:00:00                                     0.0  \n",
       "2022-12-25 22:00:00                                     0.0  \n",
       "...                                                     ...  \n",
       "2023-01-10 19:00:00                                     0.0  \n",
       "2023-01-10 20:00:00                                     0.0  \n",
       "2023-01-10 21:00:00                                     0.0  \n",
       "2023-01-10 22:00:00                                     0.0  \n",
       "2023-01-10 23:00:00                                     0.0  \n",
       "\n",
       "[390 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the preparation pipelin\n",
    "import pandas as pd\n",
    "prep = Preparation_Agent(dbfile, shiftable_devices)\n",
    "output, scaled, df = prep.pipeline_load(prep.input, load_pipe_params)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2153c5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor.shellyplug_s_4022d88961b4_power</th>\n",
       "      <th>sensor.shellyplug_s_4022d88984b8_power</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_updated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-25 18:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 19:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 20:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 21:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25 22:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 19:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 20:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 21:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 22:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sensor.shellyplug_s_4022d88961b4_power  \\\n",
       "last_updated                                                  \n",
       "2022-12-25 18:00:00                                     0.0   \n",
       "2022-12-25 19:00:00                                     0.0   \n",
       "2022-12-25 20:00:00                                     0.0   \n",
       "2022-12-25 21:00:00                                     0.0   \n",
       "2022-12-25 22:00:00                                     0.0   \n",
       "...                                                     ...   \n",
       "2023-01-10 19:00:00                                     0.0   \n",
       "2023-01-10 20:00:00                                     0.0   \n",
       "2023-01-10 21:00:00                                     0.0   \n",
       "2023-01-10 22:00:00                                     0.0   \n",
       "2023-01-10 23:00:00                                     0.0   \n",
       "\n",
       "                     sensor.shellyplug_s_4022d88984b8_power  \n",
       "last_updated                                                 \n",
       "2022-12-25 18:00:00                                     0.0  \n",
       "2022-12-25 19:00:00                                     0.0  \n",
       "2022-12-25 20:00:00                                     0.0  \n",
       "2022-12-25 21:00:00                                     0.0  \n",
       "2022-12-25 22:00:00                                     0.0  \n",
       "...                                                     ...  \n",
       "2023-01-10 19:00:00                                     0.0  \n",
       "2023-01-10 20:00:00                                     0.0  \n",
       "2023-01-10 21:00:00                                     0.0  \n",
       "2023-01-10 22:00:00                                     0.0  \n",
       "2023-01-10 23:00:00                                     0.0  \n",
       "\n",
       "[390 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = output\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff9be3",
   "metadata": {},
   "source": [
    "## **2.  Constructing the Evaluation Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c856d2c",
   "metadata": {},
   "source": [
    "### **2.1 Initialize Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7dcc1",
   "metadata": {},
   "source": [
    "First we define the **Evaluation Agent class**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14fdf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Evaluation Agent\n",
    "# ===============================================================================================\n",
    "class Evaluation_Agent:\n",
    "    def __init__(self, DATA_PATH, model_type, config, load_data=True, load_files=None, weather_sel=False, xai = False):\n",
    "        import agents\n",
    "        from helper_functions import Helper\n",
    "        import pandas as pd\n",
    "\n",
    "        helper = Helper()\n",
    "\n",
    "        self.model_type = model_type\n",
    "        self.config = config\n",
    "        self.weather_sel = weather_sel\n",
    "        self.xai = xai\n",
    "        house_df = helper.load_household(DATA_PATH, config[\"data\"][\"household\"], weather_sel = weather_sel)\n",
    "        if load_data:\n",
    "            self.preparation = agents.Preparation_Agent(house_df)\n",
    "        else:\n",
    "            self.preparation = agents.Preparation_Agent(None)\n",
    "\n",
    "        self.price = (\n",
    "            agents.Price_Agent(helper.create_day_ahead_prices_df(DATA_PATH, \"Day-ahead Prices_201501010000-201601010000.csv\"))\n",
    "            if load_data\n",
    "            else None\n",
    "        )\n",
    "        self.activity = None\n",
    "        self.load = None\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = (\"usage_\" + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "            exec(f\"self.{name} = None\")\n",
    "        self.recommendation = None\n",
    "        self.df = {}\n",
    "        self.output = {}\n",
    "        self.errors = {}\n",
    "        self.agent_scores = {}\n",
    "        self.agent_predictions_list_activity = {}\n",
    "        self.agent_predictions_list_usage = {}\n",
    "        self.cold_start_scores = {}\n",
    "        self.results = {}\n",
    "        self.cold_start_days = pd.DataFrame()\n",
    "        if load_files != None:\n",
    "            self.load_from_drive(load_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7133b304",
   "metadata": {},
   "source": [
    "### 2.2 Loading Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8ca122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: loading and storing intermediary results and further helper\n",
    "# -------------------------------------------------------------------------------------------\n",
    "def _load_object(self, filename):\n",
    "    import pickle\n",
    "    import json\n",
    "    import yaml\n",
    "\n",
    "    # using a command dict as a if-list\n",
    "    commands = {\n",
    "        \"pkl\": f\"pickle.load(open('{filename}', 'rb'))\",\n",
    "        \"json\": f\"json.load(open('{filename}', 'r'))\",\n",
    "        \"yaml\": f\"yaml.load(open('{filename}', 'r'), Loader = yaml.Loader)\",\n",
    "    }\n",
    "\n",
    "    *_, name, ftype = filename.split(\".\")\n",
    "    name = name[name.rfind(\"_\") + 1:]\n",
    "    obj = eval(commands[ftype])\n",
    "    self[name] = obj\n",
    "    \n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '_load_object', _load_object)\n",
    "del _load_object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a38d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i._load_object()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_drive(self, files):\n",
    "    files = [files] if type(files) != list else files\n",
    "    for filename in files:\n",
    "        self._load_object(filename)\n",
    "        \n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, 'load_from_drive', load_from_drive)\n",
    "del load_from_drive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i.load_from_drive()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c592e8",
   "metadata": {},
   "source": [
    "### 2.3 Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c556e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(self, EXPORT_PATH):\n",
    "    import json\n",
    "    import yaml\n",
    "    import pickle\n",
    "\n",
    "    # storing the current configuration\n",
    "    json.dump(self.config, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                      + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_config.json\", \"w\"), indent=4)\n",
    "\n",
    "    # storing the prepared data\n",
    "    if self.df != {}:\n",
    "        pickle.dump(self.df, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                     + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_df.pkl\", \"wb\"))\n",
    "\n",
    "    # storing the agents' output\n",
    "    if self.output != {}:\n",
    "        pickle.dump(self.output, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                     + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_output.pkl\", \"wb\"))\n",
    "\n",
    "    # storing the results\n",
    "    if self.results != {}:\n",
    "        pickle.dump(self.results, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                    + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_results.pkl\", \"wb\"))\n",
    "\n",
    "    # storing the results\n",
    "    if self.agent_scores != {}:\n",
    "        pickle.dump(self.agent_scores, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                    + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_scores.pkl\", \"wb\"))\n",
    "\n",
    "    if self.agent_predictions_list_activity != {}:\n",
    "        pickle.dump(self.agent_predictions_list_activity, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                     + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_predictions.pkl\", \"wb\"))\n",
    "\n",
    "    if self.agent_predictions_list_usage != {}:\n",
    "        pickle.dump(self.agent_predictions_list_usage, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                    + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_predictions_usage.pkl\", \"wb\"))\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, 'dump', dump)\n",
    "del dump "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd28404",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i.dump()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2908b1d",
   "metadata": {},
   "source": [
    "### 2.4 Get Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e7d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, item):\n",
    "    return eval(f\"self.{item}\")\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '__getitem__', __getitem__)\n",
    "del __getitem__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579af8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i.__getitem__()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8452fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __setitem__(self, key, value):\n",
    "    exec(f\"self.{key} = value\")\n",
    "    \n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '__setitem__', __setitem__)\n",
    "del __setitem__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe3f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i.__setitem__()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25340b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _format_time(self, seconds):\n",
    "    return \"{:02.0f}\".format(seconds // 60) + \":\" + \"{:02.0f}\".format(seconds % 60)\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '_format_time', _format_time)\n",
    "del _format_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525a914",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i._format_time()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59960bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_agent_names(self):\n",
    "    devices = self.config[\"user_input\"][\"shiftable_devices\"]\n",
    "    names = [\"activity\", \"load\"] + [\"usage_\"+ str(device).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower() for device in devices]\n",
    "    return names\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '_get_agent_names', _get_agent_names)\n",
    "del _get_agent_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6773c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i._get_agent_names()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f1761",
   "metadata": {},
   "source": [
    "### 2.5 Creating default configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f392ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the default configuration\n",
    "# -------------------------------------------------------------------------------------------\n",
    "def get_default_config(self, agents):\n",
    "    if type(agents) != list:\n",
    "        agents = [agents]\n",
    "\n",
    "    agents = [agent.lower() for agent in agents]\n",
    "    for agent in agents:\n",
    "        exec(f\"self._get_default_{agent}_config()\")\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, 'get_default_config', get_default_config)\n",
    "del get_default_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i.get_default_config()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_default_preparation_config(self):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    # preparation\n",
    "    self.config[\"preparation\"] = {}\n",
    "    ## preparation: activity agent\n",
    "    self.config[\"preparation\"][\"activity\"] = {\n",
    "        \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "        \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "        \"aggregate\": {\"resample_param\": \"60T\"},\n",
    "        \"activity\": {\n",
    "            \"active_appliances\": deepcopy(self.config[\"user_input\"][\"active_appliances\"]),\n",
    "            \"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"]),\n",
    "        },\n",
    "        \"time\": {\"features\": [\"hour\", \"day_name\"]},\n",
    "        \"activity_lag\": {\"features\": [\"activity\"], \"lags\": [24, 48, 72]},\n",
    "    }\n",
    "    # preparation: usage agent\n",
    "    self.config[\"preparation\"][\"usage\"] = {\n",
    "        \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "        \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "        \"activity\": {\n",
    "            \"active_appliances\": deepcopy(self.config[\"user_input\"][\"active_appliances\"]),\n",
    "            \"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"]),\n",
    "        },\n",
    "        \"aggregate_hour\": {\"resample_param\": \"60T\"},\n",
    "        \"aggregate_day\": {\"resample_param\": \"24H\"},\n",
    "        \"time\": {\"features\": [\"hour\", \"day_name\"]},\n",
    "        \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"]),\n",
    "        \"device\": {\"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"])},\n",
    "    }\n",
    "    # preparation: load agent\n",
    "    self.config[\"preparation\"][\"load\"] = {\n",
    "        \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "        \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "        \"aggregate\": {\"resample_param\": \"60T\"},\n",
    "        \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"]),\n",
    "        \"device\": {\"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"])},\n",
    "    }\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '_get_default_preparation_config', _get_default_preparation_config)\n",
    "del _get_default_preparation_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i._get_default_preparation_config()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_default_activity_config(self):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    if (self.activity == None):\n",
    "        self.init_agents()\n",
    "    self._get_dates()\n",
    "    self.config[\"activity\"] = {\n",
    "        \"model_type\": self.model_type,\n",
    "        \"split_params\": {\n",
    "            \"train_start\": deepcopy(self.config[\"data\"][\"start_dates\"][\"activity\"]),\n",
    "            \"test_delta\": {\"days\": 1, \"seconds\": -1},\n",
    "            \"target\": \"activity\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '_get_default_activity_config', _get_default_activity_config)\n",
    "del _get_default_activity_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63489f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i._get_default_activity_config()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_default_load_config(self):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    if (self.load == None):\n",
    "        self.init_agents()\n",
    "    self._get_dates()\n",
    "    self.config[\"load\"] = {\n",
    "        \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"])\n",
    "    }\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '_get_default_load_config', _get_default_load_config)\n",
    "del _get_default_load_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021aee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i._get_default_load_config()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd52a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_default_usage_config(self):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    if (self.activity == None) | (self.load == None):\n",
    "        self.init_agents()\n",
    "    self._get_dates()\n",
    "    self.config[\"usage\"] = {\n",
    "        \"model_type\":  self.model_type,\n",
    "        \"train_start\": deepcopy(self.config[\"data\"][\"start_dates\"][\"usage\"]),\n",
    "    }\n",
    "    for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "        name = (\"usage_\" + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "        self.config[name] = self.config[\"usage\"]\n",
    "        self.config[\"data\"][\"start_dates\"][name] = self.config[\"data\"][\"start_dates\"][\"usage\"]\n",
    "\n",
    "# add to Evaluation agent\n",
    "setattr(Evaluation_Agent, '_get_default_usage_config', _get_default_usage_config)\n",
    "del _get_default_usage_config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816c0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation_Agent_i = Evaluation_Agent() \n",
    "output = Explainability_Agent_i._get_default_usage_config()\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b0351",
   "metadata": {},
   "source": [
    "# 3. Complete Evaluation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70cd1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Evaluation Agent\n",
    "# ===============================================================================================\n",
    "class Evaluation_Agent:\n",
    "    def __init__(self, DATA_PATH, model_type, config, load_data=True, load_files=None, weather_sel=False, xai = False):\n",
    "        import agents\n",
    "        from helper_functions import Helper\n",
    "        import pandas as pd\n",
    "\n",
    "        helper = Helper()\n",
    "\n",
    "        self.model_type = model_type\n",
    "        self.config = config\n",
    "        self.weather_sel = weather_sel\n",
    "        self.xai = xai\n",
    "        house_df = helper.load_household(DATA_PATH, config[\"data\"][\"household\"], weather_sel = weather_sel)\n",
    "        if load_data:\n",
    "            self.preparation = agents.Preparation_Agent(house_df)\n",
    "        else:\n",
    "            self.preparation = agents.Preparation_Agent(None)\n",
    "\n",
    "        self.price = (\n",
    "            agents.Price_Agent(helper.create_day_ahead_prices_df(DATA_PATH, \"Day-ahead Prices_201501010000-201601010000.csv\"))\n",
    "            if load_data\n",
    "            else None\n",
    "        )\n",
    "        self.activity = None\n",
    "        self.load = None\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = (\"usage_\" + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "            exec(f\"self.{name} = None\")\n",
    "        self.recommendation = None\n",
    "        self.df = {}\n",
    "        self.output = {}\n",
    "        self.errors = {}\n",
    "        self.agent_scores = {}\n",
    "        self.agent_predictions_list_activity = {}\n",
    "        self.agent_predictions_list_usage = {}\n",
    "        self.cold_start_scores = {}\n",
    "        self.results = {}\n",
    "        self.cold_start_days = pd.DataFrame()\n",
    "        if load_files != None:\n",
    "            self.load_from_drive(load_files)\n",
    "\n",
    "    # helper: loading and storing intermediary results and further helper\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def _load_object(self, filename):\n",
    "        import pickle\n",
    "        import json\n",
    "        import yaml\n",
    "\n",
    "        # using a command dict as a if-list\n",
    "        commands = {\n",
    "            \"pkl\": f\"pickle.load(open('{filename}', 'rb'))\",\n",
    "            \"json\": f\"json.load(open('{filename}', 'r'))\",\n",
    "            \"yaml\": f\"yaml.load(open('{filename}', 'r'), Loader = yaml.Loader)\",\n",
    "        }\n",
    "\n",
    "        *_, name, ftype = filename.split(\".\")\n",
    "        name = name[name.rfind(\"_\") + 1:]\n",
    "        obj = eval(commands[ftype])\n",
    "        self[name] = obj\n",
    "\n",
    "    def load_from_drive(self, files):\n",
    "        files = [files] if type(files) != list else files\n",
    "        for filename in files:\n",
    "            self._load_object(filename)\n",
    "\n",
    "    def dump(self, EXPORT_PATH):\n",
    "        import json\n",
    "        import yaml\n",
    "        import pickle\n",
    "\n",
    "        # storing the current configuration\n",
    "        json.dump(self.config, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                          + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_config.json\", \"w\"), indent=4)\n",
    "\n",
    "        # storing the prepared data\n",
    "        if self.df != {}:\n",
    "            pickle.dump(self.df, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                         + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_df.pkl\", \"wb\"))\n",
    "\n",
    "        # storing the agents' output\n",
    "        if self.output != {}:\n",
    "            pickle.dump(self.output, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                         + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_output.pkl\", \"wb\"))\n",
    "\n",
    "        # storing the results\n",
    "        if self.results != {}:\n",
    "            pickle.dump(self.results, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                        + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_results.pkl\", \"wb\"))\n",
    "\n",
    "        # storing the results\n",
    "        if self.agent_scores != {}:\n",
    "            pickle.dump(self.agent_scores, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                        + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_scores.pkl\", \"wb\"))\n",
    "\n",
    "        if self.agent_predictions_list_activity != {}:\n",
    "            pickle.dump(self.agent_predictions_list_activity, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                         + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_predictions.pkl\", \"wb\"))\n",
    "\n",
    "        if self.agent_predictions_list_usage != {}:\n",
    "            pickle.dump(self.agent_predictions_list_usage, open(EXPORT_PATH + str(self.config[\"data\"][\"household\"]) + '_' + str(self.config[\"activity\"][\"model_type\"]) +'_'\n",
    "                                        + str(self.config[\"usage\"][\"model_type\"]) + '_' + str(self.weather_sel) + \"_predictions_usage.pkl\", \"wb\"))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return eval(f\"self.{item}\")\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        exec(f\"self.{key} = value\")\n",
    "\n",
    "    def _format_time(self, seconds):\n",
    "        return \"{:02.0f}\".format(seconds // 60) + \":\" + \"{:02.0f}\".format(seconds % 60)\n",
    "\n",
    "    def _get_agent_names(self):\n",
    "        devices = self.config[\"user_input\"][\"shiftable_devices\"]\n",
    "        names = [\"activity\", \"load\"] + [\"usage_\"+ str(device).replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower() for device in devices]\n",
    "        return names\n",
    "\n",
    "    # creating the default configuration\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def get_default_config(self, agents):\n",
    "        if type(agents) != list:\n",
    "            agents = [agents]\n",
    "\n",
    "        agents = [agent.lower() for agent in agents]\n",
    "        for agent in agents:\n",
    "            exec(f\"self._get_default_{agent}_config()\")\n",
    "\n",
    "    def _get_default_preparation_config(self):\n",
    "        from copy import deepcopy\n",
    "\n",
    "        # preparation\n",
    "        self.config[\"preparation\"] = {}\n",
    "        ## preparation: activity agent\n",
    "        self.config[\"preparation\"][\"activity\"] = {\n",
    "            \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "            \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "            \"aggregate\": {\"resample_param\": \"60T\"},\n",
    "            \"activity\": {\n",
    "                \"active_appliances\": deepcopy(self.config[\"user_input\"][\"active_appliances\"]),\n",
    "                \"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"]),\n",
    "            },\n",
    "            \"time\": {\"features\": [\"hour\", \"day_name\"]},\n",
    "            \"activity_lag\": {\"features\": [\"activity\"], \"lags\": [24, 48, 72]},\n",
    "        }\n",
    "        # preparation: usage agent\n",
    "        self.config[\"preparation\"][\"usage\"] = {\n",
    "            \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "            \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "            \"activity\": {\n",
    "                \"active_appliances\": deepcopy(self.config[\"user_input\"][\"active_appliances\"]),\n",
    "                \"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"]),\n",
    "            },\n",
    "            \"aggregate_hour\": {\"resample_param\": \"60T\"},\n",
    "            \"aggregate_day\": {\"resample_param\": \"24H\"},\n",
    "            \"time\": {\"features\": [\"hour\", \"day_name\"]},\n",
    "            \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"]),\n",
    "            \"device\": {\"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"])},\n",
    "        }\n",
    "        # preparation: load agent\n",
    "        self.config[\"preparation\"][\"load\"] = {\n",
    "            \"truncate\": {\"features\": \"all\", \"factor\": 1.5, \"verbose\": 0},\n",
    "            \"scale\": {\"features\": \"all\", \"kind\": \"MinMax\", \"verbose\": 0},\n",
    "            \"aggregate\": {\"resample_param\": \"60T\"},\n",
    "            \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"]),\n",
    "            \"device\": {\"threshold\": deepcopy(self.config[\"user_input\"][\"threshold\"])},\n",
    "        }\n",
    "\n",
    "    def _get_default_activity_config(self):\n",
    "        from copy import deepcopy\n",
    "\n",
    "        if (self.activity == None):\n",
    "            self.init_agents()\n",
    "        self._get_dates()\n",
    "        self.config[\"activity\"] = {\n",
    "            \"model_type\": self.model_type,\n",
    "            \"split_params\": {\n",
    "                \"train_start\": deepcopy(self.config[\"data\"][\"start_dates\"][\"activity\"]),\n",
    "                \"test_delta\": {\"days\": 1, \"seconds\": -1},\n",
    "                \"target\": \"activity\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def _get_default_load_config(self):\n",
    "        from copy import deepcopy\n",
    "\n",
    "        if (self.load == None):\n",
    "            self.init_agents()\n",
    "        self._get_dates()\n",
    "        self.config[\"load\"] = {\n",
    "            \"shiftable_devices\": deepcopy(self.config[\"user_input\"][\"shiftable_devices\"])\n",
    "        }\n",
    "\n",
    "    def _get_default_usage_config(self):\n",
    "        from copy import deepcopy\n",
    "\n",
    "        if (self.activity == None) | (self.load == None):\n",
    "            self.init_agents()\n",
    "        self._get_dates()\n",
    "        self.config[\"usage\"] = {\n",
    "            \"model_type\":  self.model_type,\n",
    "            \"train_start\": deepcopy(self.config[\"data\"][\"start_dates\"][\"usage\"]),\n",
    "        }\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = (\"usage_\" + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "            self.config[name] = self.config[\"usage\"]\n",
    "            self.config[\"data\"][\"start_dates\"][name] = self.config[\"data\"][\"start_dates\"][\"usage\"]\n",
    "\n",
    "    # extracting the available dates in the data\n",
    "    def get_first_date(self, df):\n",
    "        import pandas as pd\n",
    "\n",
    "        first_data = df.index.to_series()[0]\n",
    "        return (first_data + pd.Timedelta(\"1D\")).replace(hour=0, minute=0, second=0)\n",
    "\n",
    "    def get_last_date(self, df):\n",
    "        import pandas as pd\n",
    "\n",
    "        last_data = df.index.to_series()[-1]\n",
    "        return (last_data - pd.Timedelta(\"1D\")).replace(hour=23, minute=59, second=59)\n",
    "\n",
    "    def get_min_start_date(self, df):\n",
    "        df = df.dropna()\n",
    "        return df.loc[df.index.hour == 0, :].index[0]\n",
    "\n",
    "    def _get_dates(self):\n",
    "        import numpy as np\n",
    "\n",
    "        # first and last date in the data\n",
    "        self.config[\"data\"][\"first_date\"] = str(self.get_first_date(self.preparation.input))[:10]\n",
    "        self.config[\"data\"][\"last_date\"] = str(self.get_last_date(self.preparation.input))[:10]\n",
    "        # start dates\n",
    "        start_dates = {}\n",
    "        for agent, data in self.df.items():\n",
    "            start_dates[agent] = self.get_min_start_date(data)\n",
    "        start_dates[\"combined\"] = np.max(list(start_dates.values()))\n",
    "        self.config[\"data\"][\"start_dates\"] = {\n",
    "            key: str(value)[:10] for key, value in start_dates.items()\n",
    "        }\n",
    "\n",
    "\n",
    "    # running the pipeline\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def pipeline(self, agents, **kwargs):\n",
    "        # converting single agent to list\n",
    "        if type(agents) != list:\n",
    "            agents = [agents]\n",
    "\n",
    "        agents = [agent.lower() for agent in agents]\n",
    "\n",
    "        if 'preparation' in agents:\n",
    "            self._prepare(**kwargs)\n",
    "        if 'activity' in agents:\n",
    "            self._pipeline_activity_usage_load('activity', **kwargs)\n",
    "        if 'usage' in agents:\n",
    "            usage_agents = [\"usage_\"+ device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower() for device in self.config[\"user_input\"][\"shiftable_devices\"]]\n",
    "            for agent in usage_agents:\n",
    "                self._pipeline_activity_usage_load(agent, **kwargs)\n",
    "        if 'load' in agents:\n",
    "            self._pipeline_activity_usage_load('load', **kwargs)\n",
    "        if 'recommendation' in agents:\n",
    "            self._get_recommendations(**kwargs)\n",
    "\n",
    "    def init_agents(self):\n",
    "        import agents\n",
    "\n",
    "        # initialize the agents\n",
    "        self.activity = agents.Activity_Agent(self.df[\"activity\"])\n",
    "        self.load = agents.Load_Agent(self.df[\"load\"])\n",
    "\n",
    "        # initialize usage agents for the shiftable devices: agent = usage_name\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = (\"usage_\" + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower())\n",
    "            exec(f'self.{name} = Usage_Agent(self.df[\"usage\"], \"{device}\")')\n",
    "            self.df[name] = self.df[\"usage\"]\n",
    "\n",
    "        self.recommendation = agents.Recommendation_Agent(\n",
    "            self.df[\"activity\"],\n",
    "            self.df[\"usage\"],\n",
    "            self.df[\"load\"],\n",
    "            self.price.input,\n",
    "            self.config[\"user_input\"][\"shiftable_devices\"]\n",
    "        )\n",
    "\n",
    "    def _prepare(self, agent=\"all\"):\n",
    "        lines = {\n",
    "            \"activity\": 'self.df[\"activity\"] = self.preparation.pipeline_activity(self.preparation.input, self.config[\"preparation\"][\"activity\"])',\n",
    "            \"usage\": 'self.df[\"usage\"] = self.preparation.pipeline_usage(self.preparation.input, self.config[\"preparation\"][\"usage\"])',\n",
    "            \"load\": 'self.df[\"load\"] ,_,_ = self.preparation.pipeline_load(self.preparation.input, self.config[\"preparation\"][\"load\"])',\n",
    "        }\n",
    "        if agent == \"all\":\n",
    "            for agent in [\"activity\", \"usage\", \"load\"]:\n",
    "                exec(lines[agent])\n",
    "                print(f\"[evaluation agent] Finished preparing the data for the {agent} agent.\")\n",
    "        else:\n",
    "            exec(lines[agent])\n",
    "            print(f\"[evaluation agent] Finished preparing the data for the {agent} agent.\")\n",
    "\n",
    "    def _pipeline_activity_usage_load(self, agent, verbose=1):\n",
    "        import pandas as pd\n",
    "        from IPython.display import clear_output\n",
    "        import time\n",
    "\n",
    "        self.output[agent] = {}\n",
    "        self.errors[agent] = {}\n",
    "\n",
    "        # init agents\n",
    "        if (self.activity == None) | (self.load == None):\n",
    "            self.init_agents()\n",
    "\n",
    "        # determining the dates\n",
    "        dates = self.df[agent].index.to_series()\n",
    "        start = pd.to_datetime(self.config[\"data\"][\"start_dates\"][agent])\n",
    "        end = pd.to_datetime(self.config[\"data\"][\"last_date\"]).replace(\n",
    "            hour=23, minute=59, second=59\n",
    "        )\n",
    "        dates = dates[(dates >= start) & (dates <= end)].resample(\"1D\").count()\n",
    "        dates = [str(date)[:10] for date in list(dates.index)]\n",
    "\n",
    "        # pipeline funtion\n",
    "        start = time.time() if verbose >= 1 else None\n",
    "        for date in dates:\n",
    "            try:\n",
    "                self.output[agent][date] = eval(f'self.{agent}.pipeline(self.{agent}.input, \"{date}\", **self.config[\"{agent}\"])')\n",
    "                # verbose\n",
    "                if verbose >= 1:\n",
    "                    clear_output(wait=True)\n",
    "                    elapsed = time.time() - start\n",
    "                    remaining = (elapsed / (len(dates)) * (len(dates) - (dates.index(date) + 1)))\n",
    "                    print(f\"agent:\\t\\t{agent}\")\n",
    "                    print(f\"progress: \\t{dates.index(date)+1}/{len(dates)}\")\n",
    "                    print(f\"time:\\t\\t[{self._format_time(elapsed)}<{self._format_time(remaining)}]\\n\")\n",
    "                    print(self.output[agent][date])\n",
    "            except Exception as e:\n",
    "                self.errors[agent][date] = type(e).__name__\n",
    "\n",
    "    def _get_recommendations(\n",
    "        self, activity_threshold, usage_threshold, dates: tuple = \"all\"\n",
    "    ):\n",
    "        import numpy as np\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        # determining dates\n",
    "        start = (\n",
    "            self.config[\"data\"][\"start_dates\"][\"combined\"]\n",
    "            if dates == \"all\"\n",
    "            else dates[0]\n",
    "        )\n",
    "        end = self.config[\"data\"][\"last_date\"] if dates == \"all\" else dates[1]\n",
    "        dates = np.arange(\n",
    "            np.datetime64(start),\n",
    "            np.datetime64(end) + np.timedelta64(1, \"D\"),\n",
    "            np.timedelta64(1, \"D\"),\n",
    "        )\n",
    "        dates = [str(date) for date in dates]\n",
    "\n",
    "        # creating recommendations\n",
    "        self.errors[\"recommendation\"] = {}\n",
    "        self.output[\"recommendation\"] = {}\n",
    "        for date in dates:\n",
    "            try:\n",
    "                self.output[\"recommendation\"][date] = self.recommendation.pipeline(\n",
    "                    date, activity_threshold, usage_threshold, evaluation=self.output\n",
    "                )\n",
    "            except Exception as e:\n",
    "                self.errors[\"recommendation\"][date] = e\n",
    "\n",
    "        # merging the recommendations into one dataframe\n",
    "        df = list(self.output[\"recommendation\"].values())[0]\n",
    "\n",
    "        for idx in range(1, len(self.output[\"recommendation\"].values())):\n",
    "            df = df.append(list(self.output[\"recommendation\"].values())[idx])\n",
    "        df.set_index(\"recommendation_date\", inplace=True)\n",
    "        self.output[\"recommendation\"] = df\n",
    "        clear_output()\n",
    "\n",
    "    # individual agent scores\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def get_agent_scores(self, xai=False, **args):\n",
    "        self.xai =xai\n",
    "        scores = {}\n",
    "        scores['activity_auc'] = None\n",
    "        scores['time_mean_lime_activity'] = {}\n",
    "        scores['time_mean_shap_activity'] = {}\n",
    "        scores['usage_auc'] = {}\n",
    "        scores['time_mean_lime_usage'] = {}\n",
    "        scores['time_mean_shap_usage'] = {}\n",
    "        scores['load_mse'] = {}\n",
    "\n",
    "        agents = self._get_agent_names()\n",
    "        for agent in agents:\n",
    "            agent_type = agent.split('_')[0]\n",
    "\n",
    "            if agent_type == 'activity':\n",
    "                _, auc_test_activity, _, time_mean_lime_activity, time_mean_shap_activity, predictions_list_activity = self[agent].evaluate(self[agent].input, **self.config[agent], xai=self.xai, **args)\n",
    "                scores['activity_auc'] = auc_test_activity\n",
    "                scores['time_mean_lime_activity'] = time_mean_lime_activity\n",
    "                scores['time_mean_shap_activity'] = time_mean_shap_activity\n",
    "\n",
    "            if agent_type == 'usage':\n",
    "                _, auc_test_usage, _, time_mean_lime_usage, time_mean_shap_usage, predictions_list_usage = self[agent].evaluate(self[agent].input, **self.config[agent], xai=self.xai, **args)\n",
    "                scores['usage_auc'][self[agent].device] = auc_test_usage\n",
    "                scores['time_mean_lime_usage'] = time_mean_lime_usage\n",
    "                scores['time_mean_shap_usage'] = time_mean_shap_usage\n",
    "\n",
    "            if agent_type == 'load':\n",
    "                try:\n",
    "                    scores['load_mse'] = self.load.evaluate(**self.config['load'], evaluation=self.output['load'])\n",
    "                except KeyError:\n",
    "                    scores['load_mse'] = self.load.evaluate(**self.config['load'])\n",
    "        self.agent_scores = scores\n",
    "        self.agent_predictions_list_activity = predictions_list_activity\n",
    "        self.agent_predictions_list_usage = predictions_list_usage\n",
    "        return scores, predictions_list_activity, predictions_list_usage\n",
    "\n",
    "    def agent_scores_to_summary(self, scores='default'):\n",
    "        import pandas as pd\n",
    "\n",
    "        if scores == 'default':\n",
    "            scores = self.agent_scores\n",
    "\n",
    "        summary = {}\n",
    "        summary['activity_auc'] = pd.DataFrame()\n",
    "        summary['usage_auc'] = pd.DataFrame()\n",
    "        summary['load_mse'] = pd.DataFrame()\n",
    "\n",
    "        household_id = self.config['data']['household']\n",
    "        devices = self.config['user_input']['shiftable_devices']\n",
    "\n",
    "        # activity\n",
    "        summary['activity_auc'].loc[household_id, '-'] = scores['activity_auc']\n",
    "        # usage\n",
    "        i = 0\n",
    "        for device in devices:\n",
    "            summary['usage_auc'].loc[household_id, i] = scores['usage_auc'][device]\n",
    "            i += 1\n",
    "        # load\n",
    "        i = 0\n",
    "        for device in devices:\n",
    "            summary['load_mse'].loc[household_id, i] = scores['load_mse'][device]\n",
    "            i += 1\n",
    "\n",
    "        summary['activity_auc'].index.name = 'household'\n",
    "        summary['usage_auc'].index.name = 'household'\n",
    "        summary['load_mse'].index.name = 'household'\n",
    "        summary['usage_auc'].columns.name = 'device'\n",
    "        summary['load_mse'].columns.name = 'device'\n",
    "        return summary\n",
    "\n",
    "    def predictions_to_xai_metrics(self, predictions, activity_threshold= 0.5, usage_threshold= 0.5):\n",
    "        import numpy as np\n",
    "        import sklearn.metrics\n",
    "\n",
    "        y_true = np.array(predictions[0])\n",
    "        y_hat_test = np.array(predictions[1])\n",
    "        y_hat_lime = np.array(predictions[2])\n",
    "        y_hat_shap = np.array(predictions[3])\n",
    "\n",
    "        self.activity_threshold = activity_threshold\n",
    "        self.usage_threshold = usage_threshold\n",
    "\n",
    "        self.y_true = y_true\n",
    "        self.y_hat_test = y_hat_test\n",
    "        self.y_hat_lime = y_hat_lime\n",
    "        self.y_hat_shap = y_hat_shap\n",
    "\n",
    "        #turn y_hat test into binary\n",
    "        self.y_hat_test_bin = np.where(y_hat_test > activity_threshold, 1, 0)\n",
    "        self.y_hat_lime_bin = np.where(y_hat_lime > activity_threshold, 1, 0)\n",
    "        self.y_hat_shap_bin = np.where(y_hat_shap > activity_threshold, 1, 0)\n",
    "\n",
    "\n",
    "        xai_scores = {}\n",
    "        xai_scores['activity_lime_auc_true'] = None\n",
    "        xai_scores['activity_shap_auc_true'] = {}\n",
    "        xai_scores['activity_lime_auc_pred'] = {}\n",
    "        xai_scores['activity_shap_auc_pred'] = {}\n",
    "        xai_scores['activity_lime_MAE'] = {}\n",
    "        xai_scores['activity_shap_MAE'] = {}\n",
    "\n",
    "        # AUC of true - xai prediction\n",
    "        xai_scores['activity_lime_auc_true'] = sklearn.metrics.roc_auc_score(y_true[:len(y_hat_lime)], y_hat_lime)\n",
    "        xai_scores['activity_shap_auc_true'] = sklearn.metrics.roc_auc_score(y_true[:len(y_hat_shap)], y_hat_shap)\n",
    "\n",
    "        # AUC of predicted probabilities - xai prediction\n",
    "        xai_scores['activity_lime_auc_pred'] = sklearn.metrics.roc_auc_score(self.y_hat_test_bin[:len(y_hat_lime)], self.y_hat_lime_bin)\n",
    "        xai_scores['activity_shap_auc_pred'] = sklearn.metrics.roc_auc_score(self.y_hat_test_bin[:len(y_hat_shap)], self.y_hat_shap_bin)\n",
    "\n",
    "        # MAE\n",
    "        MAE_SHAP = []\n",
    "        zip_object = zip(self.y_hat_test[:len(y_hat_shap)],self.y_hat_shap)\n",
    "        for list1_i, list2_i in zip_object:\n",
    "            MAE_SHAP.append(abs(list1_i - list2_i))\n",
    "\n",
    "        MAE_LIME = []\n",
    "        zip_object = zip(self.y_hat_test[:len(y_hat_lime)], self.y_hat_lime)\n",
    "        for list1_i, list2_i in zip_object:\n",
    "            MAE_LIME.append(abs(list1_i - list2_i))\n",
    "\n",
    "        xai_scores['activity_lime_MAE'] = np.mean(MAE_LIME)\n",
    "        xai_scores['activity_shap_MAE'] = np.mean(MAE_SHAP)\n",
    "\n",
    "        self.xai_scores = xai_scores\n",
    "        return xai_scores\n",
    "\n",
    "    def predictions_to_xai_metrics_usage(self, predictions, activity_threshold= 0.5, usage_threshold= 0.5):\n",
    "        import numpy as np\n",
    "        import sklearn.metrics\n",
    "\n",
    "        y_true = np.array(predictions[0])\n",
    "        y_hat_test = np.array(predictions[1])\n",
    "        y_hat_lime = np.array(predictions[2])\n",
    "        y_hat_shap = np.array(predictions[3])\n",
    "\n",
    "        self.activity_threshold = activity_threshold\n",
    "        self.usage_threshold = usage_threshold\n",
    "\n",
    "        self.y_true = y_true\n",
    "        self.y_hat_test = y_hat_test\n",
    "        self.y_hat_lime = y_hat_lime\n",
    "        self.y_hat_shap = y_hat_shap\n",
    "\n",
    "        #turn y_hat test into binary\n",
    "        self.y_hat_test_bin = np.where(y_hat_test > usage_threshold, 1, 0)\n",
    "        self.y_hat_lime_bin = np.where(y_hat_lime > usage_threshold, 1, 0)\n",
    "        self.y_hat_shap_bin = np.where(y_hat_shap > usage_threshold, 1, 0)\n",
    "\n",
    "\n",
    "        xai_scores = {}\n",
    "        xai_scores['usage_lime_auc_true'] = None\n",
    "        xai_scores['usage_shap_auc_true'] = {}\n",
    "        xai_scores['usage_lime_auc_pred'] = {}\n",
    "        xai_scores['usage_shap_auc_pred'] = {}\n",
    "        xai_scores['usage_lime_MAE'] = {}\n",
    "        xai_scores['usage_shap_MAE'] = {}\n",
    "\n",
    "        # AUC of true - xai prediction\n",
    "        xai_scores['usage_lime_auc_true'] = sklearn.metrics.roc_auc_score(y_true[:len(y_hat_lime)], y_hat_lime)\n",
    "        xai_scores['usage_shap_auc_true'] = sklearn.metrics.roc_auc_score(y_true[:len(y_hat_shap)], y_hat_shap)\n",
    "\n",
    "        # AUC of predicted probabilities - xai prediction\n",
    "        xai_scores['usage_lime_auc_pred'] = sklearn.metrics.roc_auc_score(self.y_hat_test_bin[:len(y_hat_lime)], self.y_hat_lime_bin)\n",
    "        xai_scores['usage_shap_auc_pred'] = sklearn.metrics.roc_auc_score(self.y_hat_test_bin[:len(y_hat_shap)], self.y_hat_shap_bin)\n",
    "\n",
    "        # MAE\n",
    "\n",
    "        MAE_SHAP = []\n",
    "        zip_object = zip(self.y_hat_test[:len(y_hat_shap)], self.y_hat_shap)\n",
    "        for list1_i, list2_i in zip_object:\n",
    "            MAE_SHAP.append(abs(list1_i - list2_i))\n",
    "\n",
    "        MAE_LIME = []\n",
    "        zip_object = zip(self.y_hat_test[:len(y_hat_lime)], self.y_hat_lime)\n",
    "        for list1_i, list2_i in zip_object:\n",
    "            MAE_LIME.append(abs(list1_i - list2_i))\n",
    "\n",
    "        xai_scores['usage_lime_MAE'] = np.mean(MAE_LIME)\n",
    "        xai_scores['usage_shap_MAE'] = np.mean(MAE_SHAP)\n",
    "\n",
    "\n",
    "        self.xai_scores = xai_scores\n",
    "        return xai_scores\n",
    "\n",
    "    # cold start: predict on all data\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def predict_all(self, agent, **kwargs):\n",
    "        agent_type = agent.split(\"_\")[0]\n",
    "        return eval(f\"self._predict_all_{agent_type}(agent, **kwargs)\")\n",
    "\n",
    "    def _predict_all_load(self, agent, device):\n",
    "        y_hat = {\n",
    "            date: profiles.loc[device, :]\n",
    "            for date, profiles in self.output[agent].items()\n",
    "        }\n",
    "        return y_hat\n",
    "\n",
    "    def _predict_all_activity(self, agent):\n",
    "        return self._predict_all_activity_usage(agent)\n",
    "\n",
    "    def _predict_all_usage(self, agent):\n",
    "        return self._predict_all_activity_usage(agent)\n",
    "\n",
    "    def _predict_all_activity_usage(self, agent):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "        y_hat = {}\n",
    "        # intitializing the error dict\n",
    "        try:\n",
    "            self.errors[\"evaluation\"]\n",
    "        except KeyError:\n",
    "            self.errors[\"evaluation\"] = {}\n",
    "\n",
    "        try:\n",
    "            self.errors[\"evaluation\"][agent]\n",
    "        except KeyError:\n",
    "            self.errors[\"evaluation\"][agent] = {}\n",
    "\n",
    "        # determining the dates\n",
    "        dates = np.arange(\n",
    "            np.datetime64(self.config[\"data\"][\"start_dates\"][agent]),\n",
    "            np.datetime64(self.config[\"data\"][\"last_date\"]) + np.timedelta64(1, \"D\"),\n",
    "            np.timedelta64(1, \"D\"),\n",
    "        )\n",
    "        start = dates[0]\n",
    "        end = dates[-1] + pd.Timedelta(days=1, seconds=-1)\n",
    "\n",
    "        # creating X_test\n",
    "        X_test, _, _, _ = self[agent].train_test_split(\n",
    "            self[agent].input,\n",
    "            dates[-1] + np.timedelta64(1, \"D\"),\n",
    "            train_start=self.config[\"data\"][\"start_dates\"][agent],\n",
    "        )\n",
    "\n",
    "        # creating predictions\n",
    "        for date in dates:\n",
    "            X_train, y_train, _, _ = self[agent].train_test_split(\n",
    "                self[agent].input,\n",
    "                date,\n",
    "                train_start=self.config[\"data\"][\"start_dates\"][agent],\n",
    "            )\n",
    "            try:\n",
    "                model = self[agent].fit(X_train, y_train, self.model_type)\n",
    "                y_hat[date] = self[agent].predict(model, X_test)\n",
    "            except Exception as e:\n",
    "                self.errors[\"evaluation\"][agent][date] = type(e).__name__\n",
    "        return y_hat\n",
    "\n",
    "    # cold start: calculate cold start scores\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def get_cold_start_scores(self, fn: dict = \"default\"):\n",
    "        from IPython.display import clear_output\n",
    "\n",
    "        scores = {}\n",
    "        fn = {} if fn == \"default\" else fn\n",
    "\n",
    "        # activity-agent\n",
    "        scores[\"activity\"] = self._get_cold_start_score(\"activity\", fn=fn.get(\"activity\", \"default\"))\n",
    "        clear_output()\n",
    "\n",
    "        for device in self.config[\"user_input\"][\"shiftable_devices\"]:\n",
    "            name = device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "            # usage agent\n",
    "            scores[\"usage_\" + name] = self._get_cold_start_score(\"usage_\" + name, fn=fn.get(\"usage\", \"default\"))\n",
    "            # load agent\n",
    "            scores[\"load_\" + name] = self._get_cold_start_score(\"load\", fn=fn.get(\"load\", \"default\"), device=device)\n",
    "            clear_output()\n",
    "        self.cold_start_scores = scores\n",
    "\n",
    "    def _get_cold_start_score(self, agent, fn=\"default\", **kwargs):\n",
    "        import sklearn.metrics\n",
    "        import numpy as np\n",
    "\n",
    "        agent_type = agent.split(\"_\")[0]\n",
    "        # specifying the correct score function\n",
    "        fn_dict = {\n",
    "            \"activity\": f\"self.{agent}.auc\",\n",
    "            \"usage\": f\"self.{agent}.auc\",\n",
    "            \"load\": \"sklearn.metrics.mean_squared_error\",\n",
    "        }\n",
    "        fn = eval(fn_dict[agent_type]) if fn == \"default\" else fn\n",
    "\n",
    "        # specifying the correct y_true, y_hat\n",
    "        y_dict = {\n",
    "            \"activity\": \"self[agent].train_test_split(self[agent].input, date=np.datetime64(self.config['data']['last_date'])+np.timedelta64(1, 'D'), train_start=self.config['data']['start_dates'][agent])\",\n",
    "            \"usage\": \"self[agent].train_test_split(self[agent].input, date=np.datetime64(self.config['data']['last_date'])+np.timedelta64(1, 'D'), train_start=self.config['data']['start_dates'][agent])\",\n",
    "            \"load\": \"list(self.output['load'].values())[-1].loc[kwargs['device'], :]\",\n",
    "        }\n",
    "        y_true = eval(y_dict[agent_type])\n",
    "        y_true = y_true if agent_type == \"load\" else y_true[1]\n",
    "        y_hat = self.predict_all(agent, **kwargs)\n",
    "\n",
    "        # calculating the scores\n",
    "        scores = {}\n",
    "        for date, pred in y_hat.items():\n",
    "            scores[date] = fn(y_true, pred)\n",
    "        return scores\n",
    "\n",
    "    def cold_start_scores_to_df(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "        scores_df = pd.DataFrame()\n",
    "        # convert dicts into dataframe\n",
    "        for key in self.cold_start_scores.keys():\n",
    "            for date, score in self.cold_start_scores[key].items():\n",
    "                scores_df.loc[str(date), key] = score\n",
    "\n",
    "        # sort the dataframe\n",
    "        cols = (\n",
    "            [\"activity\"]\n",
    "            + [col for col in scores_df if col.startswith(\"usage\")]\n",
    "            + [col for col in scores_df if col.startswith(\"load\")]\n",
    "        )\n",
    "        scores_df.index = scores_df.index.map(np.datetime64)\n",
    "        scores_df = scores_df[cols].sort_index()\n",
    "        return scores_df\n",
    "\n",
    "    def get_cold_start_days(self, tolerance_values):\n",
    "        import pandas as pd\n",
    "\n",
    "        self.cold_start_days = pd.DataFrame({\"tolerance\": []}).set_index(\"tolerance\")\n",
    "        scores_df = self.cold_start_scores_to_df()\n",
    "        tolerance_fn = {\n",
    "            \"activity\": \"scores_df[agent].max() * (1 - tolerance[agent_type])\",\n",
    "            \"usage\": \"scores_df[agent].max() * (1 - tolerance[agent_type])\",\n",
    "            \"load\": \"tolerance['load']\",\n",
    "        }\n",
    "\n",
    "        # agent coldstart days\n",
    "        for tolerance in tolerance_values:\n",
    "            tolerance = {\"activity\": tolerance, \"usage\": tolerance, \"load\": tolerance}\n",
    "\n",
    "            for agent in scores_df.columns:\n",
    "                agent_type = agent.split(\"_\")[0]\n",
    "\n",
    "                done = False\n",
    "                day = 0\n",
    "                while not done:\n",
    "                    day += 1\n",
    "                    tolerance_value = eval(tolerance_fn[agent_type])\n",
    "                    if agent_type == \"load\":\n",
    "                        done = all(scores_df[agent].values[day - 1:] < tolerance_value)\n",
    "                    else:\n",
    "                        done = all(scores_df[agent].values[day - 1:] > tolerance_value)\n",
    "                self.cold_start_days.loc[tolerance[agent_type], agent] = day\n",
    "        # framework cold start days\n",
    "        self.cold_start_days['framework'] = self.cold_start_days.max(axis=1)\n",
    "\n",
    "    def cold_start_to_summary(self, tolerance_values='all'):\n",
    "        import pandas as pd\n",
    "\n",
    "        if tolerance_values == 'all':\n",
    "            tolerance_values = list(self.cold_start_days.index)\n",
    "\n",
    "        household_id = self.config['data']['household']\n",
    "        devices = self.config['user_input']['shiftable_devices']\n",
    "\n",
    "        summary = {}\n",
    "        summary['activity'] = {}\n",
    "        summary['usage'] = {}\n",
    "        summary['load'] = {}\n",
    "        summary['framework'] = {}\n",
    "\n",
    "        # activity agent\n",
    "        summary['activity']['-'] = {}  # '-': placeholder for device\n",
    "        summary['activity']['-'][household_id] = self.cold_start_days['activity'][tolerance_values].astype(int).to_list()\n",
    "        # usage agent\n",
    "        i = 0\n",
    "        for device in devices:\n",
    "            name = 'usage_' + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "            summary['usage'][i] = {}\n",
    "            summary['usage'][i][household_id] = self.cold_start_days[name][tolerance_values].astype(int).to_list()\n",
    "            i += 1\n",
    "\n",
    "        # load agent\n",
    "        i = 0\n",
    "        for device in devices:\n",
    "            name = 'load_' + device.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "            summary['load'][i] = {}\n",
    "            summary['load'][i][household_id] = self.cold_start_days[name][tolerance_values].astype(int).to_list()\n",
    "            i += 1\n",
    "\n",
    "        # framework\n",
    "        summary['framework']['-'] = {}  # '-': placeholder for device\n",
    "        summary['framework']['-'][household_id] = self.cold_start_days['framework'][tolerance_values].astype(int).to_list()\n",
    "\n",
    "        # converting the format\n",
    "        for key, value in summary.items():\n",
    "            summary[key] = pd.DataFrame(value)\n",
    "            summary[key].columns.name = 'device'\n",
    "            summary[key].index.name = 'household'\n",
    "        return summary\n",
    "\n",
    "    # cold start: visualizations\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def _plot_axs(self, axs, y, x=None, legend=None, **kwargs):\n",
    "        axs.plot(x, y) if x != None else axs.plot(y)\n",
    "        axs.set(**kwargs)\n",
    "        axs.legend(legend) if legend != None else None\n",
    "\n",
    "    def visualize_cold_start(self, metrics_name: dict, tolerance: dict = None, figsize=(18, 5)):\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        scores_df = self.cold_start_scores_to_df()\n",
    "        fig, axs = plt.subplots(1, 3, figsize=figsize)\n",
    "\n",
    "        # activity\n",
    "        self._plot_axs(\n",
    "            axs[0],\n",
    "            x=range(1, scores_df.shape[0] + 1),\n",
    "            y=scores_df[\"activity\"],\n",
    "            title=f\"[activity] {metrics_name['activity']}\",\n",
    "        )\n",
    "        legend = ['activity']\n",
    "        if tolerance != None:\n",
    "            tolerance_value = scores_df[\"activity\"].max() * (1 - tolerance[\"activity\"])\n",
    "            color = axs[0].lines[-1].get_color()\n",
    "            axs[0].plot([tolerance_value] * scores_df.shape[0], \"--\", c=color)\n",
    "            legend.append([f\"tolerance@{tolerance['activity']}\"])\n",
    "        axs[0].legend(legend)\n",
    "        axs[0].set_xlabel(\"days\")\n",
    "\n",
    "        # usage\n",
    "        usage_agents = [agent for agent in scores_df.columns if agent.find(\"usage\") != -1]\n",
    "        legend = []\n",
    "        for agent in usage_agents:\n",
    "            self._plot_axs(axs[1],\n",
    "                x=range(1, scores_df.shape[0] + 1),\n",
    "                y=scores_df[agent],\n",
    "                title=f\"[usage] {metrics_name['usage']}\",\n",
    "            )\n",
    "            legend += [agent]\n",
    "            if tolerance != None:\n",
    "                tolerance_value = scores_df[agent].max() * (1 - tolerance[\"usage\"])\n",
    "                color = axs[1].lines[-1].get_color()\n",
    "                axs[1].plot([tolerance_value] * scores_df.shape[0], \"--\", c=color)\n",
    "                legend += [f\"tolerance_{agent.replace('usage_', '')}@{tolerance['usage']}\"]\n",
    "        axs[1].legend(legend)\n",
    "        axs[1].set_xlabel(\"days\")\n",
    "\n",
    "        # load\n",
    "        load_agents = [agent for agent in scores_df.columns if agent.find(\"load\") != -1]\n",
    "        legend = []\n",
    "        for agent in load_agents:\n",
    "            self._plot_axs(\n",
    "                axs[2],\n",
    "                x=range(1, scores_df.shape[0] + 1),\n",
    "                y=scores_df[agent],\n",
    "                title=f\"[load] {metrics_name['load']}\",\n",
    "            )\n",
    "            legend += [agent]\n",
    "        if tolerance != None:\n",
    "            axs[2].plot([tolerance[\"load\"]] * scores_df.shape[0], \"--\", c=\"black\")\n",
    "            legend += [f\"tolerance@{tolerance['load']}\"]\n",
    "        axs[2].legend(legend)\n",
    "        axs[2].set_xlabel(\"days\")\n",
    "\n",
    "    # evaluation: calculate costs per device run\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def calculate_cost(self, date, hour, load):\n",
    "        import numpy as np\n",
    "\n",
    "        if np.isnan(hour):\n",
    "            return np.nan\n",
    "        else:\n",
    "            price_idx = self.price.input.index.values\n",
    "            prices = self.price.input.values\n",
    "\n",
    "            dt = np.datetime64(date) + np.timedelta64(int(hour), \"h\")\n",
    "            # getting the correct position for the load in the load array\n",
    "            i = np.where(price_idx == dt)[0][0]\n",
    "            i = np.where(price_idx == dt)[0][0]\n",
    "\n",
    "            # reshaping the load array and calculating the costs\n",
    "            before = np.zeros(i)\n",
    "            after = np.zeros(prices.shape[0] - load.shape[0] - before.shape[0])\n",
    "            load = np.hstack([before, load, after])\n",
    "            return np.dot(load, prices)\n",
    "\n",
    "    def _get_usage(self, device, date):\n",
    "        return self.df[\"usage\"].loc[date, device + \"_usage\"]\n",
    "\n",
    "    def _get_activity(self, date, hour):\n",
    "        import numpy as np\n",
    "\n",
    "        if np.isnan(hour):\n",
    "            return np.nan\n",
    "        else:\n",
    "            dt = np.datetime64(date) + np.timedelta64(int(hour), \"h\")\n",
    "            return self.activity.input.loc[dt, \"activity\"]\n",
    "\n",
    "    def _get_starting_times(self, device):\n",
    "        import numpy as np\n",
    "\n",
    "        # extracts hours in which the device is turned on,\n",
    "        # conditional on that the device was turned off the hour before\n",
    "        times = self.df[\"load\"][device].index.to_numpy()\n",
    "        hour = self.df[\"load\"][device].values\n",
    "        before = np.insert(hour, 0, 0)[:-1]\n",
    "        return times[(before == 0) & (hour != 0)]\n",
    "\n",
    "    def _get_starting_hours(self, device, date):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "\n",
    "        times = self._get_starting_times(device)\n",
    "        date = np.datetime64(date) if type(date) != np.datetime64 else date\n",
    "        times = times[(times >= date) & (times < date + np.timedelta64(1, \"D\"))]\n",
    "        hours = (\n",
    "            pd.Series(times).apply(lambda x: x.hour).to_numpy()\n",
    "            if times.shape[0] != 0\n",
    "            else np.nan\n",
    "        )\n",
    "        return hours\n",
    "\n",
    "    def _get_load(self, true_loads, device, date, hour):\n",
    "        import numpy as np\n",
    "\n",
    "        try:\n",
    "            dt = np.datetime64(date) + np.timedelta64(hour, \"h\")\n",
    "        # if hour == NaN, return zero load profile\n",
    "        except ValueError:\n",
    "            return np.zeros(24)\n",
    "        try:\n",
    "            return true_loads[device].loc[dt].values\n",
    "        except KeyError as ke:\n",
    "            # return a zero load profile if the datetime index was not found\n",
    "            if str(ke).split(\"(\")[0] == \"numpy.datetime64\":\n",
    "                return np.zeros(24)\n",
    "            # in any other case raise the key error\n",
    "            else:\n",
    "                raise ke\n",
    "\n",
    "    # evaluation: performance metrics\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def evaluate(self, activity_threshold, usage_threshold):\n",
    "        name = f\"activity: {activity_threshold}; usage: {usage_threshold}\"\n",
    "        self.pipeline('recommendation', activity_threshold=activity_threshold, usage_threshold=usage_threshold, dates='all')\n",
    "        self.results[name] = self._evaluate()\n",
    "\n",
    "    def _evaluate(self):\n",
    "        import numpy as np\n",
    "\n",
    "        df = self.output[\"recommendation\"].copy()\n",
    "\n",
    "        # usage and activity target\n",
    "        df[\"usage_true\"] = df.apply(lambda row: self._get_usage(row[\"device\"], row.name), axis=1)\n",
    "        df[\"activity_true\"] = df.apply(lambda row: self._get_activity(row.name, row[\"recommendation\"]), axis=1)\n",
    "        df[\"acceptable\"] = df[\"usage_true\"] * df[\"activity_true\"]\n",
    "\n",
    "        # starting times\n",
    "        df[\"starting_times\"] = df.apply(\n",
    "            lambda row: self._get_starting_hours(row[\"device\"], row.name), axis=1\n",
    "        )\n",
    "        df[\"relevant_start\"] = abs(df[\"starting_times\"] - df[\"recommendation\"])\n",
    "        df.loc[df[\"starting_times\"].notna(), \"relevant_start\"] = df[\n",
    "            df[\"starting_times\"].notna()\n",
    "        ].apply(\n",
    "            lambda row: row[\"starting_times\"][np.argmin(row[\"relevant_start\"])], axis=1\n",
    "        )\n",
    "\n",
    "        # actual loads\n",
    "        true_loads = self.load.get_true_loads(self.config[\"user_input\"][\"shiftable_devices\"])\n",
    "        df[\"load\"] = df.apply(lambda row: self._get_load(true_loads, row[\"device\"], row.name, row[\"relevant_start\"]), axis=1)\n",
    "\n",
    "        # calculating costs\n",
    "        df[\"cost_no_recommendation\"] = df.apply(lambda row: self.calculate_cost(row.name, row[\"relevant_start\"], row[\"load\"]), axis=1)\n",
    "        df[\"cost_recommendation\"] = df.apply(lambda row: self.calculate_cost(row.name, row[\"recommendation\"], row[\"load\"]),axis=1)\n",
    "        df[\"savings\"] = df[\"cost_no_recommendation\"] - df[\"cost_recommendation\"]\n",
    "        df[\"relative_savings\"] = df[\"savings\"] / df[\"cost_no_recommendation\"]\n",
    "\n",
    "        return df[\n",
    "            [\n",
    "                \"device\",\n",
    "                \"recommendation\",\n",
    "                \"acceptable\",\n",
    "                \"relevant_start\",\n",
    "                \"cost_no_recommendation\",\n",
    "                \"cost_recommendation\",\n",
    "                \"savings\",\n",
    "                \"relative_savings\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def _result_to_summary(self, result):\n",
    "        return {\n",
    "            \"n_recommendations\": result[\"recommendation\"].count(),\n",
    "            \"acceptable\": result[\"acceptable\"].mean(),\n",
    "            \"total_savings\": (result[\"acceptable\"] * result[\"savings\"]).sum(),\n",
    "            \"relative_savings_mean\": result[\"relative_savings\"].mean(),\n",
    "            \"relative_savings_median\": result[\"relative_savings\"].median(),\n",
    "        }\n",
    "\n",
    "    def results_to_summary(self):\n",
    "        import pandas as pd\n",
    "\n",
    "        summary = {\n",
    "            name: self._result_to_summary(result)\n",
    "            for name, result in self.results.items()\n",
    "        }\n",
    "        return pd.DataFrame.from_dict(summary, orient=\"index\")\n",
    "\n",
    "    # evaluation: grid search and sensitivity\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    def grid_search(self, activity_thresholds, usage_thresholds):\n",
    "        import itertools\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        # updating the config\n",
    "        try:\n",
    "            self.config['evaluation']\n",
    "        except:\n",
    "            self.config['evaluation'] = {}\n",
    "\n",
    "        self.config['evaluation']['grid_search'] = {}\n",
    "        self.config['evaluation']['grid_search']['activity_thresholds'] = list(activity_thresholds)\n",
    "        self.config['evaluation']['grid_search']['usage_thresholds'] = list(usage_thresholds)\n",
    "\n",
    "        # testing candidate thresholds\n",
    "        iterator = itertools.product(activity_thresholds, usage_thresholds)\n",
    "        for thresholds in tqdm(list(iterator)):\n",
    "            self.evaluate(thresholds[0], thresholds[1])\n",
    "\n",
    "    def get_sensitivity(self, target):\n",
    "        import pandas as pd\n",
    "\n",
    "        df = self.results_to_summary()\n",
    "        sensitivity = pd.DataFrame()\n",
    "        for threshold_name in df.index:\n",
    "            thresholds = threshold_name.split(\"; \")\n",
    "            activity_threshold, usage_threshold = [th.split(\": \")[1] for th in thresholds]\n",
    "            sensitivity.loc[activity_threshold, usage_threshold] = df.loc[threshold_name, target]\n",
    "        # sort and name rows and columns\n",
    "        sensitivity = sensitivity.loc[sorted(sensitivity.index), :]\n",
    "        sensitivity = sensitivity.loc[:, sorted(sensitivity.columns)]\n",
    "        sensitivity.index.name = \"activity_threshold\"\n",
    "        sensitivity.columns.name = \"usage_threshold\"\n",
    "        return sensitivity\n",
    "\n",
    "    def get_optimal_thresholds(self):\n",
    "        df = self.results_to_summary()\n",
    "        result = df.sort_values(by='total_savings').iloc[-1, :]\n",
    "        thresholds = result.name.split('; ')\n",
    "        thresholds = [threshold.split(': ') for threshold in thresholds]\n",
    "        thresholds = {f\"{threshold}_threshold\": value for threshold, value in thresholds}\n",
    "        self.config['evaluation']['grid_search']['optimal_thresholds'] = thresholds\n",
    "        return thresholds\n",
    "\n",
    "    def thresholds_to_index(self, activity_threshold='optimal', usage_threshold='optimal'):\n",
    "        if activity_threshold == 'optimal':\n",
    "            activity_threshold = self.config['evaluation']['grid_search']['optimal_thresholds']['activity_threshold']\n",
    "        if usage_threshold == 'optimal':\n",
    "            usage_threshold = self.config['evaluation']['grid_search']['optimal_thresholds']['usage_threshold']\n",
    "        return f\"activity: {activity_threshold}; usage: {usage_threshold}\"\n",
    "\n",
    "    def optimal_result_to_summary(self):\n",
    "        import pandas as pd\n",
    "        optimal_thresholds = self.get_optimal_thresholds()\n",
    "        optimal_thresholds_index = self.thresholds_to_index()\n",
    "        result = self.results_to_summary().loc[optimal_thresholds_index, :]\n",
    "        result = result.append(pd.Series(optimal_thresholds))\n",
    "        result.name = self.config['data']['household']\n",
    "        return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.3px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
